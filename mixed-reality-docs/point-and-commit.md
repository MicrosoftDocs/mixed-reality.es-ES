---
title: Apuntar y confirmar con las manos
description: Introducción al modelo de entrada de apuntar y confirmar
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, interaction, design, hololens, hands, far, point and commit
ms.openlocfilehash: 30f85d2bb455abab3a533e0a829b4fba8cea0a7a
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 06/05/2019
ms.locfileid: "66402381"
---
# <a name="point-and-commit-with-hands"></a><span data-ttu-id="0448a-104">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="0448a-104">Point and commit with hands</span></span>
<span data-ttu-id="0448a-105">Apuntar y confirmar con las manos es un modelo de entrada que permite a los usuarios seleccionar como destino, seleccionar y manipular contenidos 2D y objetos 3D a distancia.</span><span class="sxs-lookup"><span data-stu-id="0448a-105">Point and commit with hands is an input model that enables users to target, select and manipulate 2D content and 3D objects in the distance.</span></span> <span data-ttu-id="0448a-106">Esta técnica de interacción de "lejana" es única de la realidad mixta, no es una forma que los humanos usan para interactuar de forma natural con el mundo real.</span><span class="sxs-lookup"><span data-stu-id="0448a-106">This "far" interaction technique is unique to mixed reality and is not a way humans naturally intereact with the real world.</span></span> <span data-ttu-id="0448a-107">Por ejemplo, en la película se superhéroes *X-Men*, el personaje [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) es capaz de llegar a objetos lejanos y manipularlos a distancia con las manos.</span><span class="sxs-lookup"><span data-stu-id="0448a-107">For example, in the super hero movie *X-Men*, the character [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) is capable of reaching out and manipulating a far object in the distance with his hands.</span></span> <span data-ttu-id="0448a-108">Esto no es algo que los seres humanos pueden hacer en el mundo real.</span><span class="sxs-lookup"><span data-stu-id="0448a-108">This is not something humans can do in reality.</span></span> <span data-ttu-id="0448a-109">Tanto en HoloLens (AR) como en la realidad mixta (VR), dotamos a los usuarios con poderes mágicos, eliminando la limitación física del mundo real no para tener una magnífica experiencia con contenido holográfico, sino también para aumentar la eficacia de la interacción.</span><span class="sxs-lookup"><span data-stu-id="0448a-109">In both HoloLens (AR) and Mixed Reality (VR), we equip users with this magical power, breaking the physical constraint of the real world not only to have a delightful experience with holographic contents but also to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="0448a-110">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="0448a-110">Device support</span></span>

<span data-ttu-id="0448a-111">Modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="0448a-111">Input model</span></span> | [<span data-ttu-id="0448a-112">HoloLens (1ª generación)</span><span class="sxs-lookup"><span data-stu-id="0448a-112">HoloLens (1st gen)</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details) | <span data-ttu-id="0448a-113">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="0448a-113">HoloLens 2</span></span> | [<span data-ttu-id="0448a-114">Cascos envolventes</span><span class="sxs-lookup"><span data-stu-id="0448a-114">Immersive headsets</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details) |
| ---------| -----| ----- | ---------|
<span data-ttu-id="0448a-115">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="0448a-115">Point and commit with hands</span></span> | <span data-ttu-id="0448a-116">❌ No se admite</span><span class="sxs-lookup"><span data-stu-id="0448a-116">❌ Not supported</span></span> | <span data-ttu-id="0448a-117">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="0448a-117">✔️ Recommended</span></span> | <span data-ttu-id="0448a-118">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="0448a-118">✔️ Recommended</span></span>

<span data-ttu-id="0448a-119">Apuntar y confirmar, también conocido como manos lejanas, es una de las nuevas características que utiliza el nuevo sistema de seguimiento de la mano articulado.</span><span class="sxs-lookup"><span data-stu-id="0448a-119">Point and commit, also known as hands far, is one of the new features that utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="0448a-120">Este modelo de entrada también es el principal en los cascos envolventes mediante el uso de controladores de movimiento.</span><span class="sxs-lookup"><span data-stu-id="0448a-120">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span>

## <a name="hand-rays"></a><span data-ttu-id="0448a-121">Rayos de las manos</span><span class="sxs-lookup"><span data-stu-id="0448a-121">Hand rays</span></span>

<span data-ttu-id="0448a-122">En HoloLens 2, hemos creado un rayo que sale desde el centro de la palma de la mano.</span><span class="sxs-lookup"><span data-stu-id="0448a-122">On HoloLens 2, we created a hand ray that shoots out from the center of a palm.</span></span> <span data-ttu-id="0448a-123">Dicho rayo se trata como una extensión de la mano.</span><span class="sxs-lookup"><span data-stu-id="0448a-123">This ray is treated as an extension of the hand.</span></span> <span data-ttu-id="0448a-124">Un cursor con forma de anillo se acopla al final del rayo para indicar la ubicación en que el rayo se cruza con un objeto de destino.</span><span class="sxs-lookup"><span data-stu-id="0448a-124">A donut-shaped cursor is attached to the end of the ray to indicate the location where the ray intersects with a target object.</span></span> <span data-ttu-id="0448a-125">El objeto en que se posa el cursor puede recibir comandos gestuales de la mano.</span><span class="sxs-lookup"><span data-stu-id="0448a-125">The object that the cursor lands on can then receive gestural commands from the hand.</span></span>

<span data-ttu-id="0448a-126">Este comando gestual básico se desencadena al usar los dedos pulgar e índice para realizar la acción de pulsar en el aire.</span><span class="sxs-lookup"><span data-stu-id="0448a-126">This basic gestural command is triggered by using the thumb and index finger to perform the air-tap action.</span></span> <span data-ttu-id="0448a-127">Si se usa el rayo de la mano para apunte y la acción de pulsar en el aire para confirmar, los usuarios pueden activar un botón o un hipervínculo en un contenido web.</span><span class="sxs-lookup"><span data-stu-id="0448a-127">By using the hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="0448a-128">Con más gestos compuestos, los usuarios son capaces de navegar por el contenido web y manipular objetos 3D a distancia.</span><span class="sxs-lookup"><span data-stu-id="0448a-128">With more composite gestures, users are capable of navigating web content and manipulating 3D objects from a distance.</span></span> <span data-ttu-id="0448a-129">El diseño visual del rayo de la mano también debe reaccionar a estos estados de apuntar y confirmar, como se describe y se muestra a continuación:</span><span class="sxs-lookup"><span data-stu-id="0448a-129">The visual design of the hand ray should also react to these point and commit states, as described and shown below:</span></span> 

* <span data-ttu-id="0448a-130">En el estado *señalar*, el rayo es una línea discontinua y el cursor tiene forma de anillo.</span><span class="sxs-lookup"><span data-stu-id="0448a-130">In the *pointing* state, the ray is a dash line and the cursor is a donut shape.</span></span>
* <span data-ttu-id="0448a-131">En el estado *confirmar*, el rayo se convierte en una línea sólida y el cursor se reduce a un punto.</span><span class="sxs-lookup"><span data-stu-id="0448a-131">In the *commit* state, the ray turns into a solid line and the cursor shrinks to a dot.</span></span>

![](images/Hand-Rays-720px.jpg)

## <a name="transition-between-near-and-far"></a><span data-ttu-id="0448a-132">Transición entre cerca y lejos</span><span class="sxs-lookup"><span data-stu-id="0448a-132">Transition between near and far</span></span>

<span data-ttu-id="0448a-133">En lugar de usar un gesto concreto, como "apuntar con el dedo índice" para dirigir el rayo, hemos diseñado que el rayo parta del centro de la palma de la mano, con el fin de liberar y reservar los cinco dedos para los gestos más manipulativos, como acercar los dedos y agarrar.</span><span class="sxs-lookup"><span data-stu-id="0448a-133">Instead of using specific gesture, such as "pointing with index finger" to direct the ray, we designed the ray coming out from the center of the palm, releasing and reserving the five fingers for more manipulative gestures, such as pinch and grab.</span></span> <span data-ttu-id="0448a-134">Con este diseño, creamos solo un modelo mental, que admite exactamente el mismo conjunto de gestos de las manos para la interacción cercana y la lejana.</span><span class="sxs-lookup"><span data-stu-id="0448a-134">With this design, we create only one mental model, supporting exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="0448a-135">Puedes usar el mismo gesto de arrastrar para manipular objetos que se encuentren a distinta distancia.</span><span class="sxs-lookup"><span data-stu-id="0448a-135">You can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="0448a-136">La invocación de los rayos es automática y se basa en la proximidad:</span><span class="sxs-lookup"><span data-stu-id="0448a-136">The invocation of the rays is automatic and proximity based:</span></span>

*  <span data-ttu-id="0448a-137">Cuando a un objeto se llega estirando el brazo (aproximadamente 50 cm), los rayos se desactivan automáticamente, lo que fomenta la interacción cercana.</span><span class="sxs-lookup"><span data-stu-id="0448a-137">When an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span>
*  <span data-ttu-id="0448a-138">Cuando el objeto está a más de 50 cm, los rayos se activan.</span><span class="sxs-lookup"><span data-stu-id="0448a-138">When the object is farther than 50 cm, the rays are turned on.</span></span> <span data-ttu-id="0448a-139">La transición suave y sin problemas.</span><span class="sxs-lookup"><span data-stu-id="0448a-139">The transition should be smooth and seamless.</span></span>

![](images/Transition-Between-Near-And-Far-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="0448a-140">Interacción con una tableta táctil 2D</span><span class="sxs-lookup"><span data-stu-id="0448a-140">2D slate interaction</span></span>

<span data-ttu-id="0448a-141">Una tableta táctil 2D es un contenedor holográfico que hospeda contenido de aplicaciones 2D, como un explorador web.</span><span class="sxs-lookup"><span data-stu-id="0448a-141">A 2D Slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="0448a-142">El concepto de diseño para la interacción lejana con una tableta táctil 2D es usar los rayos de las manos para buscar el objetivo y pulsar en el aire para seleccionarlo.</span><span class="sxs-lookup"><span data-stu-id="0448a-142">The design concept for far interacting with a 2D slate is to use hand rays to target and air tap to select.</span></span> <span data-ttu-id="0448a-143">Después de buscar el destino con un rayo de la mano, los usuarios pueden pulsar en el aire para desencadenar un hipervínculo o un botón.</span><span class="sxs-lookup"><span data-stu-id="0448a-143">After targeting with a hand ray, users can air tap to trigger a hyperlink or a button.</span></span> <span data-ttu-id="0448a-144">Pueden usar una mano para "pulsar en el aire y arrastrar" para desplazar el contenido de una tableta táctil hacia arriba y hacia abajo.</span><span class="sxs-lookup"><span data-stu-id="0448a-144">They can use one hand to "air tap and drag" to scroll a slate content up and down.</span></span> <span data-ttu-id="0448a-145">El movimiento relativo de usar las dos manos para pulsar en el aire y arrastrar puede acercar y alejar el contenido de la tableta táctil.</span><span class="sxs-lookup"><span data-stu-id="0448a-145">The relative motion of using two hands to air tap and drag can zoom in and out the slate content.</span></span>

<span data-ttu-id="0448a-146">Si se seleccionan como destino del rayo las esquinas y los bordes aparece la prestación de manipulación más cercana.</span><span class="sxs-lookup"><span data-stu-id="0448a-146">Targeting the hand ray at the corners and edges reveals the closest manipulation affordance.</span></span> <span data-ttu-id="0448a-147">Mediante "agarrar y arrastrar" las prestaciones de manipulación los usuarios pueden realizar un escalado uniforme mediante las prestaciones de la esquina y pueden redistribuir la tableta táctil mediante las prestaciones del borde.</span><span class="sxs-lookup"><span data-stu-id="0448a-147">By "grab and drag" the manipulation affordances, users can perform uniform scaling through the corner affordances and can reflow the slate via the edge affordances.</span></span> <span data-ttu-id="0448a-148">El procedimiento de agarrar y arrastrar la barra holográfica de la parte superior de la tableta táctil 2D puede permitir a los usuarios mover toda la tableta táctil.</span><span class="sxs-lookup"><span data-stu-id="0448a-148">Grabbing and dragging the holobar at the top of the 2D slate can users move the whole slate.</span></span>

![](images/2D-Slate-Interaction-Far-720px.jpg)

<span data-ttu-id="0448a-149">Para manipular la propia tableta táctil 2D:</span><span class="sxs-lookup"><span data-stu-id="0448a-149">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="0448a-150">los usuarios apuntan el rayo de la mano a las esquinas y bordes y aparece la prestación de manipulación más cercana.</span><span class="sxs-lookup"><span data-stu-id="0448a-150">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="0448a-151">Al aplicar un gesto de manipulación en la prestación, los usuarios pueden realizar un escalado uniforme mediante la prestación de la esquina y pueden redistribuir la tableta táctil mediante la prestación del borde.</span><span class="sxs-lookup"><span data-stu-id="0448a-151">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="0448a-152">Si aplican un gesto de manipulación a la barra holográfica de la parte superior de la tableta táctil 2D, los usuarios pueden mover toda la tableta táctil.</span><span class="sxs-lookup"><span data-stu-id="0448a-152">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="0448a-153">Manipulación de objetos 3D</span><span class="sxs-lookup"><span data-stu-id="0448a-153">3D object manipulation</span></span>

<span data-ttu-id="0448a-154">En la manipulación directa, hay dos formas de que los usuarios manipulen objetos 3D, la manipulación con prestaciones y la manipulación sin prestaciones.</span><span class="sxs-lookup"><span data-stu-id="0448a-154">In direct manipulation, there are two ways for users to manipulate 3D object, affordance-based manipulation and non-affordance based manipulation.</span></span> <span data-ttu-id="0448a-155">En el modelo de señalar y confirmar, los usuarios son capaces de conseguir exactamente las mismas tareas a través de los rayos de las manos.</span><span class="sxs-lookup"><span data-stu-id="0448a-155">In the point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="0448a-156">No se necesita ningún aprendizaje adicional.</span><span class="sxs-lookup"><span data-stu-id="0448a-156">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="0448a-157">Manipulación con prestaciones</span><span class="sxs-lookup"><span data-stu-id="0448a-157">Affordance-based manipulation</span></span>
<span data-ttu-id="0448a-158">Los usuarios usan los rayos de las manos para apuntar y mostrar el rectángulo de selección y las prestaciones de manipulación.</span><span class="sxs-lookup"><span data-stu-id="0448a-158">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="0448a-159">Los usuarios pueden aplicar el gesto de manipulación al rectángulo de selección para mover todo el objeto, a las prestaciones del borde para girarlo y a las prestaciones de la esquina para escalarlo de forma uniforme.</span><span class="sxs-lookup"><span data-stu-id="0448a-159">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="0448a-160">Manipulación sin prestaciones</span><span class="sxs-lookup"><span data-stu-id="0448a-160">Non-affordance based manipulation</span></span>
<span data-ttu-id="0448a-161">Los usuarios señalan con los rayos de las manos para mostrar el rectángulo de selección y, después, le aplican directamente los gestos de manipulación.</span><span class="sxs-lookup"><span data-stu-id="0448a-161">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="0448a-162">Con una mano, la traslación y rotación del objeto se asocian con el movimiento y la orientación de la mano.</span><span class="sxs-lookup"><span data-stu-id="0448a-162">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="0448a-163">Con dos manos, los usuarios pueden trasladarlo, escalarlo y girarlo en función de los movimientos relativos de las dos manos.</span><span class="sxs-lookup"><span data-stu-id="0448a-163">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="0448a-164">Gestos instintivos</span><span class="sxs-lookup"><span data-stu-id="0448a-164">Instinctual gesturers</span></span>
<span data-ttu-id="0448a-165">El concepto de gestos instintivos para señalar y confirmar es similar a la de la manipulación directa.</span><span class="sxs-lookup"><span data-stu-id="0448a-165">The concept of instinctual gestures for point and commit is similar to that for direct manipulation.</span></span> <span data-ttu-id="0448a-166">Los gestos que se supone que los usuarios van a realizar en un objeto 3D los guía el diseño de las prestaciones 3D.</span><span class="sxs-lookup"><span data-stu-id="0448a-166">The gestures users are suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="0448a-167">Por ejemplo, un punto de control pequeño podría motivar a los usuarios a acercar los dedos pulgar e índice, mientras que si un usuario desea agarrar un objeto mayor, debe usar los cinco dedos.</span><span class="sxs-lookup"><span data-stu-id="0448a-167">For example, a small control point might motivate users to pinch with their thumb and index finger, while a user might want to grab a larger object using all 5 fingers.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="0448a-168">Diseño simétrico entre las manos y 6 controladores DoF</span><span class="sxs-lookup"><span data-stu-id="0448a-168">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="0448a-169">El concepto de apuntar y confirmar para la interacción lejana se creó y definió inicialmente para el Portal de realidad mixta (MRP), donde un usuario lleva puesto un casco envolvente e interactúa con objetos 3D a través de los controladores de movimiento.</span><span class="sxs-lookup"><span data-stu-id="0448a-169">The concept of point and commit for far interaction was initially created and defined for the Mixed Reality Portal (MRP), where a user wears an immersive headset and interacts with 3D objects via motion controllers.</span></span> <span data-ttu-id="0448a-170">Los controladores de movimiento lanzar rayos para señalar y manipular objetos lejanos.</span><span class="sxs-lookup"><span data-stu-id="0448a-170">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="0448a-171">Hay botones en los controladores para confirmar más acciones diferentes.</span><span class="sxs-lookup"><span data-stu-id="0448a-171">There are buttons on the controllers for further committing different actions.</span></span> <span data-ttu-id="0448a-172">Aprovechamos el modelo de interacción de rayos y los acoplamos a ambas manos.</span><span class="sxs-lookup"><span data-stu-id="0448a-172">We leverage the interaction model of rays and attached them to both hands.</span></span> <span data-ttu-id="0448a-173">Con este diseño simétrico, los usuarios que están familiarizados con MRP no necesitan aprender otro modelo de interacción para señalar y manipular a distancia cuando usan HoloLens 2, y viceversa.</span><span class="sxs-lookup"><span data-stu-id="0448a-173">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation when they use HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>

## <a name="instinctual-gestures"></a><span data-ttu-id="0448a-174">Gestos instintivos</span><span class="sxs-lookup"><span data-stu-id="0448a-174">Instinctual gestures</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)

## <a name="see-also"></a><span data-ttu-id="0448a-175">Consulte también</span><span class="sxs-lookup"><span data-stu-id="0448a-175">See also</span></span>
* [<span data-ttu-id="0448a-176">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="0448a-176">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="0448a-177">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="0448a-177">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="0448a-178">Interacciones instintivas</span><span class="sxs-lookup"><span data-stu-id="0448a-178">Instinctual interactions</span></span>](interaction-fundamentals.md)

