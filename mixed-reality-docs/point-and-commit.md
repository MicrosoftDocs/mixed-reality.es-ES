---
title: Punto y la confirmación con manos
description: Información general sobre el modelo de entrada de punto y confirmación
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Ahora, la realidad, interacción, diseño, hololens, manos, mixta elija y confirme
ms.openlocfilehash: 30f85d2bb455abab3a533e0a829b4fba8cea0a7a
ms.sourcegitcommit: 5b4292ef786447549c0199003e041ca48bb454cd
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/30/2019
ms.locfileid: "66402381"
---
# <a name="point-and-commit-with-hands"></a><span data-ttu-id="8878f-104">Punto y la confirmación con manos</span><span class="sxs-lookup"><span data-stu-id="8878f-104">Point and commit with hands</span></span>
<span data-ttu-id="8878f-105">Punto y la confirmación con manos es un modelo de entrada que permite a los usuarios de destino, seleccionar y manipular objetos 3D y contenidos 2D en la distancia.</span><span class="sxs-lookup"><span data-stu-id="8878f-105">Point and commit with hands is an input model that enables users to target, select and manipulate 2D content and 3D objects in the distance.</span></span> <span data-ttu-id="8878f-106">Esta técnica de interacción de "extremo" es única para realidad mixta y no es un hombre de manera de forma natural intereact con el mundo real.</span><span class="sxs-lookup"><span data-stu-id="8878f-106">This "far" interaction technique is unique to mixed reality and is not a way humans naturally intereact with the real world.</span></span> <span data-ttu-id="8878f-107">Por ejemplo, en la película héroe *X hombres*, el carácter [reescribible](https://en.wikipedia.org/wiki/Magneto_(comics)) es capaz de llegando y manipular un objeto lejos en la distancia con las manos.</span><span class="sxs-lookup"><span data-stu-id="8878f-107">For example, in the super hero movie *X-Men*, the character [Magneto](https://en.wikipedia.org/wiki/Magneto_(comics)) is capable of reaching out and manipulating a far object in the distance with his hands.</span></span> <span data-ttu-id="8878f-108">No es algo que los seres humanos pueden hacer en realidad.</span><span class="sxs-lookup"><span data-stu-id="8878f-108">This is not something humans can do in reality.</span></span> <span data-ttu-id="8878f-109">En HoloLens (AR) y realidad mixta (VR), se ofrecen a los usuarios con esta eficacia mágica, interrumpir la restricción física del mundo real no solo para tener una experiencia agradable con contenido holográfica sino también para que la interacción más eficaz y eficiente.</span><span class="sxs-lookup"><span data-stu-id="8878f-109">In both HoloLens (AR) and Mixed Reality (VR), we equip users with this magical power, breaking the physical constraint of the real world not only to have a delightful experience with holographic contents but also to make the interaction more effective and efficient.</span></span>

## <a name="device-support"></a><span data-ttu-id="8878f-110">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="8878f-110">Device support</span></span>

<span data-ttu-id="8878f-111">Modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="8878f-111">Input model</span></span> | [<span data-ttu-id="8878f-112">HoloLens (gen 1)</span><span class="sxs-lookup"><span data-stu-id="8878f-112">HoloLens (1st gen)</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details) | <span data-ttu-id="8878f-113">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="8878f-113">HoloLens 2</span></span> | [<span data-ttu-id="8878f-114">Inmersivos</span><span class="sxs-lookup"><span data-stu-id="8878f-114">Immersive headsets</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details) |
| ---------| -----| ----- | ---------|
<span data-ttu-id="8878f-115">Punto y la confirmación con manos</span><span class="sxs-lookup"><span data-stu-id="8878f-115">Point and commit with hands</span></span> | <span data-ttu-id="8878f-116">❌ No compatible</span><span class="sxs-lookup"><span data-stu-id="8878f-116">❌ Not supported</span></span> | <span data-ttu-id="8878f-117">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="8878f-117">✔️ Recommended</span></span> | <span data-ttu-id="8878f-118">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="8878f-118">✔️ Recommended</span></span>

<span data-ttu-id="8878f-119">Punto y confirmación, también conocido como manos ahora, es una de las nuevas características que utiliza el nuevo sistema de seguimiento de la mano articulado.</span><span class="sxs-lookup"><span data-stu-id="8878f-119">Point and commit, also known as hands far, is one of the new features that utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="8878f-120">Este modelo de entrada también es el modelo de entrada principal en inmersivos mediante el uso de los controladores de movimiento.</span><span class="sxs-lookup"><span data-stu-id="8878f-120">This input model is also the primary input model on immersive headsets through the use of motion controllers.</span></span>

## <a name="hand-rays"></a><span data-ttu-id="8878f-121">Rayos de mano</span><span class="sxs-lookup"><span data-stu-id="8878f-121">Hand rays</span></span>

<span data-ttu-id="8878f-122">En HoloLens 2, hemos creado un rayo de mano que le envíe desde el centro de una mano.</span><span class="sxs-lookup"><span data-stu-id="8878f-122">On HoloLens 2, we created a hand ray that shoots out from the center of a palm.</span></span> <span data-ttu-id="8878f-123">Este ray se trata como una extensión de la mano.</span><span class="sxs-lookup"><span data-stu-id="8878f-123">This ray is treated as an extension of the hand.</span></span> <span data-ttu-id="8878f-124">Un cursor en forma de anillo se adjunta al final del rayo para indicar la ubicación donde cruza el rayo con un objeto de destino.</span><span class="sxs-lookup"><span data-stu-id="8878f-124">A donut-shaped cursor is attached to the end of the ray to indicate the location where the ray intersects with a target object.</span></span> <span data-ttu-id="8878f-125">El objeto que llega al cursor, a continuación, puede recibir comandos gestural de la mano.</span><span class="sxs-lookup"><span data-stu-id="8878f-125">The object that the cursor lands on can then receive gestural commands from the hand.</span></span>

<span data-ttu-id="8878f-126">Este comando gestural básico se desencadena al usar el control thumb y dedo índice para realizar la acción de pulsar en el aire.</span><span class="sxs-lookup"><span data-stu-id="8878f-126">This basic gestural command is triggered by using the thumb and index finger to perform the air-tap action.</span></span> <span data-ttu-id="8878f-127">Utilizando el rayo de mano para que apunte y pulse para confirmar en el aire, los usuarios pueden activar un botón o un hipervínculo a un contenido web.</span><span class="sxs-lookup"><span data-stu-id="8878f-127">By using the hand ray to point and air tap to commit, users can activate a button or a hyperlink on a web content.</span></span> <span data-ttu-id="8878f-128">Con los gestos compuestos más, los usuarios son capaces de contenido web de explorar y manipular objetos 3D a distancia.</span><span class="sxs-lookup"><span data-stu-id="8878f-128">With more composite gestures, users are capable of navigating web content and manipulating 3D objects from a distance.</span></span> <span data-ttu-id="8878f-129">El diseño visual del rayo mano también debe reaccionar a estos Estados de punto y confirmación, como se describe y se muestra a continuación:</span><span class="sxs-lookup"><span data-stu-id="8878f-129">The visual design of the hand ray should also react to these point and commit states, as described and shown below:</span></span> 

* <span data-ttu-id="8878f-130">En el *señalando* de estado, el rayo es una línea de guiones y el cursor es una forma de anillo.</span><span class="sxs-lookup"><span data-stu-id="8878f-130">In the *pointing* state, the ray is a dash line and the cursor is a donut shape.</span></span>
* <span data-ttu-id="8878f-131">En el *confirmación* de estado, el rayo se convierte en una línea sólida y reduce el cursor en un punto.</span><span class="sxs-lookup"><span data-stu-id="8878f-131">In the *commit* state, the ray turns into a solid line and the cursor shrinks to a dot.</span></span>

![](images/Hand-Rays-720px.jpg)

## <a name="transition-between-near-and-far"></a><span data-ttu-id="8878f-132">Realizar una transición entre cerca y de extremo</span><span class="sxs-lookup"><span data-stu-id="8878f-132">Transition between near and far</span></span>

<span data-ttu-id="8878f-133">En lugar de usar un gesto específico, como "que apunta con el dedo índice" para indicar el rayo, diseñamos el rayo procedentes de salida desde el centro de la palma, lanzar y reservar los cinco dedos para los gestos de manipulación inherente más, como alejar y tomar.</span><span class="sxs-lookup"><span data-stu-id="8878f-133">Instead of using specific gesture, such as "pointing with index finger" to direct the ray, we designed the ray coming out from the center of the palm, releasing and reserving the five fingers for more manipulative gestures, such as pinch and grab.</span></span> <span data-ttu-id="8878f-134">Con este diseño, creamos un único modelo mental, compatibilidad con exactamente el mismo conjunto de gestos de mano para la interacción del próximo y lejano.</span><span class="sxs-lookup"><span data-stu-id="8878f-134">With this design, we create only one mental model, supporting exactly the same set of hand gestures for both near and far interaction.</span></span> <span data-ttu-id="8878f-135">Puede usar el mismo gesto de arrastre para manipular objetos en las distancias diferentes.</span><span class="sxs-lookup"><span data-stu-id="8878f-135">You can use the same grab gesture to manipulate objects at different distances.</span></span> <span data-ttu-id="8878f-136">La invocación de los rayos es automático y en función de proximidad:</span><span class="sxs-lookup"><span data-stu-id="8878f-136">The invocation of the rays is automatic and proximity based:</span></span>

*  <span data-ttu-id="8878f-137">Cuando un objeto está dentro de arm alcanzado distancia (aproximadamente 50 cm), los rayos están desactivados fomentar automáticamente para la interacción casi.</span><span class="sxs-lookup"><span data-stu-id="8878f-137">When an object is within arm reached distance (roughly 50 cm), the rays are turned off automatically encouraging for near interaction.</span></span>
*  <span data-ttu-id="8878f-138">Cuando el objeto es más lejos de 50 cm, están activados los rayos.</span><span class="sxs-lookup"><span data-stu-id="8878f-138">When the object is farther than 50 cm, the rays are turned on.</span></span> <span data-ttu-id="8878f-139">Debe ser la transición homogénea y sin problemas.</span><span class="sxs-lookup"><span data-stu-id="8878f-139">The transition should be smooth and seamless.</span></span>

![](images/Transition-Between-Near-And-Far-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="8878f-140">Interacción de pizarra 2D</span><span class="sxs-lookup"><span data-stu-id="8878f-140">2D slate interaction</span></span>

<span data-ttu-id="8878f-141">Una pizarra 2D es un contenedor holográfico hospedar contenido de la aplicación 2D, como explorador web.</span><span class="sxs-lookup"><span data-stu-id="8878f-141">A 2D Slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="8878f-142">El concepto de diseño para el momento interactuar con una pizarra 2D es usar rayos de mano a tap aire y de destino que seleccione.</span><span class="sxs-lookup"><span data-stu-id="8878f-142">The design concept for far interacting with a 2D slate is to use hand rays to target and air tap to select.</span></span> <span data-ttu-id="8878f-143">Después de destino con un rayo de mano, los usuarios pueden pulse en el aire para desencadenar un hipervínculo o un botón.</span><span class="sxs-lookup"><span data-stu-id="8878f-143">After targeting with a hand ray, users can air tap to trigger a hyperlink or a button.</span></span> <span data-ttu-id="8878f-144">Puede usar por un lado para "pulsar y arrastrar el aire" para desplazarse hacia arriba y abajo un contenido Pizarra.</span><span class="sxs-lookup"><span data-stu-id="8878f-144">They can use one hand to "air tap and drag" to scroll a slate content up and down.</span></span> <span data-ttu-id="8878f-145">El movimiento relativo del uso de dos manos para pulsar y arrastrar el aire puede aumentar y reducir el contenido de Pizarra.</span><span class="sxs-lookup"><span data-stu-id="8878f-145">The relative motion of using two hands to air tap and drag can zoom in and out the slate content.</span></span>

<span data-ttu-id="8878f-146">Como destino el rayo disponible en los bordes y esquinas revela la prestación de manipulación más cercano.</span><span class="sxs-lookup"><span data-stu-id="8878f-146">Targeting the hand ray at the corners and edges reveals the closest manipulation affordance.</span></span> <span data-ttu-id="8878f-147">"Arrastre y arrastrar" la factibilidad de manipulación, los usuarios puede realizar uniforme de escalado a través de las prestaciones de esquina y puede redistribuir la Pizarra a través de las prestaciones de edge.</span><span class="sxs-lookup"><span data-stu-id="8878f-147">By "grab and drag" the manipulation affordances, users can perform uniform scaling through the corner affordances and can reflow the slate via the edge affordances.</span></span> <span data-ttu-id="8878f-148">Hacerlo y arrastre el holobar en la parte superior de la Pizarra 2D pueden mover la Pizarra toda los usuarios.</span><span class="sxs-lookup"><span data-stu-id="8878f-148">Grabbing and dragging the holobar at the top of the 2D slate can users move the whole slate.</span></span>

![](images/2D-Slate-Interaction-Far-720px.jpg)

<span data-ttu-id="8878f-149">Para manipular la 2D Pizarra propio:</span><span class="sxs-lookup"><span data-stu-id="8878f-149">For manipulating the 2D slate itself:</span></span><br>

* <span data-ttu-id="8878f-150">Los usuarios señalan el rayo de mano de las esquinas o bordes para revelar la prestación de manipulación más cercano.</span><span class="sxs-lookup"><span data-stu-id="8878f-150">Users point the hand ray at the corners or edges to reveal the closest manipulation affordance.</span></span> 
* <span data-ttu-id="8878f-151">Aplicando un gesto de manipulación en la prestación, los usuarios pueden realizar un ajuste de escala uniforme a través de la prestación de esquina y pueden redistribuir la Pizarra a través de la prestación de edge.</span><span class="sxs-lookup"><span data-stu-id="8878f-151">By applying a manipulation gesture on the affordance, users can perform uniform scaling through the corner affordance and can reflow the slate via the edge affordance.</span></span> 
* <span data-ttu-id="8878f-152">Aplicando un gesto de manipulación en el holobar en la parte superior de la Pizarra 2D, los usuarios pueden mover la Pizarra toda.</span><span class="sxs-lookup"><span data-stu-id="8878f-152">By applying a manipulation gesture on the holobar at the top of the 2D slate, users can move the whole slate.</span></span><br>

<br>

## <a name="3d-object-manipulation"></a><span data-ttu-id="8878f-153">Manipulación del objeto 3D</span><span class="sxs-lookup"><span data-stu-id="8878f-153">3D object manipulation</span></span>

<span data-ttu-id="8878f-154">En la manipulación directa, hay dos maneras para que los usuarios manipular objetos 3D, manipulación de prestación y no prestación en función de manipulación.</span><span class="sxs-lookup"><span data-stu-id="8878f-154">In direct manipulation, there are two ways for users to manipulate 3D object, affordance-based manipulation and non-affordance based manipulation.</span></span> <span data-ttu-id="8878f-155">En el modelo de punto y confirmación, los usuarios son capaces de conseguir exactamente las mismas tareas a través de los rayos de mano.</span><span class="sxs-lookup"><span data-stu-id="8878f-155">In the point and commit model, users are capable of achieving exactly the same tasks through the hand rays.</span></span> <span data-ttu-id="8878f-156">No se necesita ningún aprendizaje adicional.</span><span class="sxs-lookup"><span data-stu-id="8878f-156">No additional learning is needed.</span></span><br>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="8878f-157">Manipulación de prestación</span><span class="sxs-lookup"><span data-stu-id="8878f-157">Affordance-based manipulation</span></span>
<span data-ttu-id="8878f-158">Los usuarios usar rayos de mano para que apunte y mostrar el cuadro de límite y prestaciones de manipulación.</span><span class="sxs-lookup"><span data-stu-id="8878f-158">Users use hand rays to point and reveal the bounding box and manipulation affordances.</span></span> <span data-ttu-id="8878f-159">Los usuarios pueden aplicar el gesto de manipulación en el cuadro de límite para mover todo el objeto, en la factibilidad de borde se va a girar y en la esquina prestaciones para escalar de manera uniforme.</span><span class="sxs-lookup"><span data-stu-id="8878f-159">Users can apply the manipulation gesture on the bounding box to move the whole object, on the edge affordances to rotate and on the coner affordances to scale uniformly.</span></span> <br>

![](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="8878f-160">No prestación en función de manipulación</span><span class="sxs-lookup"><span data-stu-id="8878f-160">Non-affordance based manipulation</span></span>
<span data-ttu-id="8878f-161">Los usuarios señalan con rayos de mano para mostrar el cuadro de límite, a continuación, se aplican directamente a gestos de manipulación en él.</span><span class="sxs-lookup"><span data-stu-id="8878f-161">Users point with hand rays to reveal the bounding box then directly apply manipulation gestures on it.</span></span> <span data-ttu-id="8878f-162">Con una mano, la traslación y rotación del objeto se asocian a movimiento y la orientación de la mano.</span><span class="sxs-lookup"><span data-stu-id="8878f-162">With one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="8878f-163">Con dos manos, los usuarios pueden trasladar, escalar y girarlo según los movimientos relativos de dos manos.</span><span class="sxs-lookup"><span data-stu-id="8878f-163">With two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br>

<br>

## <a name="instinctual-gesturers"></a><span data-ttu-id="8878f-164">Gesturers instinctual</span><span class="sxs-lookup"><span data-stu-id="8878f-164">Instinctual gesturers</span></span>
<span data-ttu-id="8878f-165">El concepto de gestos instinctual para la confirmación y el punto es similar a la de la manipulación directa.</span><span class="sxs-lookup"><span data-stu-id="8878f-165">The concept of instinctual gestures for point and commit is similar to that for direct manipulation.</span></span> <span data-ttu-id="8878f-166">Los gestos se supone que los usuarios deben para realizar en un objeto 3D se le guiará por el diseño de factibilidad de interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="8878f-166">The gestures users are suppose to perform on a 3D object are guided by the design of UI affordances.</span></span> <span data-ttu-id="8878f-167">Por ejemplo, un punto de control pequeño podría motivar a los usuarios alejar con su pulgar y el dedo índice, mientras que un usuario podría desear tomar un objeto más grande de todos los dedos de 5.</span><span class="sxs-lookup"><span data-stu-id="8878f-167">For example, a small control point might motivate users to pinch with their thumb and index finger, while a user might want to grab a larger object using all 5 fingers.</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a><span data-ttu-id="8878f-168">Diseño simétrica entre manos y 6 controlador GDL</span><span class="sxs-lookup"><span data-stu-id="8878f-168">Symmetric design between hands and 6 DoF controller</span></span> 
<span data-ttu-id="8878f-169">El concepto de punto y confirmación para la interacción del Lejano inicialmente se ha creado y definido para el Mixed Reality Portal (MRP), donde un usuario desempeña un auricular envolvente e interactúa con objetos 3D a través de los controladores de movimiento.</span><span class="sxs-lookup"><span data-stu-id="8878f-169">The concept of point and commit for far interaction was initially created and defined for the Mixed Reality Portal (MRP), where a user wears an immersive headset and interacts with 3D objects via motion controllers.</span></span> <span data-ttu-id="8878f-170">Solucionar los controladores de movimiento horizontal rayos para señalar y manipular objetos lejano.</span><span class="sxs-lookup"><span data-stu-id="8878f-170">The motion controllers shoot out rays for pointing and manipulating far objects.</span></span> <span data-ttu-id="8878f-171">Hay botones en los controladores para confirmar más acciones diferentes.</span><span class="sxs-lookup"><span data-stu-id="8878f-171">There are buttons on the controllers for further committing different actions.</span></span> <span data-ttu-id="8878f-172">Que aprovechan el modelo de interacción de rayos y ellos conectados a dos manos.</span><span class="sxs-lookup"><span data-stu-id="8878f-172">We leverage the interaction model of rays and attached them to both hands.</span></span> <span data-ttu-id="8878f-173">Con este diseño simétrica, los usuarios que están familiarizados con MRP no necesitan aprender otro modelo de interacción para la manipulación y el momento que apunta al usar HoloLen 2 y viceversa.</span><span class="sxs-lookup"><span data-stu-id="8878f-173">With this symmetric design, users who are familiar with MRP won't need to learn another interaction model for far pointing and manipulation when they use HoloLen 2, and vice versa.</span></span>    

![](images/Symmetric-Design-For-Rays-720px.jpg)<br>

## <a name="instinctual-gestures"></a><span data-ttu-id="8878f-174">Gestos instinctual</span><span class="sxs-lookup"><span data-stu-id="8878f-174">Instinctual gestures</span></span>

![](images/Instinctual-Gestures-Far-720px.jpg)

## <a name="see-also"></a><span data-ttu-id="8878f-175">Vea también</span><span class="sxs-lookup"><span data-stu-id="8878f-175">See also</span></span>
* [<span data-ttu-id="8878f-176">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="8878f-176">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="8878f-177">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="8878f-177">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="8878f-178">Interacciones instintivas</span><span class="sxs-lookup"><span data-stu-id="8878f-178">Instinctual interactions</span></span>](interaction-fundamentals.md)

