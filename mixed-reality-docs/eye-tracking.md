---
title: Seguimiento de los ojos
description: HoloLens 2 ofrece un nuevo nivel de conocimiento del contexto y del comportamiento humano dentro de la experiencia holográfica al proporcionar a los desarrolladores la capacidad de usar información sobre lo que están mirando los usuarios.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Seguimiento ocular, realidad mixta, entrada, ojo y calibración
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441116"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="7f807-104">Seguimiento de los ojos en HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="7f807-104">Eye tracking on HoloLens 2</span></span>

![Demostración de seguimiento ocular en MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="7f807-106">HoloLens 2 ofrece un nuevo nivel de conocimiento del contexto y del comportamiento humano dentro de la experiencia holográfica al proporcionar a los desarrolladores la capacidad de usar información sobre lo que están mirando los usuarios.</span><span class="sxs-lookup"><span data-stu-id="7f807-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="7f807-107">En esta página se proporciona información general sobre esta nueva capacidad a los desarrolladores y diseñadores sobre cómo pueden beneficiarse del seguimiento ocular de varios casos de uso e instrucciones básicas para desarrolladores.</span><span class="sxs-lookup"><span data-stu-id="7f807-107">This page provides an overview of this new capability to developers and designers on how they can benefit from eye tracking for various use cases and basic developer guidance.</span></span> 


## <a name="calibration"></a><span data-ttu-id="7f807-108">Curva</span><span class="sxs-lookup"><span data-stu-id="7f807-108">Calibration</span></span> 
<span data-ttu-id="7f807-109">Para que el seguimiento de los ojos funcione con precisión, cada usuario tiene que pasar por una [calibración de usuario de seguimiento ocular](calibration.md) en la que el usuario tiene que mirar un conjunto de destinos holográficas.</span><span class="sxs-lookup"><span data-stu-id="7f807-109">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="7f807-110">Esto permite que el dispositivo ajuste el sistema para una experiencia de visualización más cómoda y de mayor calidad para el usuario y para garantizar un seguimiento de ojo preciso al mismo tiempo.</span><span class="sxs-lookup"><span data-stu-id="7f807-110">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="7f807-111">El seguimiento ocular debe funcionar para la mayoría de los usuarios, pero hay casos poco frecuentes en los que es posible que un usuario no pueda calibrarse correctamente.</span><span class="sxs-lookup"><span data-stu-id="7f807-111">Eye tracking should work for most users, but there are rare cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="7f807-112">Para obtener más información sobre la calibración y cómo garantizar una experiencia fluida, consulte nuestra página de [calibración de usuario de seguimiento ocular](calibration.md) .</span><span class="sxs-lookup"><span data-stu-id="7f807-112">To learn more about the calibration and about how to ensure a smooth experience, please check our [eye tracking user calibration](calibration.md) page.</span></span>


## <a name="device-support"></a><span data-ttu-id="7f807-113">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="7f807-113">Device support</span></span>
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="7f807-114"><strong>Ofrecen</strong></span><span class="sxs-lookup"><span data-stu-id="7f807-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="7f807-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1.ª generación)</strong></a></span><span class="sxs-lookup"><span data-stu-id="7f807-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="7f807-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="7f807-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="7f807-117"><a href="immersive-headset-hardware-details.md"><strong>Cascos envolventes</strong></a></span><span class="sxs-lookup"><span data-stu-id="7f807-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="7f807-118">Miras hacia abajo</span><span class="sxs-lookup"><span data-stu-id="7f807-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="7f807-119">✔️</span><span class="sxs-lookup"><span data-stu-id="7f807-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="7f807-120">Datos de seguimiento ocular disponibles</span><span class="sxs-lookup"><span data-stu-id="7f807-120">Available eye tracking data</span></span>
<span data-ttu-id="7f807-121">Antes de entrar en detalles sobre los casos de uso específicos de la entrada ocular y mirarnos, queremos señalar brevemente las funcionalidades que proporciona la [API de seguimiento](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) de la vista de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="7f807-121">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="7f807-122">Los desarrolladores obtienen acceso a un solo rayo de mira fijamente (miran el origen y la dirección) a aproximadamente _30 fps (30 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="7f807-122">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="7f807-123">Para obtener información más detallada sobre cómo obtener acceso a los datos de seguimiento de los ojos, consulte nuestras guías para desarrolladores sobre el uso de la mirada [en DirectX](gaze-in-directx.md) y la mirada a [la vista de Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="7f807-123">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="7f807-124">El ojo de miración predicho es aproximadamente de 1,5 grados en el ángulo visual alrededor del destino real (vea la ilustración siguiente).</span><span class="sxs-lookup"><span data-stu-id="7f807-124">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="7f807-125">A medida que se esperan ligeras imprecisiones, los desarrolladores deben planear algún margen alrededor de este valor límite inferior (por ejemplo, 2,0-3.0 grados pueden dar lugar a una experiencia mucho más cómoda).</span><span class="sxs-lookup"><span data-stu-id="7f807-125">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="7f807-126">Veremos cómo abordar la selección de destinos pequeños con más detalle a continuación.</span><span class="sxs-lookup"><span data-stu-id="7f807-126">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="7f807-127">Para que el seguimiento de los ojos funcione con precisión, cada usuario debe realizar una calibración de seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="7f807-127">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="7f807-128">![Tamaño de objetivo óptimo a una distancia de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="7f807-128">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="7f807-129">*Tamaño óptimo de destino a una distancia de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="7f807-129">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="7f807-130">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="7f807-130">Use cases</span></span>
<span data-ttu-id="7f807-131">El seguimiento de los ojos permite a las aplicaciones realizar un seguimiento de dónde mira el usuario en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="7f807-131">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="7f807-132">En los siguientes casos de uso se describen algunas interacciones que son posibles con el seguimiento ocular en HoloLens 2 en la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="7f807-132">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="7f807-133">Tenga en cuenta que estos casos de uso todavía no forman parte de la experiencia de Shell holográfica (es decir, la interfaz que ve al iniciar su HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="7f807-133">Please note that these use cases are not yet part of the Holographic Shell experience (i.e., the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="7f807-134">Puede probar algunas de ellas en el kit de [herramientas de realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) , que proporciona varios ejemplos interesantes y eficaces para usar el seguimiento ocular, como selecciones de destino compatibles con la vista rápida y sin esfuerzo, así como desplazarse automáticamente por el texto. en qué mira el usuario.</span><span class="sxs-lookup"><span data-stu-id="7f807-134">You can try some of them out in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="7f807-135">Intención del usuario</span><span class="sxs-lookup"><span data-stu-id="7f807-135">User intent</span></span>    
<span data-ttu-id="7f807-136">Información sobre dónde y qué mira un usuario proporciona un contexto eficaz **para otras entradas**, como voz, manos y controladores.</span><span class="sxs-lookup"><span data-stu-id="7f807-136">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="7f807-137">Esta información puede utilizarse para varias tareas.</span><span class="sxs-lookup"><span data-stu-id="7f807-137">This can be used for various tasks.</span></span>
<span data-ttu-id="7f807-138">Por ejemplo, esto puede variar de forma rápida y sin **esfuerzo a través de** la escena, simplemente mirando un holograma y diciendo *"Select"* (consulte también [mirarnos y confirmar](gaze-and-commit.md)) o diciendo *"Put this..."* y, a continuación, buscar el lugar en el que el usuario quiere colocar el holograma y decir *"... allí "* .</span><span class="sxs-lookup"><span data-stu-id="7f807-138">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="7f807-139">Puedes consultar varios ejemplos en [Mixed Reality Toolkit: Selección de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) y [Mixed Reality Toolkit: Posicionamiento de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="7f807-139">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="7f807-140">Además, un ejemplo de intención del usuario podría incluir el uso de información sobre lo que los usuarios ven para mejorar la interacción con agentes virtuales incorporados y hologramas interactivos.</span><span class="sxs-lookup"><span data-stu-id="7f807-140">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="7f807-141">Por ejemplo, los agentes virtuales pueden adaptar las opciones disponibles y su comportamiento en función del contenido que se vea actualmente.</span><span class="sxs-lookup"><span data-stu-id="7f807-141">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="7f807-142">Acciones implícitas</span><span class="sxs-lookup"><span data-stu-id="7f807-142">Implicit actions</span></span>
<span data-ttu-id="7f807-143">La categoría de acciones implícitas está estrechamente relacionada con la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="7f807-143">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="7f807-144">La idea es que los hologramas o los elementos de la interfaz de usuario reaccionan de una manera instinctual que puede que no se parezca incluso a la interacción del usuario con el sistema, sino que el sistema y el usuario estén sincronizados. Un ejemplo es el **desplazamiento automático basado en la mirada** , en el que el usuario puede leer un texto largo que inicia automáticamente el desplazamiento una vez que el usuario llega a la parte inferior del cuadro de texto para evitar que el usuario realice el flujo de lectura sin levantar un dedo.</span><span class="sxs-lookup"><span data-stu-id="7f807-144">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="7f807-145">Un aspecto clave de esto es que la velocidad de desplazamiento se adapta a la velocidad de lectura del usuario.</span><span class="sxs-lookup"><span data-stu-id="7f807-145">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="7f807-146">Otro ejemplo es el **zoom y la panorámica que se admiten,** donde el usuario puede sentir como sumergir exactamente en lo que se centra.</span><span class="sxs-lookup"><span data-stu-id="7f807-146">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="7f807-147">El zoom y el control de la velocidad de zoom se pueden controlar mediante la entrada de voz o a mano, lo que es importante para proporcionar al usuario la sensación de control mientras evita estar abrumado.</span><span class="sxs-lookup"><span data-stu-id="7f807-147">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="7f807-148">Hablaremos sobre estas consideraciones de diseño con más detalle a continuación.</span><span class="sxs-lookup"><span data-stu-id="7f807-148">We will talk about these design considerations in more detail below.</span></span> <span data-ttu-id="7f807-149">Una vez que se ha ampliado, el usuario puede seguir sin problemas, por ejemplo, en el transcurso de una calle para explorar su entorno con solo ver la mirada.</span><span class="sxs-lookup"><span data-stu-id="7f807-149">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="7f807-150">Puedes consultar ejemplos de demostración de estos tipos de interacciones en el ejemplo [Mixed Reality Toolkit - Navegación con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="7f807-150">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="7f807-151">A continuación, se indican algunos otros casos de uso para _acciones implícitas_:</span><span class="sxs-lookup"><span data-stu-id="7f807-151">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="7f807-152">**Notificaciones inteligentes:** ¿Alguna vez le molestan las notificaciones que se exponen en el lugar donde está buscando?</span><span class="sxs-lookup"><span data-stu-id="7f807-152">**Smart notifications:** Ever get annoyed by notifications popping up right where you are looking?</span></span> <span data-ttu-id="7f807-153">Teniendo en cuenta la atención de un usuario, puede mejorar esta experiencia mediante el desplazamiento de notificaciones desde donde el usuario está Gazing actualmente.</span><span class="sxs-lookup"><span data-stu-id="7f807-153">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="7f807-154">Esto limita las distracciones y las descarta automáticamente una vez que el usuario haya terminado de leer.</span><span class="sxs-lookup"><span data-stu-id="7f807-154">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="7f807-155">**Attentive hologramas:** Hologramas que reaccionan sutilmente cuando se miran.</span><span class="sxs-lookup"><span data-stu-id="7f807-155">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="7f807-156">Esto puede oscilar entre elementos de la interfaz de usuario ligeramente iluminados, una flor de floración lenta hasta un perro virtual que empieza a volver al usuario y wagging su cola.</span><span class="sxs-lookup"><span data-stu-id="7f807-156">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="7f807-157">Esta interacción podría proporcionar una sensación interesante de conectividad y satisfacción en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="7f807-157">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="7f807-158">Seguimiento de la atención</span><span class="sxs-lookup"><span data-stu-id="7f807-158">Attention tracking</span></span>   
<span data-ttu-id="7f807-159">Información sobre dónde o qué ven los usuarios es una herramienta enormemente eficaz para evaluar la facilidad de uso de los diseños y para identificar problemas en flujos de trabajo eficientes.</span><span class="sxs-lookup"><span data-stu-id="7f807-159">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="7f807-160">La visualización y el análisis de seguimiento ocular son una práctica común en diversas áreas de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="7f807-160">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="7f807-161">Con HoloLens 2, se proporciona una nueva dimensión para esta comprensión, ya que los hologramas 3D se pueden colocar en contextos reales y evaluarse como corresponda.</span><span class="sxs-lookup"><span data-stu-id="7f807-161">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="7f807-162">El [Kit de herramientas de realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) proporciona ejemplos básicos para registrar y cargar datos de seguimiento ocular y cómo visualizarlos.</span><span class="sxs-lookup"><span data-stu-id="7f807-162">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>

<span data-ttu-id="7f807-163">Algunas aplicaciones en esta área son las siguientes:</span><span class="sxs-lookup"><span data-stu-id="7f807-163">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="7f807-164">**Visualización de ojo remoto:** Visualice los colaboradores remotos que buscan para aumentar la comprensión compartida.</span><span class="sxs-lookup"><span data-stu-id="7f807-164">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to increase shared understanding.</span></span>
-   <span data-ttu-id="7f807-165">**Estudios de investigación de usuarios:** El seguimiento de atención puede ayudarle a comprender mejor cómo se perciben y se relacionan con nuestro entorno, lo que puede ayudar en mejores modelos de intención humana para más interacciones de equipos humanos instinctual.</span><span class="sxs-lookup"><span data-stu-id="7f807-165">**User research studies:** Attention tracking can help better understanding how we perceive and engage with our environment which may help in better human intent models for more instinctual human-computer-interactions.</span></span> 
-   <span data-ttu-id="7f807-166">**Entrenamiento:** Entrenamiento mejorado de los Novices al comprender mejor los patrones de búsqueda visual de los expertos y su coordinación ocular a mano para tareas complejas, como el análisis de datos médicos o la maquinaria operativa.</span><span class="sxs-lookup"><span data-stu-id="7f807-166">**Training:** Improved training of novices by better understanding experts' visual search patterns and their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="7f807-167">**Diseñe evaluaciones e investigación de mercado:** El seguimiento ocular es una herramienta común para la investigación de mercado al evaluar los diseños de productos y sitios Web.</span><span class="sxs-lookup"><span data-stu-id="7f807-167">**Design evaluations and market research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span> <span data-ttu-id="7f807-168">Con HoloLens 2, podemos ampliar esto a espacios 3D mediante la combinación de variantes de diseño de productos digitales con el entorno físico.</span><span class="sxs-lookup"><span data-stu-id="7f807-168">With HoloLens 2, we can extend this to 3D spaces by merging digital product design variants with the physical environment.</span></span> 

### <a name="additional-use-cases"></a><span data-ttu-id="7f807-169">Casos de uso adicionales</span><span class="sxs-lookup"><span data-stu-id="7f807-169">Additional use cases</span></span>
- <span data-ttu-id="7f807-170">**Juegos:** ¿Alguna vez quería tener superalimentación?</span><span class="sxs-lookup"><span data-stu-id="7f807-170">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="7f807-171">Esta es tu oportunidad.</span><span class="sxs-lookup"><span data-stu-id="7f807-171">Here's your chance!</span></span> <span data-ttu-id="7f807-172">Puede levitater los hologramas mediante la estrella.</span><span class="sxs-lookup"><span data-stu-id="7f807-172">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="7f807-173">Capte vigas láser de los ojos: pruébelos en [RoboRaid para HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span><span class="sxs-lookup"><span data-stu-id="7f807-173">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="7f807-174">Convierta los enemigos en piedra o inmovilice.</span><span class="sxs-lookup"><span data-stu-id="7f807-174">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="7f807-175">Usa tu visión de rayos X para explorar edificios.</span><span class="sxs-lookup"><span data-stu-id="7f807-175">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="7f807-176">El límite es tu imaginación.</span><span class="sxs-lookup"><span data-stu-id="7f807-176">Your imagination is the limit!</span></span>
<span data-ttu-id="7f807-177">Tenga cuidado de no abrumar al usuario a pesar de ello, eche un vistazo a las [directrices de diseño de entrada basadas en el ojo](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="7f807-177">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="7f807-178">**Avatares expresivos:** El seguimiento ocular ayuda en avatares 3D más expresivos mediante el uso de datos de seguimiento de ojos en directo para animar los ojos del Avatar que indican lo que el usuario está mirando.</span><span class="sxs-lookup"><span data-stu-id="7f807-178">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="7f807-179">**Entrada de texto:** El seguimiento ocular se puede usar como alternativa a la entrada de texto de bajo esfuerzo, especialmente cuando la voz o las manos no son prácticas de usar.</span><span class="sxs-lookup"><span data-stu-id="7f807-179">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="7f807-180">Uso de la mirada a la interacción</span><span class="sxs-lookup"><span data-stu-id="7f807-180">Using eye-gaze for interaction</span></span>
<span data-ttu-id="7f807-181">Crear una interacción que aproveche los objetivos de vista rápida en movimiento puede ser un reto.</span><span class="sxs-lookup"><span data-stu-id="7f807-181">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="7f807-182">Por un lado, los ojos se mueven tan rápido que debe tener cuidado al usar la entrada mirada, ya que, de lo contrario, el usuario puede encontrar la experiencia abrumadora o distraer.</span><span class="sxs-lookup"><span data-stu-id="7f807-182">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise user may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="7f807-183">Por otro lado, también puede crear experiencias realmente mágicas que impedirán a los usuarios.</span><span class="sxs-lookup"><span data-stu-id="7f807-183">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="7f807-184">Para ayudarle, eche un vistazo a nuestra información general sobre las ventajas principales, los desafíos y las recomendaciones de diseño para [la interacción](eye-gaze-interaction.md).</span><span class="sxs-lookup"><span data-stu-id="7f807-184">To help you, check out our overview of key advantages, challenges and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="7f807-185">Guía para desarrolladores: ¿Qué ocurre si el seguimiento ocular no está disponible?</span><span class="sxs-lookup"><span data-stu-id="7f807-185">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="7f807-186">Puede haber situaciones en las que la aplicación no recibirá ningún dato de seguimiento ocular debido a diversas razones, entre las que se incluyen las siguientes:</span><span class="sxs-lookup"><span data-stu-id="7f807-186">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="7f807-187">El usuario omitió la calibración del seguimiento de ojo.</span><span class="sxs-lookup"><span data-stu-id="7f807-187">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="7f807-188">El usuario ha calibrado, pero decidió no conceder permiso a la aplicación para que use los datos de seguimiento ocular.</span><span class="sxs-lookup"><span data-stu-id="7f807-188">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="7f807-189">El usuario tiene anteojos únicos o alguna condición de ojo que el sistema todavía no admite.</span><span class="sxs-lookup"><span data-stu-id="7f807-189">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="7f807-190">Factores externos que impiden el seguimiento de ojos fiables, como manchas en el parasol o anteojos de HoloLens, luz solar directa y oclusión, debido al pelo en la parte delantera de los ojos.</span><span class="sxs-lookup"><span data-stu-id="7f807-190">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="7f807-191">Como desarrollador de aplicaciones, esto significa que debe tener en cuenta la compatibilidad con los usuarios para los que es posible que los datos de seguimiento ocular no estén disponibles.</span><span class="sxs-lookup"><span data-stu-id="7f807-191">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="7f807-192">A continuación se explica en primer lugar cómo detectar si el seguimiento ocular está disponible y cómo solucionarlo cuando no está disponible para aplicaciones diferentes.</span><span class="sxs-lookup"><span data-stu-id="7f807-192">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="7f807-193">1. Cómo detectar que el seguimiento ocular está disponible</span><span class="sxs-lookup"><span data-stu-id="7f807-193">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="7f807-194">Hay algunas comprobaciones para determinar si los datos de seguimiento ocular están disponibles.</span><span class="sxs-lookup"><span data-stu-id="7f807-194">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="7f807-195">Compruebe si...</span><span class="sxs-lookup"><span data-stu-id="7f807-195">Check whether...</span></span>
* <span data-ttu-id="7f807-196">... el sistema admite el seguimiento ocular en absoluto.</span><span class="sxs-lookup"><span data-stu-id="7f807-196">... the system supports eye tracking at all.</span></span> <span data-ttu-id="7f807-197">Llame al *método*siguiente: [Windows. percepción. people. EyesPose. IsSupported ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="7f807-197">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="7f807-198">... se calibra el usuario.</span><span class="sxs-lookup"><span data-stu-id="7f807-198">... the user is calibrated.</span></span> <span data-ttu-id="7f807-199">Llame a la *propiedad*siguiente: [Windows. imception. people. EyesPose. IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="7f807-199">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="7f807-200">... el usuario ha dado permiso a la aplicación para usar los datos de seguimiento ocular: recuperar el _' GazeInputAccessStatus '_ actual.</span><span class="sxs-lookup"><span data-stu-id="7f807-200">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="7f807-201">Un ejemplo de cómo hacerlo se explica cómo solicitar el [acceso a la entrada de mirada](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="7f807-201">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="7f807-202">Además, puede que desee comprobar que los datos de seguimiento ocular no están obsoletos agregando un tiempo de espera entre las actualizaciones de datos de seguimiento de ojos recibidos y, de lo contrario, reserva a Head-mira como se describe a continuación.</span><span class="sxs-lookup"><span data-stu-id="7f807-202">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="7f807-203">Como se describió anteriormente, existen varios motivos por los que es posible que los datos de seguimiento ocular no estén disponibles.</span><span class="sxs-lookup"><span data-stu-id="7f807-203">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="7f807-204">Aunque algunos usuarios pueden haber decidido revocar el acceso a sus datos de seguimiento ocular y son correctos con la desventaja de una experiencia de usuario inferior a la privacidad de no proporcionar acceso a los datos de seguimiento ocular, en algunos casos esto puede ser involuntaria.</span><span class="sxs-lookup"><span data-stu-id="7f807-204">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="7f807-205">Por lo tanto, si la aplicación usa el seguimiento ocular y esta es una parte importante de la experiencia, recomendamos que se comunique claramente al usuario.</span><span class="sxs-lookup"><span data-stu-id="7f807-205">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="7f807-206">Informar a los usuarios de por qué el seguimiento ocular es fundamental para su aplicación (quizás incluso mostrar algunas características mejoradas) para experimentar todo el potencial de su aplicación puede ayudar al usuario a comprender mejor lo que están ofreciendo.</span><span class="sxs-lookup"><span data-stu-id="7f807-206">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="7f807-207">Ayudar al usuario a identificar por qué el seguimiento ocular puede no funcionar (en función de las comprobaciones anteriores) y ofrecer algunas sugerencias para solucionar rápidamente posibles problemas.</span><span class="sxs-lookup"><span data-stu-id="7f807-207">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="7f807-208">Por ejemplo, si puede detectar que el sistema admite el seguimiento ocular, el usuario está calibrado e incluso ha dado su permiso, pero no se reciben datos de seguimiento ocular, puede que esto señale a otros problemas, como manchas o ojos que se ocluidos.</span><span class="sxs-lookup"><span data-stu-id="7f807-208">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="7f807-209">No obstante, tenga en cuenta que hay casos poco frecuentes de usuarios para los que es posible que el seguimiento ocular simplemente no funcione.</span><span class="sxs-lookup"><span data-stu-id="7f807-209">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="7f807-210">Por lo tanto, sea respetuoso de eso permitiendo descartar o incluso deshabilitar recordatorios para habilitar el seguimiento ocular en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="7f807-210">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="7f807-211">2. reserva para aplicaciones con miras ocular como puntero de entrada principal</span><span class="sxs-lookup"><span data-stu-id="7f807-211">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="7f807-212">Si la aplicación usa la vista de puntero para seleccionar rápidamente los hologramas en toda la escena, aunque los datos de seguimiento ocular no están disponibles, se recomienda revertir al encabezado y empezar a mostrar el cursor de miras hacia abajo.</span><span class="sxs-lookup"><span data-stu-id="7f807-212">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="7f807-213">Se recomienda utilizar un tiempo de espera (por ejemplo, 500 – 1500 MS) para determinar si se debe cambiar o no.</span><span class="sxs-lookup"><span data-stu-id="7f807-213">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="7f807-214">Esto es para evitar que se extraiga un cursor cada vez que el sistema pierda el seguimiento debido a movimientos de ojos o guiños y parpadeos.</span><span class="sxs-lookup"><span data-stu-id="7f807-214">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="7f807-215">Si es un desarrollador de Unity, la reserva automática para la cabeza de mira ya está controlada en el kit de herramientas de realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="7f807-215">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="7f807-216">Si es un desarrollador de DirectX, debe administrar este conmutador usted mismo.</span><span class="sxs-lookup"><span data-stu-id="7f807-216">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="7f807-217">3. reserva para otras aplicaciones específicas del seguimiento ocular</span><span class="sxs-lookup"><span data-stu-id="7f807-217">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="7f807-218">La aplicación puede usar miradamente en una forma única que se adapte específicamente a los ojos; por ejemplo, para animar los ojos de un avatar o para mapas térmicosr la atención basada en el ojo con información precisa sobre la atención visual.</span><span class="sxs-lookup"><span data-stu-id="7f807-218">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="7f807-219">En este caso, no hay ninguna reserva clara.</span><span class="sxs-lookup"><span data-stu-id="7f807-219">In this case, there is no clear fallback.</span></span> <span data-ttu-id="7f807-220">Si el seguimiento ocular no está disponible, es posible que estas funcionalidades simplemente deban deshabilitarse.</span><span class="sxs-lookup"><span data-stu-id="7f807-220">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span>
<span data-ttu-id="7f807-221">De nuevo, se recomienda comunicar esto al usuario que puede no ser consciente de que la funcionalidad no funciona.</span><span class="sxs-lookup"><span data-stu-id="7f807-221">Again, we recommend to clearly communicate this to the user who may be unaware that the capability is not working.</span></span>

<br>

<span data-ttu-id="7f807-222">Esperamos que esta página le haya proporcionado una buena introducción para empezar a comprender el papel del seguimiento ocular y la entrada de mirada para HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="7f807-222">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="7f807-223">Para empezar a desarrollar, eche un vistazo a nuestra información sobre el papel de la mirada [para interactuar con los hologramas](eye-gaze-interaction.md), [mirando en Unity](https://aka.ms/mrtk-eyes) y miramos [a la vista en DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="7f807-223">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="7f807-224">Consulta también</span><span class="sxs-lookup"><span data-stu-id="7f807-224">See also</span></span>
* [<span data-ttu-id="7f807-225">Calibración</span><span class="sxs-lookup"><span data-stu-id="7f807-225">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="7f807-226">Comodidad</span><span class="sxs-lookup"><span data-stu-id="7f807-226">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="7f807-227">Interacción con miras oculares</span><span class="sxs-lookup"><span data-stu-id="7f807-227">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="7f807-228">Miras a la vista en DirectX</span><span class="sxs-lookup"><span data-stu-id="7f807-228">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="7f807-229">Mirada a la vista de Unity (kit de herramientas de realidad mixta)</span><span class="sxs-lookup"><span data-stu-id="7f807-229">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="7f807-230">Miras y confirmaciones</span><span class="sxs-lookup"><span data-stu-id="7f807-230">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="7f807-231">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="7f807-231">Voice input</span></span>](voice-design.md)


