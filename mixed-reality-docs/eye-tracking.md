---
title: Miras hacia abajo
description: HoloLens 2 permite un nuevo nivel de contexto y comprensión humana dentro de la experiencia holográfica, ya que proporciona a los desarrolladores la capacidad de usar información sobre lo que los usuarios ven.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Seguimiento ocular, realidad mixta, entrada, ojo
ms.openlocfilehash: 6c51e1cdc2057142f47b6f96e8a1f1aec0bbcc17
ms.sourcegitcommit: 3b32339c5d5c79eaecd84ed27254a8f4321731f1
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/27/2019
ms.locfileid: "70047106"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="088c7-104">Miras a la vista de HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="088c7-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="088c7-105">HoloLens 2 permite un nuevo nivel de contexto y comprensión humana dentro de la experiencia holográfica, ya que proporciona a los desarrolladores la capacidad de usar información sobre lo que los usuarios ven.</span><span class="sxs-lookup"><span data-stu-id="088c7-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="088c7-106">En esta página se indica a los desarrolladores cómo pueden beneficiarse del seguimiento ocular de varios casos de uso, así como qué buscar al diseñar interfaces de usuario basadas en el ojo.</span><span class="sxs-lookup"><span data-stu-id="088c7-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="088c7-107">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="088c7-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="088c7-108"><strong>Característica</strong></span><span class="sxs-lookup"><span data-stu-id="088c7-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="088c7-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1.ª generación)</strong></a></span><span class="sxs-lookup"><span data-stu-id="088c7-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="088c7-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="088c7-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="088c7-111"><a href="immersive-headset-hardware-details.md"><strong>Cascos envolventes</strong></a></span><span class="sxs-lookup"><span data-stu-id="088c7-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="088c7-112">Miras hacia abajo</span><span class="sxs-lookup"><span data-stu-id="088c7-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="088c7-113">❌</span><span class="sxs-lookup"><span data-stu-id="088c7-113">❌</span></span></td>
     <td><span data-ttu-id="088c7-114">✔️</span><span class="sxs-lookup"><span data-stu-id="088c7-114">✔️</span></span></td>
     <td><span data-ttu-id="088c7-115">❌</span><span class="sxs-lookup"><span data-stu-id="088c7-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="088c7-116">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="088c7-116">Use cases</span></span>
<span data-ttu-id="088c7-117">El seguimiento de los ojos permite a las aplicaciones realizar un seguimiento de dónde mira el usuario en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="088c7-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="088c7-118">En los siguientes casos de uso se describen algunas interacciones que son posibles con el seguimiento ocular en la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="088c7-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="088c7-119">Tenga en cuenta que el [Kit de herramientas de la realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) es útil para proporcionar varios ejemplos interesantes y eficaces para usar el seguimiento ocular, como selecciones de destino compatibles con la vista rápida y sin esfuerzo, así como desplazarse automáticamente por el texto basado en el aspecto del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="088c7-120">Intención del usuario</span><span class="sxs-lookup"><span data-stu-id="088c7-120">User intent</span></span>    
<span data-ttu-id="088c7-121">Información sobre dónde y qué mira un usuario proporciona un contexto eficaz **para otras entradas**, como voz, manos y controladores.</span><span class="sxs-lookup"><span data-stu-id="088c7-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="088c7-122">Esta información puede utilizarse para varias tareas.</span><span class="sxs-lookup"><span data-stu-id="088c7-122">This can be used for various tasks.</span></span>
<span data-ttu-id="088c7-123">Por ejemplo, esto puede variar de forma rápida y sin esfuerzo a través de la escena, simplemente mirando un holograma y diciendo "Select" (consulte también la [cabecera y la confirmación](gaze-and-commit.md)) o diciendo "Put this..." y, a continuación, buscando dónde desea colocar el usuario el holograma y el "... allí ".</span><span class="sxs-lookup"><span data-stu-id="088c7-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where the user wants to place the hologram and say "...there".</span></span> <span data-ttu-id="088c7-124">Puedes consultar varios ejemplos en [Mixed Reality Toolkit: Selección de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) y [Mixed Reality Toolkit: Posicionamiento de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="088c7-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="088c7-125">Además, un ejemplo de intención del usuario podría incluir el uso de información sobre lo que los usuarios ven para mejorar la interacción con agentes virtuales incorporados y hologramas interactivos.</span><span class="sxs-lookup"><span data-stu-id="088c7-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="088c7-126">Por ejemplo, los agentes virtuales pueden adaptar las opciones disponibles y su comportamiento en función del contenido que se vea actualmente.</span><span class="sxs-lookup"><span data-stu-id="088c7-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="088c7-127">Acciones implícitas</span><span class="sxs-lookup"><span data-stu-id="088c7-127">Implicit actions</span></span>
<span data-ttu-id="088c7-128">La categoría de acciones implícitas está estrechamente relacionada con la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="088c7-129">La idea es que los hologramas o los elementos de la interfaz de usuario reaccionan de una manera algo instinctual que puede que no parezca incluso que el usuario está interactuando con el sistema, sino que el sistema y el usuario están sincronizados. Un ejemplo es el **desplazamiento automático basado en la mirada** en el que el usuario lee el texto a medida que el texto continúa desplazando o fluyen en sincronización con la vista del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user reads text as the text continues to scroll or flow in sync with the user's gaze.</span></span> <span data-ttu-id="088c7-130">Un aspecto clave de esto es que la velocidad de desplazamiento se adapta a la velocidad de lectura del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-130">A key aspect of this is that scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="088c7-131">Otro ejemplo es el **zoom y la panorámica** que se admiten, donde el usuario puede sentir como sumergir exactamente en lo que se centra.</span><span class="sxs-lookup"><span data-stu-id="088c7-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="088c7-132">El zoom y el control de la velocidad de zoom se pueden controlar mediante la entrada de voz o a mano, lo que es importante para proporcionar al usuario la sensación de control mientras evita estar abrumado.</span><span class="sxs-lookup"><span data-stu-id="088c7-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="088c7-133">Hablaremos sobre estas instrucciones de diseño con más detalle a continuación.</span><span class="sxs-lookup"><span data-stu-id="088c7-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="088c7-134">Una vez que se ha ampliado, el usuario puede seguir sin problemas, por ejemplo, en el transcurso de una calle para explorar su entorno con solo ver la mirada.</span><span class="sxs-lookup"><span data-stu-id="088c7-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="088c7-135">Puedes consultar ejemplos de demostración de estos tipos de interacciones en el ejemplo [Mixed Reality Toolkit - Navegación con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="088c7-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="088c7-136">Los casos de uso adicionales para _acciones implícitas_ pueden incluir:</span><span class="sxs-lookup"><span data-stu-id="088c7-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="088c7-137">**Notificaciones inteligentes:** ¿Te molesta que aparezcan notificaciones justo donde estabas mirando?</span><span class="sxs-lookup"><span data-stu-id="088c7-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="088c7-138">Teniendo en cuenta la atención de un usuario, puede mejorar esta experiencia mediante el desplazamiento de notificaciones desde donde el usuario está Gazing actualmente.</span><span class="sxs-lookup"><span data-stu-id="088c7-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="088c7-139">Esto limita las distracciones y las descarta automáticamente una vez que el usuario haya terminado de leer.</span><span class="sxs-lookup"><span data-stu-id="088c7-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="088c7-140">**Hologramas atentos:** Hologramas que reaccionan sutilmente cuando se miran.</span><span class="sxs-lookup"><span data-stu-id="088c7-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="088c7-141">Esto puede abarcar desde elementos de interfaz de usuario ligeramente iluminados hasta una flor de floración lenta hasta una mascota virtual que empieza a volver al usuario o intenta evitar la mirada al usuario después de una estrella prolongada.</span><span class="sxs-lookup"><span data-stu-id="088c7-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="088c7-142">Esta interacción podría proporcionar una sensación interesante de conectividad y satisfacción en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="088c7-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="088c7-143">Seguimiento de la atención</span><span class="sxs-lookup"><span data-stu-id="088c7-143">Attention tracking</span></span>   
<span data-ttu-id="088c7-144">Información sobre dónde o qué ven los usuarios es una herramienta enormemente eficaz para evaluar la facilidad de uso de los diseños y para identificar problemas en flujos de trabajo eficientes.</span><span class="sxs-lookup"><span data-stu-id="088c7-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="088c7-145">La visualización y el análisis de seguimiento ocular son una práctica común en diversas áreas de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="088c7-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="088c7-146">Con HoloLens 2, se proporciona una nueva dimensión para esta comprensión, ya que los hologramas 3D se pueden colocar en contextos reales y evaluarse como corresponda.</span><span class="sxs-lookup"><span data-stu-id="088c7-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="088c7-147">El [Kit de herramientas de realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) proporciona ejemplos básicos para registrar y cargar datos de seguimiento ocular y cómo visualizarlos.</span><span class="sxs-lookup"><span data-stu-id="088c7-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="088c7-148">Otras aplicaciones de esta área pueden incluir:</span><span class="sxs-lookup"><span data-stu-id="088c7-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="088c7-149">**Visualización de ojo remoto:** Visualice los colaboradores remotos que buscan para asegurarse de que las instrucciones se comprenden y se siguen correctamente.</span><span class="sxs-lookup"><span data-stu-id="088c7-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="088c7-150">**Estudios de investigación con usuarios:** El seguimiento de atención se puede usar para explorar la forma en que los usuarios principiantes frente a expertos analizan visualmente el contenido o cómo su coordinación ocular para tareas complejas, como el análisis de datos médicos o la maquinaria operativa.</span><span class="sxs-lookup"><span data-stu-id="088c7-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="088c7-151">**Entrenamiento de simulaciones y supervisión del rendimiento:** Practica y optimiza la ejecución de tareas mediante una identificación de cuellos de botella más eficaz en el flujo de ejecución.</span><span class="sxs-lookup"><span data-stu-id="088c7-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="088c7-152">**Evaluaciones de diseño, publicidad y estudios de mercado:** El seguimiento ocular es una herramienta común para la investigación de mercado al evaluar los diseños de productos y sitios Web.</span><span class="sxs-lookup"><span data-stu-id="088c7-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="088c7-153">Casos de uso adicionales</span><span class="sxs-lookup"><span data-stu-id="088c7-153">Additional use cases</span></span>
- <span data-ttu-id="088c7-154">**Videojuegos:** ¿Alguna vez has deseado tener superpoderes?</span><span class="sxs-lookup"><span data-stu-id="088c7-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="088c7-155">Esta es tu oportunidad.</span><span class="sxs-lookup"><span data-stu-id="088c7-155">Here's your chance!</span></span> <span data-ttu-id="088c7-156">Puede levitater los hologramas mediante la estrella.</span><span class="sxs-lookup"><span data-stu-id="088c7-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="088c7-157">Dispara rayos láser con los ojos.</span><span class="sxs-lookup"><span data-stu-id="088c7-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="088c7-158">Convierta los enemigos en piedra o inmovilice.</span><span class="sxs-lookup"><span data-stu-id="088c7-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="088c7-159">Usa tu visión de rayos X para explorar edificios.</span><span class="sxs-lookup"><span data-stu-id="088c7-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="088c7-160">El límite es tu imaginación.</span><span class="sxs-lookup"><span data-stu-id="088c7-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="088c7-161">**Avatares expresivos:** El seguimiento ocular ayuda en avatares 3D más expresivos mediante el uso de datos de seguimiento de ojos en directo para animar los ojos del Avatar que indican lo que el usuario está mirando.</span><span class="sxs-lookup"><span data-stu-id="088c7-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> <span data-ttu-id="088c7-162">También agrega más expresividad agregando parpadeos.</span><span class="sxs-lookup"><span data-stu-id="088c7-162">It also adds more expressiveness by adding blinks.</span></span> 

- <span data-ttu-id="088c7-163">**Entrada de texto:** El seguimiento ocular se puede usar como alternativa a la entrada de texto de bajo esfuerzo, especialmente cuando la voz o las manos no son prácticas de usar.</span><span class="sxs-lookup"><span data-stu-id="088c7-163">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="088c7-164">API de seguimiento de los ojos</span><span class="sxs-lookup"><span data-stu-id="088c7-164">Eye tracking API</span></span>
<span data-ttu-id="088c7-165">Antes de entrar en detalles sobre las directrices de diseño específicas para la interacción ocular, queremos señalar brevemente las funcionalidades que proporciona la API de seguimiento de la vista HoloLens 2 para los desarrolladores.</span><span class="sxs-lookup"><span data-stu-id="088c7-165">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 Eye Tracker API provides to developers.</span></span> <span data-ttu-id="088c7-166">Proporciona un único origen de miración y una dirección, que proporciona datos de aproximadamente _30 Hz_.</span><span class="sxs-lookup"><span data-stu-id="088c7-166">It provides a single eye-gaze--gaze origin and direction--providing data at approximately _30 Hz_.</span></span> 

<span data-ttu-id="088c7-167">La vista de predicción mira en la CA.</span><span class="sxs-lookup"><span data-stu-id="088c7-167">The predicted eye-gaze lies within ca.</span></span> <span data-ttu-id="088c7-168">1,0-1,5 grados en el ángulo visual alrededor del destino real.</span><span class="sxs-lookup"><span data-stu-id="088c7-168">1.0 - 1.5 degrees in visual angle around the actual target.</span></span> <span data-ttu-id="088c7-169">Caben esperar pequeñas imprecisiones, por lo que debe dejarse algo de margen para este valor límite inferior.</span><span class="sxs-lookup"><span data-stu-id="088c7-169">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="088c7-170">Más adelante se tratará este aspecto en detalle.</span><span class="sxs-lookup"><span data-stu-id="088c7-170">We will discuss this more below.</span></span> <span data-ttu-id="088c7-171">Para que el seguimiento de los ojos funcione con precisión, cada usuario debe realizar una calibración de seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="088c7-171">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="088c7-172">![Tamaño de objetivo óptimo a una distancia de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="088c7-172">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="088c7-173">*Tamaño óptimo de destino a una distancia de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="088c7-173">*Optimal target size at a 2-meter distance*</span></span>
<br>
<br>
<span data-ttu-id="088c7-174">La [API de seguimiento ocular](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) es accesible a través de: ' Windows. Perception. people. EyesPose '.</span><span class="sxs-lookup"><span data-stu-id="088c7-174">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: \`Windows.Perception.People.EyesPose'.</span></span> 

## <a name="calibration"></a><span data-ttu-id="088c7-175">Curva</span><span class="sxs-lookup"><span data-stu-id="088c7-175">Calibration</span></span> 
<span data-ttu-id="088c7-176">Para que el seguimiento de los ojos funcione con precisión, cada usuario debe realizar una calibración de seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="088c7-176">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> <span data-ttu-id="088c7-177">En HoloLens 2, se solicita al usuario que calibre los objetos visuales durante la configuración del dispositivo, mirando el conjunto de destinos de fijación.</span><span class="sxs-lookup"><span data-stu-id="088c7-177">On HoloLens 2, the user is prompted to calibrate visuals during device setup, by looking at the set of fixation targets.</span></span> <span data-ttu-id="088c7-178">Esto permite que el dispositivo ajuste el dispositivo para una experiencia de visualización cómoda y de calidad para el usuario y garantizar un seguimiento de ojo preciso al mismo tiempo.</span><span class="sxs-lookup"><span data-stu-id="088c7-178">This allows the device to adjust the device for a comfortable and quality viewing experience for the user and ensure accurate eye tracking at the same time.</span></span>  <span data-ttu-id="088c7-179">La calibración debe funcionar para la mayoría de los usuarios, pero hay casos en los que es posible que el usuario no pueda calibrarse correctamente.</span><span class="sxs-lookup"><span data-stu-id="088c7-179">Calibration should work for most of the users, but there are cases in which user might be unable to calibrate successfully.</span></span>  <span data-ttu-id="088c7-180">Para obtener más información acerca de la calibración, Compruebe la [calibración](https://docs.microsoft.com/en-us/windows/mixed-reality/calibration).</span><span class="sxs-lookup"><span data-stu-id="088c7-180">To learn more about the calibration, please check [Calibration](https://docs.microsoft.com/en-us/windows/mixed-reality/calibration).</span></span>

## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="088c7-181">Guías de diseño ocular</span><span class="sxs-lookup"><span data-stu-id="088c7-181">Eye-gaze design guidelines</span></span>
<span data-ttu-id="088c7-182">Crear una interacción que aproveche los objetivos de vista rápida en movimiento puede ser un reto.</span><span class="sxs-lookup"><span data-stu-id="088c7-182">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="088c7-183">En esta sección, se resumen las principales ventajas y los desafíos que se deben tener en cuenta al diseñar la aplicación.</span><span class="sxs-lookup"><span data-stu-id="088c7-183">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="088c7-184">Ventajas de la entrada ocular</span><span class="sxs-lookup"><span data-stu-id="088c7-184">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="088c7-185">**Señalización a alta velocidad.**</span><span class="sxs-lookup"><span data-stu-id="088c7-185">**High speed pointing.**</span></span> <span data-ttu-id="088c7-186">El músculo ocular es el músculo de reacción más rápido en el cuerpo humano.</span><span class="sxs-lookup"><span data-stu-id="088c7-186">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="088c7-187">**Poco esfuerzo.**</span><span class="sxs-lookup"><span data-stu-id="088c7-187">**Low effort.**</span></span> <span data-ttu-id="088c7-188">Prácticamente no se necesita ningún movimiento físico.</span><span class="sxs-lookup"><span data-stu-id="088c7-188">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="088c7-189">**Implícito.**</span><span class="sxs-lookup"><span data-stu-id="088c7-189">**Implicitness.**</span></span> <span data-ttu-id="088c7-190">A menudo lo describen los usuarios como "atención", la información acerca de los movimientos oculares de un usuario permite que el sistema sepa cuál es el objetivo que el usuario tiene previsto interactuar.</span><span class="sxs-lookup"><span data-stu-id="088c7-190">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="088c7-191">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="088c7-191">**Alternative input channel.**</span></span> <span data-ttu-id="088c7-192">La mirada a la mano puede proporcionar una gran cantidad de datos de soporte técnico para la entrada de voz y entrega en años de experiencia de los usuarios en función de su coordinación ocular a mano.</span><span class="sxs-lookup"><span data-stu-id="088c7-192">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="088c7-193">**Atención visual.**</span><span class="sxs-lookup"><span data-stu-id="088c7-193">**Visual attention.**</span></span> <span data-ttu-id="088c7-194">Otra ventaja importante es la posibilidad de deducir lo que un usuario está pagando con atención.</span><span class="sxs-lookup"><span data-stu-id="088c7-194">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="088c7-195">Esto puede ayudar en diversas áreas de la aplicación que abarcan de una evaluación más eficaz de los distintos diseños para ayudar a las interfaces de usuario más inteligentes y a las guías sociales mejoradas para la comunicación remota.</span><span class="sxs-lookup"><span data-stu-id="088c7-195">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="088c7-196">En pocas palabras, el uso de la mirada a la entrada ofrece una señal contextual rápida y sin esfuerzo.</span><span class="sxs-lookup"><span data-stu-id="088c7-196">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="088c7-197">Esto es especialmente eficaz cuando se combina con otras entradas como la *voz* y la entrada *manual* para confirmar la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-197">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="088c7-198">Desafíos de la mirada: la entrada</span><span class="sxs-lookup"><span data-stu-id="088c7-198">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="088c7-199">Con una gran cantidad de energía, supone una gran responsabilidad.</span><span class="sxs-lookup"><span data-stu-id="088c7-199">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="088c7-200">A pesar de la mirada, se puede usar para crear experiencias de usuario satisfactorias, lo que hace que se sienta como un Superhero, también es importante saber lo que no es adecuado para tener en cuenta adecuadamente esto.</span><span class="sxs-lookup"><span data-stu-id="088c7-200">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="088c7-201">A continuación se explican algunos de los *desafíos* que se deben tener en cuenta, así como cómo abordarlos al trabajar con la entrada de mirada:</span><span class="sxs-lookup"><span data-stu-id="088c7-201">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="088c7-202">**La mirada está "Always On"** En el momento en que se abre el Lids, los ojos comienzan fixating sobre las cosas en el entorno.</span><span class="sxs-lookup"><span data-stu-id="088c7-202">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="088c7-203">Al reaccionar a cada una de las búsquedas que se realizan y se emiten acciones accidentalmente porque se ha buscado algo demasiado tiempo, se producirá una experiencia incumplida.</span><span class="sxs-lookup"><span data-stu-id="088c7-203">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="088c7-204">Por lo tanto, se recomienda combinar ojo con un *comando de voz*, un gesto de *mano*, un clic de *botón* o una permanencia extendida para desencadenar la selección de un destino.</span><span class="sxs-lookup"><span data-stu-id="088c7-204">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="088c7-205">Esta solución también permite un modo en el que el usuario puede mirar libremente sin saturarse mediante la activación involuntaria de algo.</span><span class="sxs-lookup"><span data-stu-id="088c7-205">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="088c7-206">Este problema también se debe tener en cuenta a la hora de diseñar comentarios visuales y acústicos cuando solo se examina un objetivo.</span><span class="sxs-lookup"><span data-stu-id="088c7-206">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="088c7-207">No debe sobrecargarse al usuario con efectos emergentes inmediatos o sonidos al pasar sobre los elementos.</span><span class="sxs-lookup"><span data-stu-id="088c7-207">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="088c7-208">El detalle es clave.</span><span class="sxs-lookup"><span data-stu-id="088c7-208">Subtlety is key.</span></span> <span data-ttu-id="088c7-209">Más adelante, en las recomendaciones de diseño, se describen algunos de los procedimientos recomendados para esto.</span><span class="sxs-lookup"><span data-stu-id="088c7-209">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="088c7-210">**Observación frente a control** Imagine que desea enderezar con precisión una fotografía en la pared.</span><span class="sxs-lookup"><span data-stu-id="088c7-210">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="088c7-211">Miras los bordes y la zona circundante para ver si está bien alineada.</span><span class="sxs-lookup"><span data-stu-id="088c7-211">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="088c7-212">Ahora Imagine cómo lo haría si quiere usar el ojo de la mirada como entrada para trasladar la imagen.</span><span class="sxs-lookup"><span data-stu-id="088c7-212">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="088c7-213">Difícil, ¿verdad?</span><span class="sxs-lookup"><span data-stu-id="088c7-213">Difficult, isn't it?</span></span> <span data-ttu-id="088c7-214">Esto describe el doble rol de ojo y mira si es necesario para la entrada y el control.</span><span class="sxs-lookup"><span data-stu-id="088c7-214">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="088c7-215">**Salir antes de hacer clic:** En el caso de las selecciones de destino rápido, la investigación ha demostrado que el ojo de un usuario puede continuar antes de concluir un clic manual (por ejemplo, un airtap).</span><span class="sxs-lookup"><span data-stu-id="088c7-215">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="088c7-216">Por lo tanto, se debe prestar especial atención a la sincronización de la señal de mirada rápida con una entrada de control más lenta (por ejemplo, voz, manos, controlador).</span><span class="sxs-lookup"><span data-stu-id="088c7-216">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="088c7-217">**Objetivos pequeños:** ¿Sabe que se siente al intentar leer texto que es simplemente un poco pequeño para leerlo de forma cómoda?</span><span class="sxs-lookup"><span data-stu-id="088c7-217">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="088c7-218">Esta limitación de los ojos puede hacer que se sienta cansado y se haya gastado porque intenta reajustar los ojos para centrarse mejor.</span><span class="sxs-lookup"><span data-stu-id="088c7-218">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="088c7-219">Se trata de una sensación que podría invocar a los usuarios al obligarles a seleccionar destinos que son demasiado pequeños en la aplicación mediante el establecimiento de destinos de la vista.</span><span class="sxs-lookup"><span data-stu-id="088c7-219">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="088c7-220">Al diseñar la aplicación, para crear una experiencia agradable y cómoda para los usuarios, se recomienda que los objetivos sean al menos de 2° en ángulo visual, o preferiblemente mayores.</span><span class="sxs-lookup"><span data-stu-id="088c7-220">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="088c7-221">**Movimientos oculares** desiguales Nuestros ojos realizan movimientos rápidos desde la fijación hasta la fijación.</span><span class="sxs-lookup"><span data-stu-id="088c7-221">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="088c7-222">Si observas las trayectorias de movimientos registrados de ojos, podrás ver que son irregulares.</span><span class="sxs-lookup"><span data-stu-id="088c7-222">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="088c7-223">Los ojos se mueven rápidamente y a saltos espontáneos en comparación con la *mirada con la cabeza* o los *movimientos manuales*.</span><span class="sxs-lookup"><span data-stu-id="088c7-223">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="088c7-224">**Confiabilidad del seguimiento:** La precisión del seguimiento de los ojos puede verse mermada con los cambios de luz, al ajustarse los ojos a las nuevas condiciones.</span><span class="sxs-lookup"><span data-stu-id="088c7-224">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="088c7-225">Aunque esto no debería afectar necesariamente al diseño de la aplicación, dado que la precisión debe estar dentro de la limitación de 2 °, es posible que sea necesario que el usuario se calibre de nuevo.</span><span class="sxs-lookup"><span data-stu-id="088c7-225">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="088c7-226">Recomendaciones de diseño</span><span class="sxs-lookup"><span data-stu-id="088c7-226">Design recommendations</span></span>
<span data-ttu-id="088c7-227">A continuación se muestra una lista de recomendaciones de diseño específicas basadas en las ventajas y los desafíos descritos para la entrada ocular:</span><span class="sxs-lookup"><span data-stu-id="088c7-227">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="088c7-228">**La mirada no es lo mismo que la mirada:**</span><span class="sxs-lookup"><span data-stu-id="088c7-228">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="088c7-229">**Ten en cuenta si los movimientos rápidos e irregulares de los ojos funcionan bien para la tarea de entrada:** Aunque nuestros movimientos de ojo rápidos y desiguales son excelentes para seleccionar rápidamente los destinos en nuestro campo de vista, es menos aplicable a las tareas que requieren trayectorias de entrada fluidas (por ejemplo, dibujar o enmarcar anotaciones).</span><span class="sxs-lookup"><span data-stu-id="088c7-229">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="088c7-230">En este caso, es preferible apuntar con la mano o con la cabeza.</span><span class="sxs-lookup"><span data-stu-id="088c7-230">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="088c7-231">**Evite adjuntar algo directamente a la mirada del usuario (por ejemplo, un control deslizante o un cursor).**</span><span class="sxs-lookup"><span data-stu-id="088c7-231">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="088c7-232">En el caso de un cursor, esto puede dar lugar al efecto "cursor fleeing" debido a ligeras desplazamientos en la señal de ojo mirada.</span><span class="sxs-lookup"><span data-stu-id="088c7-232">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="088c7-233">En el caso de un control deslizante, puede entrar en conflicto con el doble rol de controlar el control deslizante con los ojos mientras también se desea comprobar si el objeto está en la ubicación correcta.</span><span class="sxs-lookup"><span data-stu-id="088c7-233">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="088c7-234">En pocas palabras, los usuarios pueden saturarse y distraerse, especialmente si la señal es imprecisa para ese usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-234">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="088c7-235">**Combine la mirada con otras entradas:** La integración del seguimiento ocular con otras entradas, como gestos de mano, comandos de voz o pulsaciones de botones, ofrece varias ventajas:</span><span class="sxs-lookup"><span data-stu-id="088c7-235">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="088c7-236">**Permitir la observación libre:** Dado que el rol principal de nuestros ojos es observar nuestro entorno, es importante que los usuarios tengan la posibilidad de buscar sin desencadenar comentarios ni acciones (visual, Auditor, etc.).</span><span class="sxs-lookup"><span data-stu-id="088c7-236">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="088c7-237">La combinación del seguimiento ocular con otro control de entrada permite una transición suave entre los modos de observación de seguimiento ocular y de control de entrada.</span><span class="sxs-lookup"><span data-stu-id="088c7-237">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="088c7-238">**Proveedor de contexto eficaz:** El uso de información sobre dónde y qué mira el usuario mientras se ejecuta un comando de voz o realiza un gesto de mano permite canalizar sin problemas la entrada a través del campo de vista.</span><span class="sxs-lookup"><span data-stu-id="088c7-238">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="088c7-239">Por ejemplo: “Coloca eso ahí” para seleccionar y situar de manera rápida y fluida un holograma en la escena con solo mirar un objetivo y un destino.</span><span class="sxs-lookup"><span data-stu-id="088c7-239">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="088c7-240">**Necesidad de sincronizar entradas multimodales (problema de “salir antes de hacer clic”):** La combinación de movimientos oculares rápidos con entradas adicionales más complejas, como comandos de voz largos o gestos de mano, asume el riesgo de continuar la mirada antes de finalizar el comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="088c7-240">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="088c7-241">Por lo tanto, si crea sus propios controles de entrada (por ejemplo, gestos de mano personalizados), asegúrese de registrar la aparición de esta entrada o una duración aproximada para correlacionarla con lo que un usuario ha mirado en el pasado.</span><span class="sxs-lookup"><span data-stu-id="088c7-241">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had gazed at in the past.</span></span>
    
3. <span data-ttu-id="088c7-242">**Información sutil para la entrada de seguimiento de los ojos:** Resulta útil proporcionar comentarios cuando se examina un destino para indicar que el sistema funciona según lo previsto, pero debe mantenerse sutil.</span><span class="sxs-lookup"><span data-stu-id="088c7-242">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="088c7-243">Esto puede incluir una mezcla lenta, de arriba y de salida, que resalta visualmente o realiza otros comportamientos de destino sutiles, como movimientos lentos, como un aumento ligeramente del tamaño de destino, para indicar que el sistema ha detectado correctamente que el usuario está viendo un destino sin interrumpir innecesariamente el flujo de trabajo actual del usuario.</span><span class="sxs-lookup"><span data-stu-id="088c7-243">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="088c7-244">**Evita entradas que obliguen a realizar movimientos forzados con los ojos:** No obligue a los usuarios a realizar movimientos oculares específicos (gestos de mirados) para desencadenar acciones en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="088c7-244">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="088c7-245">**Ten en cuenta las imprecisiones:** Se distinguen dos tipos de imprecisiones que son evidentes para los usuarios: desplazamiento y vibración.</span><span class="sxs-lookup"><span data-stu-id="088c7-245">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="088c7-246">La manera más fácil de resolver un desplazamiento es proporcionar destinos suficientemente grandes para interactuar con.</span><span class="sxs-lookup"><span data-stu-id="088c7-246">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="088c7-247">Se recomienda usar un ángulo visual superior a 2 ° como referencia.</span><span class="sxs-lookup"><span data-stu-id="088c7-247">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="088c7-248">Por ejemplo, la miniatura es aproximadamente de 2 ° en el ángulo visual al expandir el brazo.</span><span class="sxs-lookup"><span data-stu-id="088c7-248">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="088c7-249">Esto conduce a la siguiente pauta:</span><span class="sxs-lookup"><span data-stu-id="088c7-249">This leads to the following guidance:</span></span>
    - <span data-ttu-id="088c7-250">No obligue a los usuarios a seleccionar pequeños destinos.</span><span class="sxs-lookup"><span data-stu-id="088c7-250">Do not force users to select tiny targets.</span></span> <span data-ttu-id="088c7-251">La investigación ha demostrado que si los destinos son suficientemente grandes y que el sistema está diseñado correctamente, los usuarios describen sus interacciones como sin esfuerzo y mágicas.</span><span class="sxs-lookup"><span data-stu-id="088c7-251">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="088c7-252">Si los objetivos son demasiado pequeños, los usuarios describen la experiencia como agotadora y frustrante.</span><span class="sxs-lookup"><span data-stu-id="088c7-252">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="088c7-253">Vea también</span><span class="sxs-lookup"><span data-stu-id="088c7-253">See also</span></span>
* [<span data-ttu-id="088c7-254">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="088c7-254">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="088c7-255">Encabezado y ojo en DirectX</span><span class="sxs-lookup"><span data-stu-id="088c7-255">Head and eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="088c7-256">Mirada a la vista de Unity (kit de herramientas de realidad mixta)</span><span class="sxs-lookup"><span data-stu-id="088c7-256">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="088c7-257">Calibración</span><span class="sxs-lookup"><span data-stu-id="088c7-257">Calibration</span></span>](https://docs.microsoft.com/en-us/windows/mixed-reality/calibration)
* [<span data-ttu-id="088c7-258">Gestos con la mano</span><span class="sxs-lookup"><span data-stu-id="088c7-258">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="088c7-259">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="088c7-259">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="088c7-260">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="088c7-260">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="088c7-261">Comodidad</span><span class="sxs-lookup"><span data-stu-id="088c7-261">Comfort</span></span>](comfort.md)
