---
title: Miras hacia abajo
description: HoloLens 2 permite un nuevo nivel de contexto y comprensión humana dentro de la experiencia holográfica, ya que proporciona a los desarrolladores la capacidad de usar información sobre lo que los usuarios ven.
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: Seguimiento ocular, realidad mixta, entrada, ojo
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122063"
---
# <a name="eye-gaze-on-hololens-2"></a><span data-ttu-id="e8916-104">Miras a la vista de HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="e8916-104">Eye-gaze on HoloLens 2</span></span>
<span data-ttu-id="e8916-105">HoloLens 2 permite un nuevo nivel de contexto y comprensión humana dentro de la experiencia holográfica, ya que proporciona a los desarrolladores la capacidad de usar información sobre lo que los usuarios ven.</span><span class="sxs-lookup"><span data-stu-id="e8916-105">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability of using information about what users are looking at.</span></span> <span data-ttu-id="e8916-106">En esta página se indica a los desarrolladores cómo pueden beneficiarse del seguimiento ocular de varios casos de uso, así como qué buscar al diseñar interfaces de usuario basadas en el ojo.</span><span class="sxs-lookup"><span data-stu-id="e8916-106">This page tells developers how they can benefit from eye tracking for various use cases as well as what to look for when designing eye-gaze-based user interfaces.</span></span> 


## <a name="device-support"></a><span data-ttu-id="e8916-107">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="e8916-107">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="e8916-108"><strong>Característica</strong></span><span class="sxs-lookup"><span data-stu-id="e8916-108"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="e8916-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1.ª generación)</strong></a></span><span class="sxs-lookup"><span data-stu-id="e8916-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="e8916-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="e8916-110"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="e8916-111"><a href="immersive-headset-hardware-details.md"><strong>Cascos envolventes</strong></a></span><span class="sxs-lookup"><span data-stu-id="e8916-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="e8916-112">Miras hacia abajo</span><span class="sxs-lookup"><span data-stu-id="e8916-112">Eye-gaze</span></span></td>
     <td><span data-ttu-id="e8916-113">❌</span><span class="sxs-lookup"><span data-stu-id="e8916-113">❌</span></span></td>
     <td><span data-ttu-id="e8916-114">✔️</span><span class="sxs-lookup"><span data-stu-id="e8916-114">✔️</span></span></td>
     <td><span data-ttu-id="e8916-115">❌</span><span class="sxs-lookup"><span data-stu-id="e8916-115">❌</span></span></td>
</tr>
</table>

## <a name="use-cases"></a><span data-ttu-id="e8916-116">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="e8916-116">Use cases</span></span>
<span data-ttu-id="e8916-117">El seguimiento de los ojos permite a las aplicaciones realizar un seguimiento de dónde mira el usuario en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="e8916-117">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="e8916-118">En los siguientes casos de uso se describen algunas interacciones que son posibles con el seguimiento ocular en la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="e8916-118">The following use cases describe some interactions that are possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="e8916-119">Tenga en cuenta que el [Kit de herramientas de la realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) es útil para proporcionar varios ejemplos interesantes y eficaces para usar el seguimiento ocular, como selecciones de destino compatibles con la vista rápida y sin esfuerzo, así como desplazarse automáticamente por el texto basado en el aspecto del usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-119">Keep in mind that the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) is useful for providing several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections as well as automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="e8916-120">Intención del usuario</span><span class="sxs-lookup"><span data-stu-id="e8916-120">User intent</span></span>    
<span data-ttu-id="e8916-121">Información sobre dónde y qué mira un usuario proporciona un contexto eficaz **para otras entradas**, como voz, manos y controladores.</span><span class="sxs-lookup"><span data-stu-id="e8916-121">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="e8916-122">Esta información puede utilizarse para varias tareas.</span><span class="sxs-lookup"><span data-stu-id="e8916-122">This can be used for various tasks.</span></span>
<span data-ttu-id="e8916-123">Por ejemplo, esto puede variar de forma rápida y sin esfuerzo a través de la escena, simplemente examinando un holograma y diciendo "Select" (consulte también el [encabezado y la confirmación](gaze-and-commit.md)) o diciendo *"Put this..."* y, después, buscando Dónde está el usuario. quiere colocar el holograma y decir *"... allí "* .</span><span class="sxs-lookup"><span data-stu-id="e8916-123">For example, this can range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="e8916-124">Puedes consultar varios ejemplos en [Mixed Reality Toolkit: Selección de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) y [Mixed Reality Toolkit: Posicionamiento de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="e8916-124">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="e8916-125">Además, un ejemplo de intención del usuario podría incluir el uso de información sobre lo que los usuarios ven para mejorar la interacción con agentes virtuales incorporados y hologramas interactivos.</span><span class="sxs-lookup"><span data-stu-id="e8916-125">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="e8916-126">Por ejemplo, los agentes virtuales pueden adaptar las opciones disponibles y su comportamiento en función del contenido que se vea actualmente.</span><span class="sxs-lookup"><span data-stu-id="e8916-126">For instance, virtual agents might adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="e8916-127">Acciones implícitas</span><span class="sxs-lookup"><span data-stu-id="e8916-127">Implicit actions</span></span>
<span data-ttu-id="e8916-128">La categoría de acciones implícitas está estrechamente relacionada con la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-128">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="e8916-129">La idea es que los hologramas o los elementos de la interfaz de usuario reaccionan de una manera algo instinctual que puede que no parezca incluso que el usuario está interactuando con el sistema, sino que el sistema y el usuario están sincronizados. Un ejemplo es el **desplazamiento automático basado en la mirada** , en el que el usuario puede leer un texto largo que inicia automáticamente el desplazamiento una vez que el usuario llega a la parte inferior del cuadro de texto para evitar que el usuario realice el flujo de lectura sin levantar un dedo.</span><span class="sxs-lookup"><span data-stu-id="e8916-129">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading without lifting a finger.</span></span>  
<span data-ttu-id="e8916-130">Un aspecto clave de esto es que la velocidad de desplazamiento se adapta a la velocidad de lectura del usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-130">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="e8916-131">Otro ejemplo es el **zoom y la panorámica** que se admiten, donde el usuario puede sentir como sumergir exactamente en lo que se centra.</span><span class="sxs-lookup"><span data-stu-id="e8916-131">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she is focused on.</span></span> <span data-ttu-id="e8916-132">El zoom y el control de la velocidad de zoom se pueden controlar mediante la entrada de voz o a mano, lo que es importante para proporcionar al usuario la sensación de control mientras evita estar abrumado.</span><span class="sxs-lookup"><span data-stu-id="e8916-132">Triggering zoom and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="e8916-133">Hablaremos sobre estas instrucciones de diseño con más detalle a continuación.</span><span class="sxs-lookup"><span data-stu-id="e8916-133">We will talk about these design guidelines in more detail below.</span></span> <span data-ttu-id="e8916-134">Una vez que se ha ampliado, el usuario puede seguir sin problemas, por ejemplo, en el transcurso de una calle para explorar su entorno con solo ver la mirada.</span><span class="sxs-lookup"><span data-stu-id="e8916-134">Once zoomed in, the user can  smoothly follow, for example, the course of a street to explore his or her neighborhood by simply using their eye-gaze.</span></span>
<span data-ttu-id="e8916-135">Puedes consultar ejemplos de demostración de estos tipos de interacciones en el ejemplo [Mixed Reality Toolkit - Navegación con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="e8916-135">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="e8916-136">Los casos de uso adicionales para _acciones implícitas_ pueden incluir:</span><span class="sxs-lookup"><span data-stu-id="e8916-136">Additional use cases for _implicit actions_ can include:</span></span>
- <span data-ttu-id="e8916-137">**Notificaciones inteligentes:** ¿Te molesta que aparezcan notificaciones justo donde estabas mirando?</span><span class="sxs-lookup"><span data-stu-id="e8916-137">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="e8916-138">Teniendo en cuenta la atención de un usuario, puede mejorar esta experiencia mediante el desplazamiento de notificaciones desde donde el usuario está Gazing actualmente.</span><span class="sxs-lookup"><span data-stu-id="e8916-138">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="e8916-139">Esto limita las distracciones y las descarta automáticamente una vez que el usuario haya terminado de leer.</span><span class="sxs-lookup"><span data-stu-id="e8916-139">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="e8916-140">**Hologramas atentos:** Hologramas que reaccionan sutilmente cuando se miran.</span><span class="sxs-lookup"><span data-stu-id="e8916-140">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="e8916-141">Esto puede abarcar desde elementos de interfaz de usuario ligeramente iluminados hasta una flor de floración lenta hasta una mascota virtual que empieza a volver al usuario o intenta evitar la mirada al usuario después de una estrella prolongada.</span><span class="sxs-lookup"><span data-stu-id="e8916-141">This can range from slightly glowing UI elements to a slowly blooming flower to a virtual pet starting to look back at the user or trying to avoid the user's eye-gaze after a prolonged stare.</span></span> <span data-ttu-id="e8916-142">Esta interacción podría proporcionar una sensación interesante de conectividad y satisfacción en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="e8916-142">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="e8916-143">Seguimiento de la atención</span><span class="sxs-lookup"><span data-stu-id="e8916-143">Attention tracking</span></span>   
<span data-ttu-id="e8916-144">Información sobre dónde o qué ven los usuarios es una herramienta enormemente eficaz para evaluar la facilidad de uso de los diseños y para identificar problemas en flujos de trabajo eficientes.</span><span class="sxs-lookup"><span data-stu-id="e8916-144">Information about where or what users look at is an immensely powerful tool to assess usability of designs, and to identify problems in efficient workflows.</span></span> <span data-ttu-id="e8916-145">La visualización y el análisis de seguimiento ocular son una práctica común en diversas áreas de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="e8916-145">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="e8916-146">Con HoloLens 2, se proporciona una nueva dimensión para esta comprensión, ya que los hologramas 3D se pueden colocar en contextos reales y evaluarse como corresponda.</span><span class="sxs-lookup"><span data-stu-id="e8916-146">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="e8916-147">El [Kit de herramientas de realidad mixta](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) proporciona ejemplos básicos para registrar y cargar datos de seguimiento ocular y cómo visualizarlos.</span><span class="sxs-lookup"><span data-stu-id="e8916-147">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and  how to visualize them.</span></span>

<span data-ttu-id="e8916-148">Otras aplicaciones de esta área pueden incluir:</span><span class="sxs-lookup"><span data-stu-id="e8916-148">Other applications in this area can include:</span></span> 
-   <span data-ttu-id="e8916-149">**Visualización de ojo remoto:** Visualice los colaboradores remotos que buscan para asegurarse de que las instrucciones se comprenden y se siguen correctamente.</span><span class="sxs-lookup"><span data-stu-id="e8916-149">**Remote eye-gaze visualization:** Visualize what remote collaborators are looking at to ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="e8916-150">**Estudios de investigación con usuarios:** El seguimiento de atención se puede usar para explorar la forma en que los usuarios principiantes frente a expertos analizan visualmente el contenido o cómo su coordinación ocular para tareas complejas, como el análisis de datos médicos o la maquinaria operativa.</span><span class="sxs-lookup"><span data-stu-id="e8916-150">**User research studies:** Attention tracking can be used to explore the way novice vs. expert users visually analyze content or how their hand-eye-coordination for complex tasks, such as for analysis of medical data or while operating machinery.</span></span>
-   <span data-ttu-id="e8916-151">**Entrenamiento de simulaciones y supervisión del rendimiento:** Practica y optimiza la ejecución de tareas mediante una identificación de cuellos de botella más eficaz en el flujo de ejecución.</span><span class="sxs-lookup"><span data-stu-id="e8916-151">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="e8916-152">**Evaluaciones de diseño, publicidad y estudios de mercado:** El seguimiento ocular es una herramienta común para la investigación de mercado al evaluar los diseños de productos y sitios Web.</span><span class="sxs-lookup"><span data-stu-id="e8916-152">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research when evaluating website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="e8916-153">Casos de uso adicionales</span><span class="sxs-lookup"><span data-stu-id="e8916-153">Additional use cases</span></span>
- <span data-ttu-id="e8916-154">**Videojuegos:** ¿Alguna vez has deseado tener superpoderes?</span><span class="sxs-lookup"><span data-stu-id="e8916-154">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="e8916-155">Esta es tu oportunidad.</span><span class="sxs-lookup"><span data-stu-id="e8916-155">Here's your chance!</span></span> <span data-ttu-id="e8916-156">Puede levitater los hologramas mediante la estrella.</span><span class="sxs-lookup"><span data-stu-id="e8916-156">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="e8916-157">Dispara rayos láser con los ojos.</span><span class="sxs-lookup"><span data-stu-id="e8916-157">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="e8916-158">Convierta los enemigos en piedra o inmovilice.</span><span class="sxs-lookup"><span data-stu-id="e8916-158">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="e8916-159">Usa tu visión de rayos X para explorar edificios.</span><span class="sxs-lookup"><span data-stu-id="e8916-159">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="e8916-160">El límite es tu imaginación.</span><span class="sxs-lookup"><span data-stu-id="e8916-160">Your imagination is the limit!</span></span>  

- <span data-ttu-id="e8916-161">**Avatares expresivos:** El seguimiento ocular ayuda en avatares 3D más expresivos mediante el uso de datos de seguimiento de ojos en directo para animar los ojos del Avatar que indican lo que el usuario está mirando.</span><span class="sxs-lookup"><span data-stu-id="e8916-161">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="e8916-162">**Entrada de texto:** El seguimiento ocular se puede usar como alternativa a la entrada de texto de bajo esfuerzo, especialmente cuando la voz o las manos no son prácticas de usar.</span><span class="sxs-lookup"><span data-stu-id="e8916-162">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 


## <a name="available-eye-tracking-data"></a><span data-ttu-id="e8916-163">Datos de seguimiento ocular disponibles</span><span class="sxs-lookup"><span data-stu-id="e8916-163">Available eye tracking data</span></span>
<span data-ttu-id="e8916-164">Antes de entrar en detalles sobre las directrices de diseño específicas para la interacción ocular, queremos señalar brevemente las funcionalidades que proporciona la [API de seguimiento](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) de la vista de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="e8916-164">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="e8916-165">Los desarrolladores obtienen acceso a un solo rayo de mira fijamente (miran el origen y la dirección) a aproximadamente _30 fps (60 Hz)_ .</span><span class="sxs-lookup"><span data-stu-id="e8916-165">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (60 Hz)_.</span></span>
<span data-ttu-id="e8916-166">Para obtener información más detallada sobre cómo obtener acceso a los datos de seguimiento de los ojos, consulte nuestras guías para desarrolladores sobre el uso de la mirada [en DirectX](gaze-in-directx.md) y la mirada a [la vista de Unity](https://aka.ms/mrtk-eyes).</span><span class="sxs-lookup"><span data-stu-id="e8916-166">For more detailed information about how to access eye tracking data, please refer to our developer guides on using [eye-gaze in DirectX](gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="e8916-167">El ojo de miración predicho es aproximadamente de 1,5 grados en el ángulo visual alrededor del destino real (vea la ilustración siguiente).</span><span class="sxs-lookup"><span data-stu-id="e8916-167">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="e8916-168">A medida que se esperan ligeras imprecisiones, los desarrolladores deben planear algún margen alrededor de este valor límite inferior (por ejemplo, 2,0-3.0 grados pueden dar lugar a una experiencia mucho más cómoda).</span><span class="sxs-lookup"><span data-stu-id="e8916-168">As slight imprecisions are expected, developers should plan for some margin around this lower bound value (e.g., 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="e8916-169">Veremos cómo abordar la selección de destinos pequeños con más detalle a continuación.</span><span class="sxs-lookup"><span data-stu-id="e8916-169">We will discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="e8916-170">Para que el seguimiento de los ojos funcione con precisión, cada usuario debe realizar una calibración de seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="e8916-170">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="e8916-171">![Tamaño de objetivo óptimo a una distancia de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="e8916-171">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="e8916-172">*Tamaño óptimo de destino a una distancia de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="e8916-172">*Optimal target size at a 2-meter distance*</span></span>

## <a name="calibration"></a><span data-ttu-id="e8916-173">Curva</span><span class="sxs-lookup"><span data-stu-id="e8916-173">Calibration</span></span> 
<span data-ttu-id="e8916-174">Para que el seguimiento de los ojos funcione con precisión, cada usuario tiene que pasar por una [calibración de usuario de seguimiento ocular](calibration.md) en la que el usuario tiene que mirar un conjunto de destinos holográficas.</span><span class="sxs-lookup"><span data-stu-id="e8916-174">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](calibration.md) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="e8916-175">Esto permite que el dispositivo ajuste el sistema para una experiencia de visualización más cómoda y de mayor calidad para el usuario y para garantizar un seguimiento de ojo preciso al mismo tiempo.</span><span class="sxs-lookup"><span data-stu-id="e8916-175">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> <span data-ttu-id="e8916-176">El seguimiento ocular debe funcionar para la mayoría de los usuarios, pero hay casos en los que un usuario podría no ser capaz de calibrarse correctamente.</span><span class="sxs-lookup"><span data-stu-id="e8916-176">Eye tracking should work for most users, but there are cases in which a user might be unable to calibrate successfully.</span></span>
<span data-ttu-id="e8916-177">Para obtener más información acerca de la calibración, Compruebe la [calibración](calibration.md).</span><span class="sxs-lookup"><span data-stu-id="e8916-177">To learn more about the calibration, please check [Calibration](calibration.md).</span></span>

## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="e8916-178">Guías de diseño de entrada de mirada</span><span class="sxs-lookup"><span data-stu-id="e8916-178">Eye-gaze input design guidelines</span></span>
<span data-ttu-id="e8916-179">Crear una interacción que aproveche los objetivos de vista rápida en movimiento puede ser un reto.</span><span class="sxs-lookup"><span data-stu-id="e8916-179">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="e8916-180">En esta sección, se resumen las principales ventajas y los desafíos que se deben tener en cuenta al diseñar la aplicación.</span><span class="sxs-lookup"><span data-stu-id="e8916-180">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="e8916-181">Ventajas de la entrada ocular</span><span class="sxs-lookup"><span data-stu-id="e8916-181">Benefits of eye-gaze input</span></span>
- <span data-ttu-id="e8916-182">**Señalización a alta velocidad.**</span><span class="sxs-lookup"><span data-stu-id="e8916-182">**High speed pointing.**</span></span> <span data-ttu-id="e8916-183">El músculo ocular es el músculo de reacción más rápido en el cuerpo humano.</span><span class="sxs-lookup"><span data-stu-id="e8916-183">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="e8916-184">**Poco esfuerzo.**</span><span class="sxs-lookup"><span data-stu-id="e8916-184">**Low effort.**</span></span> <span data-ttu-id="e8916-185">Prácticamente no se necesita ningún movimiento físico.</span><span class="sxs-lookup"><span data-stu-id="e8916-185">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="e8916-186">**Implícito.**</span><span class="sxs-lookup"><span data-stu-id="e8916-186">**Implicitness.**</span></span> <span data-ttu-id="e8916-187">A menudo lo describen los usuarios como "atención", la información acerca de los movimientos oculares de un usuario permite que el sistema sepa cuál es el objetivo que el usuario tiene previsto interactuar.</span><span class="sxs-lookup"><span data-stu-id="e8916-187">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="e8916-188">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="e8916-188">**Alternative input channel.**</span></span> <span data-ttu-id="e8916-189">La mirada a la mano puede proporcionar una gran cantidad de datos de soporte técnico para la entrada de voz y entrega en años de experiencia de los usuarios en función de su coordinación ocular a mano.</span><span class="sxs-lookup"><span data-stu-id="e8916-189">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="e8916-190">**Atención visual.**</span><span class="sxs-lookup"><span data-stu-id="e8916-190">**Visual attention.**</span></span> <span data-ttu-id="e8916-191">Otra ventaja importante es la posibilidad de deducir lo que un usuario está pagando con atención.</span><span class="sxs-lookup"><span data-stu-id="e8916-191">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="e8916-192">Esto puede ayudar en diversas áreas de la aplicación que abarcan de una evaluación más eficaz de los distintos diseños para ayudar a las interfaces de usuario más inteligentes y a las guías sociales mejoradas para la comunicación remota.</span><span class="sxs-lookup"><span data-stu-id="e8916-192">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="e8916-193">En pocas palabras, el uso de la mirada a la entrada ofrece una señal contextual rápida y sin esfuerzo.</span><span class="sxs-lookup"><span data-stu-id="e8916-193">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual signal.</span></span> <span data-ttu-id="e8916-194">Esto es especialmente eficaz cuando se combina con otras entradas como la *voz* y la entrada *manual* para confirmar la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-194">This is particularly powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="e8916-195">Desafíos de la mirada: la entrada</span><span class="sxs-lookup"><span data-stu-id="e8916-195">Challenges of eye-gaze as an input</span></span>
<span data-ttu-id="e8916-196">Con una gran cantidad de energía, supone una gran responsabilidad.</span><span class="sxs-lookup"><span data-stu-id="e8916-196">With lots of power, comes lots of responsibility.</span></span>
<span data-ttu-id="e8916-197">A pesar de la mirada, se puede usar para crear experiencias de usuario satisfactorias, lo que hace que se sienta como un Superhero, también es importante saber lo que no es adecuado para tener en cuenta adecuadamente esto.</span><span class="sxs-lookup"><span data-stu-id="e8916-197">While eye-gaze can be used to create satisfying user experiences that makes you feel like a superhero, it is also important to know what it is not good at to appropriately account for this.</span></span> <span data-ttu-id="e8916-198">A continuación se explican algunos de los *desafíos* que se deben tener en cuenta, así como cómo abordarlos al trabajar con la entrada de mirada:</span><span class="sxs-lookup"><span data-stu-id="e8916-198">The following discusses some *challenges* to consider as well as how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="e8916-199">**La mirada está "Always On"** En el momento en que se abre el Lids, los ojos comienzan fixating sobre las cosas en el entorno.</span><span class="sxs-lookup"><span data-stu-id="e8916-199">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="e8916-200">Al reaccionar a cada una de las búsquedas que se realizan y se emiten acciones accidentalmente porque se ha buscado algo demasiado tiempo, se producirá una experiencia incumplida.</span><span class="sxs-lookup"><span data-stu-id="e8916-200">Reacting to every look you make and accidentally issuing actions because you looked at something for too long would result in an unsatisfying experience.</span></span>
<span data-ttu-id="e8916-201">Por lo tanto, se recomienda combinar ojo con un *comando de voz*, un gesto de *mano*, un clic de *botón* o una permanencia extendida para desencadenar la selección de un destino.</span><span class="sxs-lookup"><span data-stu-id="e8916-201">Therefore we recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="e8916-202">Esta solución también permite un modo en el que el usuario puede mirar libremente sin saturarse mediante la activación involuntaria de algo.</span><span class="sxs-lookup"><span data-stu-id="e8916-202">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="e8916-203">Este problema también se debe tener en cuenta a la hora de diseñar comentarios visuales y acústicos cuando solo se examina un objetivo.</span><span class="sxs-lookup"><span data-stu-id="e8916-203">This issue should also be considered when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="e8916-204">No debe sobrecargarse al usuario con efectos emergentes inmediatos o sonidos al pasar sobre los elementos.</span><span class="sxs-lookup"><span data-stu-id="e8916-204">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="e8916-205">El detalle es clave.</span><span class="sxs-lookup"><span data-stu-id="e8916-205">Subtlety is key.</span></span> <span data-ttu-id="e8916-206">Más adelante, en las recomendaciones de diseño, se describen algunos de los procedimientos recomendados para esto.</span><span class="sxs-lookup"><span data-stu-id="e8916-206">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="e8916-207">**Observación frente a control** Imagine que desea enderezar con precisión una fotografía en la pared.</span><span class="sxs-lookup"><span data-stu-id="e8916-207">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="e8916-208">Miras los bordes y la zona circundante para ver si está bien alineada.</span><span class="sxs-lookup"><span data-stu-id="e8916-208">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="e8916-209">Ahora Imagine cómo lo haría si quiere usar el ojo de la mirada como entrada para trasladar la imagen.</span><span class="sxs-lookup"><span data-stu-id="e8916-209">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="e8916-210">Difícil, ¿verdad?</span><span class="sxs-lookup"><span data-stu-id="e8916-210">Difficult, isn't it?</span></span> <span data-ttu-id="e8916-211">Esto describe el doble rol de ojo y mira si es necesario para la entrada y el control.</span><span class="sxs-lookup"><span data-stu-id="e8916-211">This describes the double role of eye-gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="e8916-212">**Salir antes de hacer clic:** En el caso de las selecciones de destino rápido, la investigación ha demostrado que el ojo de un usuario puede continuar antes de concluir un clic manual (por ejemplo, un airtap).</span><span class="sxs-lookup"><span data-stu-id="e8916-212">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="e8916-213">Por lo tanto, se debe prestar especial atención a la sincronización de la señal de mirada rápida con una entrada de control más lenta (por ejemplo, voz, manos, controlador).</span><span class="sxs-lookup"><span data-stu-id="e8916-213">Hence, special attention must be paid to synchronizing the fast eye-gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="e8916-214">**Objetivos pequeños:** ¿Sabe que se siente al intentar leer texto que es simplemente un poco pequeño para leerlo de forma cómoda?</span><span class="sxs-lookup"><span data-stu-id="e8916-214">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="e8916-215">Esta limitación de los ojos puede hacer que se sienta cansado y se haya gastado porque intenta reajustar los ojos para centrarse mejor.</span><span class="sxs-lookup"><span data-stu-id="e8916-215">This straining feeling on your eyes can cause you to feel tired and worn out because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="e8916-216">Se trata de una sensación que podría invocar a los usuarios al obligarles a seleccionar destinos que son demasiado pequeños en la aplicación mediante el establecimiento de destinos de la vista.</span><span class="sxs-lookup"><span data-stu-id="e8916-216">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="e8916-217">Al diseñar la aplicación, para crear una experiencia agradable y cómoda para los usuarios, se recomienda que los objetivos sean al menos de 2° en ángulo visual, o preferiblemente mayores.</span><span class="sxs-lookup"><span data-stu-id="e8916-217">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="e8916-218">**Movimientos oculares** desiguales Nuestros ojos realizan movimientos rápidos desde la fijación hasta la fijación.</span><span class="sxs-lookup"><span data-stu-id="e8916-218">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="e8916-219">Si observas las trayectorias de movimientos registrados de ojos, podrás ver que son irregulares.</span><span class="sxs-lookup"><span data-stu-id="e8916-219">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="e8916-220">Los ojos se mueven rápidamente y en saltos espontáneos en comparación con los *movimientos*de *miras* o de mano.</span><span class="sxs-lookup"><span data-stu-id="e8916-220">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="e8916-221">**Confiabilidad del seguimiento:** La precisión del seguimiento de los ojos puede verse mermada con los cambios de luz, al ajustarse los ojos a las nuevas condiciones.</span><span class="sxs-lookup"><span data-stu-id="e8916-221">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="e8916-222">Aunque esto no debería afectar necesariamente al diseño de la aplicación, dado que la precisión debe estar dentro de la limitación de 2 °, es posible que sea necesario que el usuario se calibre de nuevo.</span><span class="sxs-lookup"><span data-stu-id="e8916-222">While this should not necessarily affect your application design, as the accuracy should be within the 2° limitation, i might be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="e8916-223">Recomendaciones de diseño</span><span class="sxs-lookup"><span data-stu-id="e8916-223">Design recommendations</span></span>
<span data-ttu-id="e8916-224">A continuación se muestra una lista de recomendaciones de diseño específicas basadas en las ventajas y los desafíos descritos para la entrada ocular:</span><span class="sxs-lookup"><span data-stu-id="e8916-224">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="e8916-225">**La mirada no es lo mismo que la mirada:**</span><span class="sxs-lookup"><span data-stu-id="e8916-225">**Eye-gaze is not the same as Head-gaze:**</span></span>
    - <span data-ttu-id="e8916-226">**Ten en cuenta si los movimientos rápidos e irregulares de los ojos funcionan bien para la tarea de entrada:** Aunque nuestros movimientos de ojo rápidos y desiguales son excelentes para seleccionar rápidamente los destinos en nuestro campo de vista, es menos aplicable a las tareas que requieren trayectorias de entrada fluidas (por ejemplo, dibujar o enmarcar anotaciones).</span><span class="sxs-lookup"><span data-stu-id="e8916-226">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it is less applicable for tasks that require smooth input trajectories (e.g., drawing or encircling annotations).</span></span> <span data-ttu-id="e8916-227">En este caso, es preferible apuntar con la mano o con la cabeza.</span><span class="sxs-lookup"><span data-stu-id="e8916-227">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="e8916-228">**Evite adjuntar algo directamente a la mirada del usuario (por ejemplo, un control deslizante o un cursor).**</span><span class="sxs-lookup"><span data-stu-id="e8916-228">**Avoid attaching something directly to the user’s eye-gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="e8916-229">En el caso de un cursor, esto puede dar lugar al efecto "cursor fleeing" debido a ligeras desplazamientos en la señal de ojo mirada.</span><span class="sxs-lookup"><span data-stu-id="e8916-229">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="e8916-230">En el caso de un control deslizante, puede entrar en conflicto con el doble rol de controlar el control deslizante con los ojos mientras también se desea comprobar si el objeto está en la ubicación correcta.</span><span class="sxs-lookup"><span data-stu-id="e8916-230">In case of a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="e8916-231">En pocas palabras, los usuarios pueden saturarse y distraerse, especialmente si la señal es imprecisa para ese usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-231">In a nutshell, users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="e8916-232">**Combine la mirada con otras entradas:** La integración del seguimiento ocular con otras entradas, como gestos de mano, comandos de voz o pulsaciones de botones, ofrece varias ventajas:</span><span class="sxs-lookup"><span data-stu-id="e8916-232">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="e8916-233">**Permitir la observación libre:** Dado que el rol principal de nuestros ojos es observar nuestro entorno, es importante que los usuarios tengan la posibilidad de buscar sin desencadenar comentarios ni acciones (visual, Auditor, etc.).</span><span class="sxs-lookup"><span data-stu-id="e8916-233">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important users are allowed to look around without triggering any (visual, auditory, etc.) feedback or actions.</span></span> 
    <span data-ttu-id="e8916-234">La combinación del seguimiento ocular con otro control de entrada permite una transición suave entre los modos de observación de seguimiento ocular y de control de entrada.</span><span class="sxs-lookup"><span data-stu-id="e8916-234">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="e8916-235">**Proveedor de contexto eficaz:** El uso de información sobre dónde y qué mira el usuario mientras se ejecuta un comando de voz o realiza un gesto de mano permite canalizar sin problemas la entrada a través del campo de vista.</span><span class="sxs-lookup"><span data-stu-id="e8916-235">**Powerful context provider:** Using information about where and what the user is looking at while uttering a voice command or performing a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="e8916-236">Por ejemplo: “Coloca eso ahí” para seleccionar y situar de manera rápida y fluida un holograma en la escena con solo mirar un objetivo y un destino.</span><span class="sxs-lookup"><span data-stu-id="e8916-236">For example: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="e8916-237">**Necesidad de sincronizar entradas multimodales (problema de “salir antes de hacer clic”):** La combinación de movimientos oculares rápidos con entradas adicionales más complejas, como comandos de voz largos o gestos de mano, asume el riesgo de continuar la mirada antes de finalizar el comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="e8916-237">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs, such as long voice commands or hand gestures, bears the risk of continuing your eye-gaze before finishing the additional input command.</span></span> <span data-ttu-id="e8916-238">Por lo tanto, si crea sus propios controles de entrada (por ejemplo, gestos de mano personalizados), asegúrese de registrar la aparición de esta entrada o de una duración aproximada para correlacionarla con lo que un usuario había examinado en el pasado.</span><span class="sxs-lookup"><span data-stu-id="e8916-238">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="e8916-239">**Información sutil para la entrada de seguimiento de los ojos:** Resulta útil proporcionar comentarios cuando se examina un destino para indicar que el sistema funciona según lo previsto, pero debe mantenerse sutil.</span><span class="sxs-lookup"><span data-stu-id="e8916-239">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="e8916-240">Esto puede incluir una mezcla lenta, de arriba y de salida, que resalta visualmente o realiza otros comportamientos de destino sutiles, como movimientos lentos, como un aumento ligeramente del tamaño de destino, para indicar que el sistema ha detectado correctamente que el usuario está viendo un destino sin interrumpir innecesariamente el flujo de trabajo actual del usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-240">This can include slowly blending, in and out, visual highlights or perform other subtle target behaviors, such as slow motions, such as slightly increasing the target size, to indicate that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="e8916-241">**Evita entradas que obliguen a realizar movimientos forzados con los ojos:** No obligue a los usuarios a realizar movimientos oculares específicos (gestos de mirados) para desencadenar acciones en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="e8916-241">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="e8916-242">**Ten en cuenta las imprecisiones:** Se distinguen dos tipos de imprecisiones que son evidentes para los usuarios: desplazamiento y vibración.</span><span class="sxs-lookup"><span data-stu-id="e8916-242">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="e8916-243">La manera más fácil de resolver un desplazamiento es proporcionar destinos suficientemente grandes para interactuar con.</span><span class="sxs-lookup"><span data-stu-id="e8916-243">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="e8916-244">Se recomienda usar un ángulo visual superior a 2 ° como referencia.</span><span class="sxs-lookup"><span data-stu-id="e8916-244">It is suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="e8916-245">Por ejemplo, la miniatura es aproximadamente de 2 ° en el ángulo visual al expandir el brazo.</span><span class="sxs-lookup"><span data-stu-id="e8916-245">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="e8916-246">Esto conduce a la siguiente pauta:</span><span class="sxs-lookup"><span data-stu-id="e8916-246">This leads to the following guidance:</span></span>
    - <span data-ttu-id="e8916-247">No obligue a los usuarios a seleccionar pequeños destinos.</span><span class="sxs-lookup"><span data-stu-id="e8916-247">Do not force users to select tiny targets.</span></span> <span data-ttu-id="e8916-248">La investigación ha demostrado que si los destinos son suficientemente grandes y que el sistema está diseñado correctamente, los usuarios describen sus interacciones como sin esfuerzo y mágicas.</span><span class="sxs-lookup"><span data-stu-id="e8916-248">Research has shown that if targets are sufficiently large, and that the system is designed well, users describe their interactions as effortless and magical.</span></span> <span data-ttu-id="e8916-249">Si los objetivos son demasiado pequeños, los usuarios describen la experiencia como agotadora y frustrante.</span><span class="sxs-lookup"><span data-stu-id="e8916-249">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a><span data-ttu-id="e8916-250">Instrucciones para desarrolladores: ¿Qué ocurre si el seguimiento ocular no está disponible?</span><span class="sxs-lookup"><span data-stu-id="e8916-250">Dev guidance: What if eye tracking is not available?</span></span>
<span data-ttu-id="e8916-251">Puede haber situaciones en las que la aplicación no recibirá ningún dato de seguimiento ocular debido a diversas razones, entre las que se incluyen las siguientes:</span><span class="sxs-lookup"><span data-stu-id="e8916-251">There may be situations in which your app will not receive any eye tracking data due to various reasons including but not limited to:</span></span>
* <span data-ttu-id="e8916-252">El usuario omitió la calibración del seguimiento de ojo.</span><span class="sxs-lookup"><span data-stu-id="e8916-252">The user skipped the eye tracking calibration.</span></span>
* <span data-ttu-id="e8916-253">El usuario ha calibrado, pero decidió no conceder permiso a la aplicación para que use los datos de seguimiento ocular.</span><span class="sxs-lookup"><span data-stu-id="e8916-253">The user calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>
* <span data-ttu-id="e8916-254">El usuario tiene anteojos únicos o alguna condición de ojo que el sistema todavía no admite.</span><span class="sxs-lookup"><span data-stu-id="e8916-254">The user has unique eyeglasses or some eye condition that the system does not yet support.</span></span>
* <span data-ttu-id="e8916-255">Factores externos que impiden el seguimiento de ojos fiables, como manchas en el parasol o anteojos de HoloLens, luz solar directa y oclusión, debido al pelo en la parte delantera de los ojos.</span><span class="sxs-lookup"><span data-stu-id="e8916-255">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight and occlusions due to hair in front of the eyes.</span></span>

<span data-ttu-id="e8916-256">Como desarrollador de aplicaciones, esto significa que debe tener en cuenta la compatibilidad con los usuarios para los que es posible que los datos de seguimiento ocular no estén disponibles.</span><span class="sxs-lookup"><span data-stu-id="e8916-256">For you as an app developer, this means that you need to account for how to support users for whom eye tracking data may not be available.</span></span> <span data-ttu-id="e8916-257">A continuación se explica en primer lugar cómo detectar si el seguimiento ocular está disponible y cómo solucionarlo cuando no está disponible para aplicaciones diferentes.</span><span class="sxs-lookup"><span data-stu-id="e8916-257">Below we first explain how to detect whether eye tracking is available and how to address when it is not available for different applications.</span></span>

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a><span data-ttu-id="e8916-258">1. Cómo detectar que el seguimiento ocular está disponible</span><span class="sxs-lookup"><span data-stu-id="e8916-258">1. How to detect that eye tracking is available</span></span>
<span data-ttu-id="e8916-259">Hay algunas comprobaciones para determinar si los datos de seguimiento ocular están disponibles.</span><span class="sxs-lookup"><span data-stu-id="e8916-259">There are a few checks to determine whether eye tracking data is available.</span></span> <span data-ttu-id="e8916-260">Compruebe si...</span><span class="sxs-lookup"><span data-stu-id="e8916-260">Check whether...</span></span>
* <span data-ttu-id="e8916-261">... el sistema admite el seguimiento ocular en absoluto.</span><span class="sxs-lookup"><span data-stu-id="e8916-261">... the system supports eye tracking at all.</span></span> <span data-ttu-id="e8916-262">Llame al *método*siguiente: [Windows. Perception. people. EyesPose. IsSupported ()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span><span class="sxs-lookup"><span data-stu-id="e8916-262">Call the following *method*: [Windows.Perception.People.EyesPose.IsSupported()](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)</span></span>

* <span data-ttu-id="e8916-263">... se calibra el usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-263">... the user is calibrated.</span></span> <span data-ttu-id="e8916-264">Llame a la siguiente *propiedad*: [Windows. Perception. people. EyesPose. IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span><span class="sxs-lookup"><span data-stu-id="e8916-264">Call the following *property*: [Windows.Perception.People.EyesPose.IsCalibrationValid](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)</span></span>

* <span data-ttu-id="e8916-265">... el usuario ha dado permiso a la aplicación para usar los datos de seguimiento ocular: Recupere el _' GazeInputAccessStatus '_ actual.</span><span class="sxs-lookup"><span data-stu-id="e8916-265">... the user has given your app permission to use their eye tracking data: Retrieve the current _'GazeInputAccessStatus'_.</span></span> <span data-ttu-id="e8916-266">Un ejemplo de cómo hacerlo se explica cómo solicitar el [acceso a la entrada de mirada](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span><span class="sxs-lookup"><span data-stu-id="e8916-266">An example on how to do this is explained at [Requesting access to gaze input](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input).</span></span>

<span data-ttu-id="e8916-267">Además, puede que desee comprobar que los datos de seguimiento ocular no están obsoletos agregando un tiempo de espera entre las actualizaciones de datos de seguimiento de ojos recibidos y, de lo contrario, reserva a Head-mira como se describe a continuación.</span><span class="sxs-lookup"><span data-stu-id="e8916-267">In addition, you may want to check that your eye tracking data is not stale by adding a timeout between received eye tracking data updates and otherwise fallback to head-gaze as discussed below.</span></span> 

<span data-ttu-id="e8916-268">Como se describió anteriormente, existen varios motivos por los que es posible que los datos de seguimiento ocular no estén disponibles.</span><span class="sxs-lookup"><span data-stu-id="e8916-268">As described above, there are several reasons why eye tracking data may not be available.</span></span> <span data-ttu-id="e8916-269">Aunque algunos usuarios pueden haber decidido revocar el acceso a sus datos de seguimiento ocular y son correctos con la desventaja de una experiencia de usuario inferior a la privacidad de no proporcionar acceso a los datos de seguimiento ocular, en algunos casos esto puede ser involuntaria.</span><span class="sxs-lookup"><span data-stu-id="e8916-269">While some users may have consciously decided to revoke access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="e8916-270">Por lo tanto, si la aplicación usa el seguimiento ocular y esta es una parte importante de la experiencia, recomendamos que se comunique claramente al usuario.</span><span class="sxs-lookup"><span data-stu-id="e8916-270">Hence, if your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span> <span data-ttu-id="e8916-271">Informar a los usuarios de por qué el seguimiento ocular es fundamental para su aplicación (quizás incluso mostrar algunas características mejoradas) para experimentar todo el potencial de su aplicación puede ayudar al usuario a comprender mejor lo que están ofreciendo.</span><span class="sxs-lookup"><span data-stu-id="e8916-271">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application can help the user to better understand what they are giving up.</span></span> <span data-ttu-id="e8916-272">Ayudar al usuario a identificar por qué el seguimiento ocular puede no funcionar (en función de las comprobaciones anteriores) y ofrecer algunas sugerencias para solucionar rápidamente posibles problemas.</span><span class="sxs-lookup"><span data-stu-id="e8916-272">Help the user to identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> <span data-ttu-id="e8916-273">Por ejemplo, si puede detectar que el sistema admite el seguimiento ocular, el usuario está calibrado e incluso ha dado su permiso, pero no se reciben datos de seguimiento ocular, puede que esto señale a otros problemas, como manchas o ojos que se ocluidos.</span><span class="sxs-lookup"><span data-stu-id="e8916-273">For example, if you can detect that the system supports eye tracking, the user is calibrated and even has given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> <span data-ttu-id="e8916-274">No obstante, tenga en cuenta que hay casos poco frecuentes de usuarios para los que es posible que el seguimiento ocular simplemente no funcione.</span><span class="sxs-lookup"><span data-stu-id="e8916-274">Please note though that there are rare cases of users for whom eye tracking may simply not work.</span></span> <span data-ttu-id="e8916-275">Por lo tanto, sea respetuoso de eso permitiendo descartar o incluso deshabilitar recordatorios para habilitar el seguimiento ocular en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="e8916-275">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="e8916-276">2. Reserva para aplicaciones con miras ocular como puntero de entrada principal</span><span class="sxs-lookup"><span data-stu-id="e8916-276">2. Fallback for apps using eye-gaze as a primary input pointer</span></span>
<span data-ttu-id="e8916-277">Si la aplicación usa la vista de puntero para seleccionar rápidamente los hologramas en toda la escena, aunque los datos de seguimiento ocular no están disponibles, se recomienda revertir al encabezado y empezar a mostrar el cursor de miras hacia abajo.</span><span class="sxs-lookup"><span data-stu-id="e8916-277">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="e8916-278">Se recomienda utilizar un tiempo de espera (por ejemplo, 500 – 1500 MS) para determinar si se debe cambiar o no.</span><span class="sxs-lookup"><span data-stu-id="e8916-278">We recommend using a timeout (e.g., 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="e8916-279">Esto es para evitar que se extraiga un cursor cada vez que el sistema pierda el seguimiento debido a movimientos de ojos o guiños y parpadeos.</span><span class="sxs-lookup"><span data-stu-id="e8916-279">This is to prevent popping up a cursor every time the system may briefly lose tracking due to fast eye motions or winks and blinks.</span></span> <span data-ttu-id="e8916-280">Si es un desarrollador de Unity, la reserva automática para la cabeza de mira ya está controlada en el kit de herramientas de realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="e8916-280">If you are a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="e8916-281">Si es un desarrollador de DirectX, debe administrar este conmutador usted mismo.</span><span class="sxs-lookup"><span data-stu-id="e8916-281">If you are a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="e8916-282">3. Reserva para otras aplicaciones específicas del seguimiento ocular</span><span class="sxs-lookup"><span data-stu-id="e8916-282">3. Fallback for other eye-tracking-specific applications</span></span>
<span data-ttu-id="e8916-283">La aplicación puede usar miradamente en una forma única que se adapte específicamente a los ojos; por ejemplo, para animar los ojos de un avatar o para mapas térmicosr la atención basada en el ojo con información precisa sobre la atención visual.</span><span class="sxs-lookup"><span data-stu-id="e8916-283">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes - for example, for animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="e8916-284">En este caso, no hay ninguna reserva clara.</span><span class="sxs-lookup"><span data-stu-id="e8916-284">In this case, there is no clear fallback.</span></span> <span data-ttu-id="e8916-285">Si el seguimiento ocular no está disponible, es posible que estas funcionalidades simplemente deban deshabilitarse.</span><span class="sxs-lookup"><span data-stu-id="e8916-285">If eye tracking is not available, these capabilities may simply need to be disabled.</span></span> 

<br>

<span data-ttu-id="e8916-286">Esperamos que esta página le haya proporcionado una buena introducción para empezar a comprender el papel del seguimiento ocular y la entrada de mirada para HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="e8916-286">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="e8916-287">Para empezar a desarrollar, eche un vistazo a nuestra información sobre [la vista de la mirada en Unity](https://aka.ms/mrtk-eyes) y [la mirada en DirectX](gaze-in-directx.md).</span><span class="sxs-lookup"><span data-stu-id="e8916-287">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="e8916-288">Vea también</span><span class="sxs-lookup"><span data-stu-id="e8916-288">See also</span></span>
* [<span data-ttu-id="e8916-289">Miras a la vista en DirectX</span><span class="sxs-lookup"><span data-stu-id="e8916-289">Eye-gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="e8916-290">Mirada a la vista de Unity (kit de herramientas de realidad mixta)</span><span class="sxs-lookup"><span data-stu-id="e8916-290">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="e8916-291">Calibración</span><span class="sxs-lookup"><span data-stu-id="e8916-291">Calibration</span></span>](calibration.md)
* [<span data-ttu-id="e8916-292">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="e8916-292">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="e8916-293">Gestos con la mano</span><span class="sxs-lookup"><span data-stu-id="e8916-293">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="e8916-294">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="e8916-294">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="e8916-295">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="e8916-295">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="e8916-296">Comodidad</span><span class="sxs-lookup"><span data-stu-id="e8916-296">Comfort</span></span>](comfort.md)
