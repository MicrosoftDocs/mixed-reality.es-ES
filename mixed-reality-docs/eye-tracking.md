---
title: Seguimiento de los ojos
description: Seguimiento de los ojos
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Eye Tracking, Mixed Reality, Input, Eye Gaze
ms.openlocfilehash: 7298a34a946f86aaf789cfe44ad971169fc8ece3
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 06/05/2019
ms.locfileid: "66453704"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="cb2cf-104">Seguimiento de los ojos en HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="cb2cf-104">Eye tracking on HoloLens 2</span></span>
<span data-ttu-id="cb2cf-105">HoloLens 2 ofrece un nivel completamente nuevo de conocimiento del contexto y del comportamiento humano dentro de la experiencia holográfica al proporcionar a los desarrolladores la increíble capacidad de usar información sobre lo que están mirando los usuarios.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-105">HoloLens 2 allows for a whole new level of context and human understanding within the holographic experience by providing developers with the incredible ability of using information about what users are looking at.</span></span> <span data-ttu-id="cb2cf-106">Esta página proporciona información general sobre cómo pueden aprovechar los desarrolladores el seguimiento de los ojos para varios casos de uso y qué debe tenerse en cuenta al diseñar interfaces de usuario basadas en la mirada con los ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-106">This page gives an overview of how developers can benefit from eye tracking for various use cases and what to look out for when designing eye-gaze-based user interfaces.</span></span> 

## <a name="use-cases"></a><span data-ttu-id="cb2cf-107">Casos de uso</span><span class="sxs-lookup"><span data-stu-id="cb2cf-107">Use cases</span></span>
<span data-ttu-id="cb2cf-108">El seguimiento de los ojos permite a las aplicaciones realizar un seguimiento de dónde mira el usuario en tiempo real.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-108">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="cb2cf-109">En esta sección se describen algunos de los posibles casos de uso y las interacciones novedosas que son posibles mediante el seguimiento de los ojos en la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-109">This section describes some of the potential use cases and novel interactions that become possible with eye tracking in mixed reality.</span></span>
<span data-ttu-id="cb2cf-110">Antes de comenzar, a continuación se mencionará [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) varias veces, ya que proporciona varios ejemplos interesantes y eficaces para usar el seguimiento de los ojos, como la selección rápida y sin esfuerzo de objetivos mediante los ojos y el desplazamiento automático por texto en función de dónde mira el usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-110">Before getting started, in the following we will mention the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) several times as it provides several interesting and powerful examples for using eye tracking such as quick and effortless eye-supported target selections and automatically scrolling through text based on where the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="cb2cf-111">Intención del usuario</span><span class="sxs-lookup"><span data-stu-id="cb2cf-111">User intent</span></span>    
<span data-ttu-id="cb2cf-112">La información acerca de dónde mira un usuario proporciona un potente **contexto para otras entradas**, como las de voz, manos y controlador.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-112">Information about where a user looks at provides a powerful **context for other inputs**, such as voice, hands and controllers.</span></span>
<span data-ttu-id="cb2cf-113">Esta información puede utilizarse para varias tareas.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-113">This can be used for various tasks.</span></span>
<span data-ttu-id="cb2cf-114">Por ejemplo, puede servir para **enfocar** rápidamente y sin esfuerzo objetivos por la escena solo con mirar un holograma y decir "Seleccionar" (consulta también [Mirada con la cabeza y confirmación](gaze-and-commit.md)) o para decir "Coloca esto..." y, a continuación, mirar al lugar donde deseas colocar el holograma y decir "...ahí".</span><span class="sxs-lookup"><span data-stu-id="cb2cf-114">For example, this may range from quickly and effortlessly **targeting** across the scene by simply looking at a hologram and saying "select" (also see [Head-gaze and commit](gaze-and-commit.md)) or by saying "put this...", then looking over to where you want to place the hologram and say "...there".</span></span> <span data-ttu-id="cb2cf-115">Puedes consultar varios ejemplos en [Mixed Reality Toolkit: Selección de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) y [Mixed Reality Toolkit: Posicionamiento de objetivos con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-115">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="cb2cf-116">Otro ejemplo relacionado con la intención del usuario es usar la información sobre lo que mira el usuario para mejorar la interacción con agentes virtuales integrados y hologramas interactivos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-116">An additional example for user intent may include using information about what users look at to enhance the engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="cb2cf-117">Por ejemplo, los agentes virtuales pueden adaptar las opciones disponibles y su comportamiento según el contenido visualizado en cada momento.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-117">For example, virtual agents may adapt available options and their behavior based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="cb2cf-118">Acciones implícitas</span><span class="sxs-lookup"><span data-stu-id="cb2cf-118">Implicit actions</span></span>
<span data-ttu-id="cb2cf-119">La categoría de acciones implícitas está estrechamente relacionada con la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-119">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="cb2cf-120">La idea es que los hologramas o los elementos de la interfaz de usuario reaccionen de manera prácticamente instintiva, de modo que casi no parezca que el usuario interactúa con el sistema, sino que el sistema y el usuario están sincronizados. Un ejemplo muy eficaz es el del **desplazamiento automático basado en la mirada con los ojos**.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-120">The idea is that holograms or user interface elements react in a somewhat instinctual way that may not even feel like you are interacting with the system at all, but rather that the system and the user are in sync. For example, one immensely successful example is **eye-gaze-based auto scroll**.</span></span> <span data-ttu-id="cb2cf-121">La idea es muy sencilla: El usuario lee un texto y puede seguir leyendo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-121">The idea is as simple: The user reads a text and can just keep on reading.</span></span> <span data-ttu-id="cb2cf-122">El texto se mueve hacia arriba gradualmente para que el usuario pueda seguir leyendo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-122">The text gradually moves up to keep users in their reading flow.</span></span> <span data-ttu-id="cb2cf-123">Un aspecto clave es que la velocidad de desplazamiento se adapta a la velocidad de lectura del usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-123">A key aspect is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="cb2cf-124">Otro ejemplo es el **zoom y el desplazamiento lateral con los ojos** que hace que el usuario sienta que se dirige exactamente hacia donde enfoca.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-124">Another example is **eye-supported zoom and pan** for which the user can feel like diving exactly toward what he or she is focusing at.</span></span> <span data-ttu-id="cb2cf-125">La activación del zoom y el control de su velocidad pueden realizarse con la voz o manualmente, lo que resulta importante para transmitir una sensación de control y evitar abrumar al usuario (más adelante se describen con más detalle estas directrices de diseño).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-125">Triggering the zoom and controlling the zoom speed can be controlled via voice or hand input which is important about providing the feeling of control and avoid overwhelming the user (we will talk about these design guidelines in more detail below).</span></span> <span data-ttu-id="cb2cf-126">Tras acercar la imagen con el zoom, el usuario puede seguir de manera fluida, por ejemplo, el curso de una calle para explorar su vecindario simplemente mirando con los ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-126">Once zoomed in, the user can then smoothly follow, for example, the course of a street to explore his or her neighborhood just simply by using their eye gaze.</span></span>
<span data-ttu-id="cb2cf-127">Puedes consultar ejemplos de demostración de estos tipos de interacciones en el ejemplo [Mixed Reality Toolkit - Navegación con los ojos](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-127">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="cb2cf-128">A continuación, se indican algunos otros casos de uso para _acciones implícitas_:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-128">Additional use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="cb2cf-129">**Notificaciones inteligentes:** ¿Te molesta que aparezcan notificaciones justo donde estabas mirando?</span><span class="sxs-lookup"><span data-stu-id="cb2cf-129">**Smart notifications:** Ever get annoyed by notifications popping up right where you were focusing?</span></span> <span data-ttu-id="cb2cf-130">La experiencia puede mejorar si se tiene en cuenta dónde está centrando el usuario su atención en cada momento.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-130">Taking into account where a user is currently paying attention to, you can make it better!</span></span> <span data-ttu-id="cb2cf-131">Muestra notificaciones desplazadas de donde está mirando actualmente el usuario para limitar las distracciones y ciérralas automáticamente una vez leídas.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-131">Show notifications offset from where the user is currently looking to limit distractions and automatically dismiss them once finished reading.</span></span> 
- <span data-ttu-id="cb2cf-132">**Hologramas atentos:** Hologramas que reaccionan sutilmente cuando se les mira.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-132">**Attentive holograms:** Holograms that subtly react when being looked at.</span></span> <span data-ttu-id="cb2cf-133">Pueden ser elementos de la interfaz de usuario que brillan ligeramente, una flor que se abre lentamente o una mascota virtual que te devuelve la mirada o evita el contacto visual tras mirarla durante un tiempo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-133">This may range from slightly glowing UI elements, a slowly blooming flower to a virtual pet starting to look back at you or trying to avoid your eye gaze after a prolonged stare.</span></span> <span data-ttu-id="cb2cf-134">Esto puede proporcionar una interesante sensación de conectividad y satisfacción en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-134">This may provide an interesting sense of connectivity and satisfaction in your app.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="cb2cf-135">Seguimiento de la atención</span><span class="sxs-lookup"><span data-stu-id="cb2cf-135">Attention tracking</span></span>   
<span data-ttu-id="cb2cf-136">La información acerca de dónde miran los usuarios es una herramienta increíblemente eficaz para evaluar la utilidad de diseños e identificar problemas en flujos de trabajo eficientes.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-136">Information about where users look at is an immensely powerful tool to assess usability of designs and to identify problems in efficient work streams.</span></span> <span data-ttu-id="cb2cf-137">Actualmente, los análisis y la visualización con seguimiento de los ojos ya son una práctica habitual en varias áreas de aplicación.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-137">By now,  eye tracking visualization and analytics are already a common practice in various application areas.</span></span> <span data-ttu-id="cb2cf-138">Con HoloLens 2, proporcionamos una nueva dimensión de este conocimiento, ya que es posible situar hologramas 3D en contextos reales y evaluarlos en esas situaciones.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-138">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed alongside.</span></span> <span data-ttu-id="cb2cf-139">[Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) proporciona ejemplos básicos para el registro y la carga de datos de seguimiento de los ojos y cómo visualizarlos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-139">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and for how to visualize them.</span></span>

<span data-ttu-id="cb2cf-140">Algunas aplicaciones en esta área son las siguientes:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-140">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="cb2cf-141">**Visualización de mirada con los ojos remota:** Visualiza lo que están mirando colaboradores remotos para, por ejemplo, asegurarte de que las instrucciones se entienden y siguen correctamente.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-141">**Remote eye gaze visualization:** Visualize what remote collaborators are looking at to, for example, ensure whether instructions are correctly understood and followed.</span></span>
-   <span data-ttu-id="cb2cf-142">**Estudios de investigación con usuarios:** El seguimiento de la atención puede usarse para comparar la manera en que los usuarios inexpertos y los expertos analizan visualmente contenido o su coordinación ojo-mano en tareas complejas (por ejemplo, al analizar datos médicos o al manejar maquinaria).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-142">**User research studies:** Attention tracking can be used to explore the way novice vs. experts users visually analyze content or their hand-eye-coordination for complex tasks (e.g., for analysis of medical data or while operating machinery).</span></span>
-   <span data-ttu-id="cb2cf-143">**Entrenamiento de simulaciones y supervisión del rendimiento:** Practica y optimiza la ejecución de tareas mediante una identificación de cuellos de botella más eficaz en el flujo de ejecución.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-143">**Training simulations and Performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span>
-   <span data-ttu-id="cb2cf-144">**Evaluaciones de diseño, publicidad y estudios de mercado:** El seguimiento de los ojos es una herramienta común en estudios de mercado para evaluar los diseños de productos y sitios web.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-144">**Design evaluations, advertisement and marketing research:** Eye tracking is a common tool for market research to evaluate website and product designs.</span></span>

### <a name="additional-use-cases"></a><span data-ttu-id="cb2cf-145">Casos de uso adicionales</span><span class="sxs-lookup"><span data-stu-id="cb2cf-145">Additional use cases</span></span>
- <span data-ttu-id="cb2cf-146">**Videojuegos:** ¿Alguna vez has deseado tener superpoderes?</span><span class="sxs-lookup"><span data-stu-id="cb2cf-146">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="cb2cf-147">Esta es tu oportunidad.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-147">Here's your chance!</span></span> <span data-ttu-id="cb2cf-148">Haz que los hologramas leviten con solo mirarlos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-148">Levitate holograms by staring at them.</span></span> <span data-ttu-id="cb2cf-149">Dispara rayos láser con los ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-149">Shoot laser beams from your eyes.</span></span> <span data-ttu-id="cb2cf-150">Congela a tus enemigos o conviértelos en piedra.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-150">Turn enemies into stone or freeze them!</span></span> <span data-ttu-id="cb2cf-151">Usa tu visión de rayos X para explorar edificios.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-151">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="cb2cf-152">El límite es tu imaginación.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-152">Your imagination is the limit!</span></span>  

- <span data-ttu-id="cb2cf-153">**Avatares expresivos:** El seguimiento de los ojos ayuda a conseguir avatares 3D más expresivos mediante el uso de datos de seguimiento de ojos en vivo para animar los ojos del avatar de forma que indiquen lo que el usuario está mirando actualmente.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-153">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking date to animate the avatar's eyes to indicate what the user is currently looking at.</span></span> <span data-ttu-id="cb2cf-154">Además, aporta más expresividad mediante guiños y parpadeos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-154">It also adds more expressiveness by adding winks and blinks.</span></span> 

- <span data-ttu-id="cb2cf-155">**Entrada de texto:** El seguimiento de los ojos puede ser una alternativa interesante para introducir texto sin esfuerzo, especialmente cuando no es práctico usar la voz o las manos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-155">**Text entry:** Eye tracking can be used as an interesting alternative for low-effort text entry especially when speech or hands are inconvenient to use.</span></span> 


## <a name="eye-tracking-api"></a><span data-ttu-id="cb2cf-156">API de seguimiento de los ojos</span><span class="sxs-lookup"><span data-stu-id="cb2cf-156">Eye tracking API</span></span>
<span data-ttu-id="cb2cf-157">Antes de entrar en detalles sobre las directrices de diseño específicas para la interacción de mirada con los ojos, expondremos brevemente las funcionalidades que ofrece el seguidor de ojos de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-157">Before going into detail about the specific design guidelines for eye-gaze interaction, we want to briefly point to the capabilities that the HoloLens 2 Eye Tracker is providing.</span></span> <span data-ttu-id="cb2cf-158">La [API de seguimiento de los ojos](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) es accesible mediante: `Windows.Perception.People.EyesPose`.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-158">The [Eye Tracking API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose) is accessible through: `Windows.Perception.People.EyesPose`.</span></span> <span data-ttu-id="cb2cf-159">Proporciona un único haz de mirada con los ojos (origen y dirección de la mirada) a los desarrolladores.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-159">It provides a single eye gaze ray (gaze origin and direction) to developers.</span></span>
<span data-ttu-id="cb2cf-160">El seguidor de ojos proporciona datos a _30 FPS_ aproximadamente.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-160">The eye tracker provides data at about _30 FPS_.</span></span>
<span data-ttu-id="cb2cf-161">La mirada con los ojos prevista se encuentra a entre</span><span class="sxs-lookup"><span data-stu-id="cb2cf-161">The predicted eye gaze lies within ca.</span></span> <span data-ttu-id="cb2cf-162">1 y 1,5 grados aproximadamente en ángulo visual en torno al objetivo enfocado.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-162">1.0 - 1.5 degrees in visual angle around the actual looked at target.</span></span> <span data-ttu-id="cb2cf-163">Caben esperar pequeñas imprecisiones, por lo que debe dejarse algo de margen para este valor límite inferior.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-163">As slight imprecisions are expected, you should plan for some margin around this lower bound value.</span></span> <span data-ttu-id="cb2cf-164">Más adelante se tratará este aspecto en detalle.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-164">We will discuss this more below.</span></span> <span data-ttu-id="cb2cf-165">Para que el seguimiento de los ojos funcione con precisión, cada usuario debe realizar una calibración de seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-165">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="cb2cf-166">![Tamaño de objetivo óptimo a una distancia de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="cb2cf-166">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="cb2cf-167">*Tamaño de objetivo óptimo a una distancia de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="cb2cf-167">*Optimal target size at 2 meter distance*</span></span>


## <a name="eye-gaze-design-guidelines"></a><span data-ttu-id="cb2cf-168">Directrices para el diseño de mirada con los ojos</span><span class="sxs-lookup"><span data-stu-id="cb2cf-168">Eye gaze design guidelines</span></span>
<span data-ttu-id="cb2cf-169">La creación de una interacción que aproveche el enfoque de los ojos en rápido movimiento puede ser complicada.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-169">Building an interaction that takes advantage of fast moving eye targeting can be challenging.</span></span> <span data-ttu-id="cb2cf-170">En esta sección, se resumen las principales ventajas y desafíos que tener en cuenta al diseñar la aplicación.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-170">In this section, we summarize the key advantages and challenges to take into account when designing your app.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="cb2cf-171">Ventajas de la entrada mediante mirada con los ojos</span><span class="sxs-lookup"><span data-stu-id="cb2cf-171">Benefits of eye gaze input</span></span>
- <span data-ttu-id="cb2cf-172">**Señalización a alta velocidad.**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-172">**High speed pointing.**</span></span> <span data-ttu-id="cb2cf-173">El músculo ocular es el que más rápido reacciona en el cuerpo humano.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-173">The eye muscle is the fastest reacting muscle in our body.</span></span> 

- <span data-ttu-id="cb2cf-174">**Poco esfuerzo.**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-174">**Low effort.**</span></span> <span data-ttu-id="cb2cf-175">Prácticamente no se necesita ningún movimiento físico.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-175">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="cb2cf-176">**Implícito.**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-176">**Implicitness.**</span></span> <span data-ttu-id="cb2cf-177">La información sobre los movimientos oculares de un usuario permite al sistema saber con qué objetivo planea interactuar el usuario, lo que suele describirse como "leer la mente".</span><span class="sxs-lookup"><span data-stu-id="cb2cf-177">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage with.</span></span> 

- <span data-ttu-id="cb2cf-178">**Canal de entrada alternativo.**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-178">**Alternative input channel.**</span></span> <span data-ttu-id="cb2cf-179">La mirada con los ojos puede ofrecer una entrada eficaz alternativa a las entradas con la mano y con la voz, respaldada por años de experiencia de usuarios basada en su coordinación ojo-mano.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-179">Eye gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="cb2cf-180">**Atención visual.**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-180">**Visual attention.**</span></span> <span data-ttu-id="cb2cf-181">Otra ventaja importante es la posibilidad de deducir a qué presta atención un usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-181">Another important benefit is the possibility to infer what a user's is paying attention to.</span></span> <span data-ttu-id="cb2cf-182">Esto puede resultar útil en varias áreas de aplicación, como para evaluar más eficazmente diseños diferentes o para crear interfaces de usuario más inteligentes y mejorar indicaciones sociales para comunicación remota.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-182">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter User Interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="cb2cf-183">En pocas palabras, el uso de la mirada con los ojos como entrada ofrece potencialmente una señal contextual rápida y sin esfuerzo. Esto es especialmente eficaz en combinación con otras entradas, como la de *voz* y la *manual*, para confirmar la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-183">In a nutshell, using eye gaze as an input potentially offers a fast and effortless contextual signal - This is particularly powerful in combination with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="cb2cf-184">Desafíos de la mirada con los ojos como entrada</span><span class="sxs-lookup"><span data-stu-id="cb2cf-184">Challenges of eye gaze as an input</span></span>
<span data-ttu-id="cb2cf-185">Un gran poder conlleva una gran responsabilidad: Aunque la mirada con los ojos puede usarse para crear experiencias mágicas en las que el usuario puede sentirse como un superhéroe, también es importante saber en qué casos no resulta tan eficaz para tener esto en cuenta cuando corresponda.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-185">With lots of power, comes lots of responsibility: While eye gaze can be used to create magical user experiences feeling like a superhero, it is also important to know what it is not good at to account for this appropriately.</span></span> <span data-ttu-id="cb2cf-186">A continuación, se describen algunos *desafíos* que tener en cuenta y cómo abordarlos al trabajar con la entrada mediante mirada con los ojos:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-186">In the following, we discuss some *challenges* to take into account and how to address them when working with eye gaze input:</span></span> 

- <span data-ttu-id="cb2cf-187">**La mirada con los ojos "siempre está activada".** En el momento en el que abres los párpados, los ojos comienzan a fijar cosas por el entorno.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-187">**Your eye gaze is "always on"** The moment you open your eye lids, your eyes start fixating things in your environment.</span></span> <span data-ttu-id="cb2cf-188">Si se reacciona a cada cosa que miras, con la posibilidad de que se desencadenen acciones por error porque has mantenido la mirada sobre algo demasiado tiempo, la experiencia resultaría terrible.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-188">Reacting to every look you make and potentially accidentally issuing actions because you looked at something for too long would result in a terrible experience!</span></span>
<span data-ttu-id="cb2cf-189">Por esta razón, se recomienda combinar la mirada con los ojos con un *comando de voz*, un *gesto con la mano*, un *clic de botón* o con permanencia prolongada para desencadenar la selección de un objetivo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-189">This is why we recommend combining eye gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target.</span></span>
<span data-ttu-id="cb2cf-190">Esta solución también admite un modo en que el usuario puede mirar libremente sin la abrumadora sensación de desencadenar involuntariamente algo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-190">This solution also allows for a mode in which the user can freely look around without the overwhelming feeling of involuntarily triggering something.</span></span> <span data-ttu-id="cb2cf-191">Esta cuestión también debe tenerse en cuenta al diseñar la información visual y auditiva que se recibe con solo mirar a un objetivo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-191">This issue should also be taken into account when designing visual and auditory feedback when merely looking at a target.</span></span>
<span data-ttu-id="cb2cf-192">No debe sobrecargarse al usuario con efectos emergentes inmediatos o sonidos al pasar sobre los elementos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-192">Do not overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="cb2cf-193">La clave es la sutileza.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-193">Subtlety is key!</span></span> <span data-ttu-id="cb2cf-194">Más adelante, en las recomendaciones de diseño, se describen algunos de los procedimientos recomendados para esto.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-194">We will discuss some best practices for this further below when talking about design recommendations.</span></span>

- <span data-ttu-id="cb2cf-195">**Observación frente a control.** Supón que deseas alinear una fotografía con la pared de forma precisa.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-195">**Observation vs. control** Imagine you want to precisely align a photograph at your wall.</span></span> <span data-ttu-id="cb2cf-196">Miras los bordes y la zona circundante para ver si está bien alineada.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-196">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="cb2cf-197">Ahora imagina cómo podrías hacerlo si al mismo tiempo quieres utilizar la mirada con los ojos como entrada para mover la imagen.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-197">Now imagine how you would do that when at the same time you want to use your eye gaze as an input to move the picture.</span></span> <span data-ttu-id="cb2cf-198">Difícil, ¿verdad?</span><span class="sxs-lookup"><span data-stu-id="cb2cf-198">Difficult, isn't it?</span></span> <span data-ttu-id="cb2cf-199">Esto describe la doble función de la mirada con los ojos cuando se necesita como entrada y como control.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-199">This describes the double role of eye gaze when it is required both for input and control.</span></span> 

- <span data-ttu-id="cb2cf-200">**Salir antes de hacer clic:** Los estudios han demostrado que, para selecciones de objetivos rápidas, la mirada con los ojos del usuario puede desplazarse antes de concluir un clic manual (por ejemplo, al pulsar en el aire).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-200">**Leave before click:** For quick target selections, research has shown that a user's eye gaze may move on before concluding a manual click (e.g., an airtap).</span></span> <span data-ttu-id="cb2cf-201">Por lo tanto, se debe prestar especial atención a la sincronización de la señal de la mirada con los ojos rápida con la entrada de un control más lento (por ejemplo, una entrada de voz, manos o controlador).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-201">Hence, special attention must be paid to synchronizing the fast eye gaze signal with slower control input (e.g., voice, hands, controller).</span></span>

- <span data-ttu-id="cb2cf-202">**Objetivos pequeños:** Piensa en la sensación al intentar leer texto que es demasiado pequeño para leerse cómodamente.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-202">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to comfortably read?</span></span> <span data-ttu-id="cb2cf-203">Es una sensación estresante para los ojos, que provoca agotamiento al intentar reajustar los ojos para enfocar mejor.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-203">This straining feeling on your eyes that cause you to feel tired and worn out because you try to readjust your eyes to focus better?</span></span>
<span data-ttu-id="cb2cf-204">Esta misma sensación es la que puedes hacer sentir a los usuarios si los obligas a seleccionar objetivos demasiado pequeños en la aplicación mediante la mirada con los ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-204">This is a feeling you may invoke in your users when forcing them to select too small targets in your app using eye targeting.</span></span>
<span data-ttu-id="cb2cf-205">Al diseñar la aplicación, para crear una experiencia agradable y cómoda para los usuarios, se recomienda que los objetivos sean al menos de 2° en ángulo visual, o preferiblemente mayores.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-205">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="cb2cf-206">**Movimientos de mirada con los ojos irregulares.** Los ojos realizan movimientos rápidos al pasar de fijarse en un elemento a fijarse en otro.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-206">**Ragged eye gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="cb2cf-207">Si observas las trayectorias de movimientos registrados de ojos, podrás ver que son irregulares.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-207">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="cb2cf-208">Los ojos se mueven rápidamente y a saltos espontáneos en comparación con la *mirada con la cabeza* o los *movimientos manuales*.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-208">Your eyes move quickly and in spontaneous jumps in comparison to *head gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="cb2cf-209">**Confiabilidad del seguimiento:** La precisión del seguimiento de los ojos puede verse mermada con los cambios de luz, al ajustarse los ojos a las nuevas condiciones.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-209">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eye adjust to the new conditions.</span></span>
<span data-ttu-id="cb2cf-210">Aunque esto no debe necesariamente afectar al diseño de tu aplicación, ya que la precisión debe oscilar dentro de la limitación de 2° mencionada anteriormente,</span><span class="sxs-lookup"><span data-stu-id="cb2cf-210">While this should not necessarily affect your app design, as the accuracy should be within the above mentioned limitation of 2°.</span></span> <span data-ttu-id="cb2cf-211">sí puede significar que el usuario tenga que realizar otra calibración.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-211">It may mean that the user has to run another calibration.</span></span> 


### <a name="design-recommendations"></a><span data-ttu-id="cb2cf-212">Recomendaciones de diseño</span><span class="sxs-lookup"><span data-stu-id="cb2cf-212">Design recommendations</span></span>
<span data-ttu-id="cb2cf-213">A continuación, se enumeran las recomendaciones de diseño específicas en función de las ventajas y desafíos descritos para la entrada mediante mirada con los ojos:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-213">In the following, we list specific design recommendations based on the described advantages and challenges for eye gaze input:</span></span>

1. <span data-ttu-id="cb2cf-214">**La mirada con los ojos no es lo mismo que la mirada con la cabeza:**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-214">**Eye gaze != Head gaze:**</span></span>
    - <span data-ttu-id="cb2cf-215">**Ten en cuenta si los movimientos rápidos e irregulares de los ojos funcionan bien para la tarea de entrada:** Aunque los movimientos rápidos e irregulares de los ojos son excelentes para seleccionar rápidamente objetivos en nuestro campo de visión, son menos eficaces para tareas que requieren trayectorias de entrada suaves (por ejemplo, para dibujar o rodear anotaciones con un círculo).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-215">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great to quickly select targets across our Field of View, it is less applicable for tasks that require smooth input trajectories (e.g., for drawing or encircling annotations).</span></span> <span data-ttu-id="cb2cf-216">En este caso, es preferible apuntar con la mano o con la cabeza.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-216">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="cb2cf-217">**Evita asociar elementos directamente a la mirada con los ojos del usuario (por ejemplo, un control deslizante o un cursor).**</span><span class="sxs-lookup"><span data-stu-id="cb2cf-217">**Avoid attaching something directly to the user’s eye gaze (e.g., a slider or cursor).**</span></span>
<span data-ttu-id="cb2cf-218">En el caso de un cursor, esto podría provocar un efecto de fuga del cursor, debido a ligeros desplazamientos en la señal de la mirada con los ojos proyectada.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-218">In case of a cursor, this may result in the “fleeing cursor” effect due to slight offsets in the projected eye gaze signal.</span></span> <span data-ttu-id="cb2cf-219">En el caso de un control deslizante, surge un conflicto con la doble función de controlar el control deslizante con los ojos mientras también se desea comprobar que el objeto se encuentra en la ubicación correcta.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-219">In case of a slider, it conflicts with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="cb2cf-220">En pocas palabras, un usuario puede rápidamente sentirse abrumado y distraerse, especialmente si la señal es imprecisa para ese usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-220">In a nutshell, users may quickly feel overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="cb2cf-221">**Combina la mirada con los ojos con otras entradas:** La integración del seguimiento de los ojos con otras entradas, como gestos manuales, comandos de voz o la pulsación de un botón, tiene varias ventajas:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-221">**Combine eye gaze with other inputs:** The integration of Eye Tracking with other inputs, such as hand gestures, voice commands or button presses, serves several advantages:</span></span>
    - <span data-ttu-id="cb2cf-222">**Permitir la observación libre:** Dado que la función principal de los ojos es observar nuestro entorno, es importante permitir mirar a los usuarios sin activar acciones o información (visual, auditiva, etc.).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-222">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it is important to allow users to look around without triggering any (visual, auditory, ...) feedback or actions.</span></span> 
    <span data-ttu-id="cb2cf-223">La combinación del seguimiento de ojos con otro control de entrada permite una transición fluida entre los modos de control de entrada y de observación con seguimiento de ojos.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-223">Combining ET with another input control allows for smoothly transitioning between ET observation and input control modes.</span></span>
  
    - <span data-ttu-id="cb2cf-224">**Proveedor de contexto eficaz:** Al usar información acerca de dónde mira el usuario mientras se pronuncia un comando de voz o se realiza un gesto con la mano, es posible canalizar sin esfuerzo la entrada por el campo de visión.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-224">**Powerful context provider:** Using information about where the user is looking at while uttering a voice command or performing a hand gesture allows for effortlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="cb2cf-225">Algunos ejemplos son: “Coloca eso ahí” para seleccionar y situar de manera rápida y fluida un holograma en la escena con solo mirar un objetivo y un destino.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-225">Examples include: “Put that there” to quickly and fluently select and position a hologram across the scene by simply looking at a target and destination.</span></span> 

    - <span data-ttu-id="cb2cf-226">**Necesidad de sincronizar entradas multimodales (problema de “salir antes de hacer clic”):** La combinación de rápidos movimientos oculares con entradas adicionales más complejas (por ejemplo, comandos de voz prolongados o gestos con la mano) conlleva el riesgo de desviar la mirada con los ojos antes de finalizar el comando de entrada adicional.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-226">**Need for synchronizing multimodal inputs (“leave before click” issue):** Combining rapid eye movements with more complex additional inputs (e.g., long voice commands or hand gestures) bears the risk of moving on with your eye gaze before finishing the additional input command.</span></span> <span data-ttu-id="cb2cf-227">Por lo tanto, si creas tus propios controles de entrada (por ejemplo, gestos con la mano personalizados), asegúrate de registrar el comienzo de esta entrada o la duración aproximada para relacionarla con el elemento en el que se había fijado el usuario en el pasado.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-227">Hence, if you create your own input controls (e.g., custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had fixated on in the past.</span></span>
    
3. <span data-ttu-id="cb2cf-228">**Información sutil para la entrada de seguimiento de los ojos:** Es útil proporcionar información al mirar un objetivo (para indicar que el sistema funciona según lo previsto) pero debe ser sutil.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-228">**Subtle feedback for eye tracking input:** It is useful to provide feedback if a target is looked at (to indicate that the system is working as intended) but should be kept subtle.</span></span> <span data-ttu-id="cb2cf-229">Esta puede ser información visual destacada que aparece o desaparece lentamente u otros comportamientos sutiles según el objetivo, como movimientos lentos (por ejemplo, aumentar ligeramente el tamaño del objetivo) para indicar que el sistema ha detectado correctamente que el usuario está mirando a un objetivo, sin interrumpir innecesariamente el flujo de trabajo actual del usuario.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-229">This may include slowly blending in/out visual highlights or perform other subtle target behaviors, such as slow motions (e.g., slightly increasing the target) to indicate that the system correctly detected that the user is looking at a target, however, without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="cb2cf-230">**Evita entradas que obliguen a realizar movimientos forzados con los ojos:** No obligues a los usuarios a realizar movimientos con los ojos específicos (gestos de mirada) para desencadenar acciones en la aplicación.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-230">**Avoid enforcing unnatural eye movements as input:** Do not force users to perform specific eye movements (gaze gestures) to trigger actions in your app.</span></span>

5. <span data-ttu-id="cb2cf-231">**Ten en cuenta las imprecisiones:** Podemos distinguir dos tipos de imprecisiones que son visibles para los usuarios: El desplazamiento y las sacudidas.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-231">**Account for imprecisions:** We distinguish two types of imprecisions which are noticeable to users: Offset and Jitter.</span></span> <span data-ttu-id="cb2cf-232">La manera más sencilla de solucionar los desplazamientos es proporcionar objetivos suficientemente grandes para interactuar con ellos (más de 2° en ángulo visual; como referencia: la miniatura es de aproximadamente 2° en ángulo visual al estirar el brazo (1)).</span><span class="sxs-lookup"><span data-stu-id="cb2cf-232">The easiest way to address offsets is to provide sufficiently large targets to interact with (> 2° in visual angle – as reference: your thumbnail is about 2° in visual angle when you stretch out your arm (1)).</span></span> <span data-ttu-id="cb2cf-233">Esto conduce a la siguiente pauta:</span><span class="sxs-lookup"><span data-stu-id="cb2cf-233">This leads to the following guidance:</span></span>
    - <span data-ttu-id="cb2cf-234">No obligues a los usuarios a seleccionar objetivos demasiado pequeños: Hay estudios que han demostrado que si los objetivos son lo suficientemente grandes (y el sistema está correctamente diseñado), los usuarios afirman que la interacción resulta mágica y no requiere esfuerzo.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-234">Do not force users to select tiny targets: Research has shown that if targets are sufficiently large (and the system is designed well), users describe the interaction as effortless and magical.</span></span> <span data-ttu-id="cb2cf-235">Si los objetivos son demasiado pequeños, los usuarios describen la experiencia como agotadora y frustrante.</span><span class="sxs-lookup"><span data-stu-id="cb2cf-235">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
   

## <a name="see-also"></a><span data-ttu-id="cb2cf-236">Consulte también</span><span class="sxs-lookup"><span data-stu-id="cb2cf-236">See also</span></span>
* [<span data-ttu-id="cb2cf-237">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="cb2cf-237">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="cb2cf-238">Control con la cabeza y los ojos de DirectX</span><span class="sxs-lookup"><span data-stu-id="cb2cf-238">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="cb2cf-239">Mirada con los ojos en Unity (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="cb2cf-239">Eye gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="cb2cf-240">Gestos con la mano</span><span class="sxs-lookup"><span data-stu-id="cb2cf-240">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="cb2cf-241">Entrada de voz</span><span class="sxs-lookup"><span data-stu-id="cb2cf-241">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="cb2cf-242">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="cb2cf-242">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="cb2cf-243">Comodidad</span><span class="sxs-lookup"><span data-stu-id="cb2cf-243">Comfort</span></span>](comfort.md)
