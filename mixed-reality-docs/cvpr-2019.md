---
title: Aplicaciones de visión de equipo para taller auriculares de realidad mixta en CVPR 2019
description: Información general y programación de las aplicaciones de visión de equipo para taller auriculares de realidad mixta, entrega en la conferencia CVPR en junio de 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: eventos, el modo de investigación, cvpr, visión de equipo, la investigación, HoloLens
ms.openlocfilehash: ea38256dd5b6b7b36acf9e3d2a209cee8517aed5
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629139"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a>Aplicaciones de la visión de equipo para auriculares de realidad mixta
Long Beach (CA) - 17 de junio de 2019 (tarde)

Organizan junto con [CVPR 2019](http://cvpr2019.thecvf.com/)

## <a name="organizers"></a>Organizadores
* Marc Pollefeys
* Federica Bogo
* Johannes Schönberger
* Osman Ulusoy

## <a name="overview"></a>Información general

![Imagen de un rompecabezas](images/cvpr2019_teaser2.jpg)

Auriculares de realidad mixta, como el Microsoft HoloLens se están convirtiendo en plataformas eficaz para desarrollar aplicaciones de la visión de equipo. El modo de investigación de HoloLens permite investigación sobre Visión de equipo en el dispositivo, ya que proporciona acceso a todas las secuencias de sensor de imagen raw--incluidos profundidad e IR. Como modo de investigación ahora está disponible desde mayo de 2018, estamos comenzando a ver varias demostraciones interesantes y las aplicaciones que se desarrollan para HoloLens. 

El objetivo de este taller es reunir los estudiantes e investigadores interesados en la visión de equipo para las aplicaciones de realidad mixta. El taller proporcionará una ubicación para compartir aplicaciones y demostraciones y aprender entre sí para crear o migrar aplicaciones a la realidad mixta. 

Le animamos a los envíos en los temas de reconocimiento de objetos (ego-centric), disponible y de seguimiento de usuario, reconocimiento de la actividad, sistema, reconstrucción 3D, descripción de la escena, localización basada en sensores, navegación y mucho más.

## <a name="paper-submission"></a>Envío de papel
* Fecha límite de envío de papel: 17 de mayo
* Notificación a los autores: 24 de mayo

Envíos de papel deberían utilizar la plantilla CVPR y están limitados a 4 páginas más referencias. Además, le animamos a los autores para enviar un vídeo que muestra su aplicación.
Tenga en cuenta que los envíos de trabajo publicado anteriormente están permitidos (incluidas trabajo aceptado para la principal conferencia de 2019 CVPR). 

Los envíos se pueden cargar en el CMT: https://cmt3.research.microsoft.com/CVFORMR2019

Se seleccionará un subconjunto de documentos para la presentación oral en el taller. Sin embargo, se recomienda encarecidamente a todos los autores para presentar su trabajo durante la sesión de demostración.


## <a name="schedule"></a>Programa
* 13:30-13:45: Comentarios bienvenidas y la apertura.
* 13:45-14:15: **El discurso de charla**: Prof. Marc Pollefeys, ETH Zurich y Microsoft. Título: TBD.
* 14:15-14:45: **El discurso de charla**: Prof. Kris Kitani, Carnegie Mellon University. Título: TBD.
* 14:45-15:15: **El discurso de charla**: Recuperación ante desastres. Yang Liu, California Institute of Technology. Título: TBD.
* 15:15-16:15: Pausa para café y demostraciones.
* 16:15-16:45: **El discurso de charla**: Prof. Kristen Grauman, University of Texas en investigación de inteligencia artificial de Austin o Facebook. Título: TBD.
* 16:45-17:15: Presentaciones oral.
* 17:15-17:30: Comentarios finales.
