---
title: Aplicaciones de visión de equipo para taller auriculares de realidad mixta en CVPR 2019
description: Información general y programación de las aplicaciones de visión de equipo para taller auriculares de realidad mixta, entrega en la conferencia CVPR en junio de 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: eventos, el modo de investigación, cvpr, visión de equipo, la investigación, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148708"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a>Aplicaciones de la visión de equipo para auriculares de realidad mixta

Organizan junto con [CVPR 2019](http://cvpr2019.thecvf.com/)

Long Beach (CA)

17 de junio de, 2019 tarde) - Hyatt Regency F


## <a name="organizers"></a>Organizadores
* Marc Pollefeys
* Federica Bogo
* Johannes Schönberger
* Osman Ulusoy

## <a name="overview"></a>Información general

![Imagen de un rompecabezas](images/cvpr2019_teaser2.jpg)

Auriculares de realidad mixta, como el Microsoft HoloLens se están convirtiendo en plataformas eficaz para desarrollar aplicaciones de la visión de equipo. El modo de investigación de HoloLens permite investigación sobre Visión de equipo en el dispositivo, ya que proporciona acceso a todas las secuencias de sensor de imagen raw--incluidos profundidad e IR. Como modo de investigación ahora está disponible desde mayo de 2018, estamos comenzando a ver varias demostraciones interesantes y las aplicaciones que se desarrollan para HoloLens. 

El objetivo de este taller es reunir los estudiantes e investigadores interesados en la visión de equipo para las aplicaciones de realidad mixta. El taller proporcionará una ubicación para compartir aplicaciones y demostraciones y aprender entre sí para crear o migrar aplicaciones a la realidad mixta. 

Le animamos a los envíos en los temas de reconocimiento de objetos (ego-centric), disponible y de seguimiento de usuario, reconocimiento de la actividad, sistema, reconstrucción 3D, descripción de la escena, localización basada en sensores, navegación y mucho más.

## <a name="paper-submission"></a>Envío de papel
* Fecha límite de envío de papel: 17 de mayo
* Notificación a los autores: 24 de mayo

Envíos de papel deberían utilizar la plantilla CVPR y están limitados a 4 páginas más referencias. Además, le animamos a los autores para enviar un vídeo que muestra su aplicación.
Tenga en cuenta que los envíos de trabajo publicado anteriormente están permitidos (incluidas trabajo aceptado para la principal conferencia de 2019 CVPR). 

Los envíos se pueden cargar en el CMT: https://cmt3.research.microsoft.com/CVFORMR2019

Se seleccionará un subconjunto de documentos para la presentación oral en el taller. Sin embargo, se recomienda encarecidamente a todos los autores para presentar su trabajo durante la sesión de demostración.


## <a name="schedule"></a>Programa
* 13:30-13:45: Comentarios bienvenidas y la apertura.
* 13:45-14:15: **El discurso de charla**: Prof. Marc Pollefeys, ETH Zurich y Microsoft. Título: Visión de equipo egocentric en HoloLens.
* 14:15-14:45: **El discurso de charla**: Prof. Kris Kitani, Carnegie Mellon University. Título: Actividad egocentric y postura de previsión.
* 14:45-15:15: **El discurso de charla**: Recuperación ante desastres. Yang Liu, California Institute of Technology. Título: Potenciar a un Ayudante cognitivo for the Blind con realidad aumentada.
* 15:15-16:15: Pausa para café y demostraciones.
* 16:15-16:45: **El discurso de charla**: Prof. Kristen Grauman, University of Texas en investigación de inteligencia artificial de Austin o Facebook. Título: Interacción humana-object en primera persona vídeo.
* 16:45-17:15: Presentaciones oral:
    * Registro Debugging made easy - navegación ortopédicos independiente con HoloLens. F. Liebmann, Roner S., M. von Atzigen, Wanivenhaus F., Neuhaus C., Spirig J., D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.
    * Aprendizaje estéreo deambulan con un HoloLens. H. Zhan, Y. Pekelny, O. Ulusoy.
* 17:15-17:30: Comentarios finales.
