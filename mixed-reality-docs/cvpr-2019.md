---
title: Computer Vision aplicaciones para auriculares de realidad mixta Workshop en CVPR 2019
description: Información general y programación de las aplicaciones de Computer Vision para los auriculares con micrófonos de realidad mixta, que se entregarán en la Conferencia de CVPR del 2019 de junio.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: evento, modo de investigación, CVPR, Computer Vision, investigación, HoloLens
ms.openlocfilehash: 89d79bcef77043564e51faada940d2c71a6005e4
ms.sourcegitcommit: 2f600e5ad00cd447b180b0f89192b4b9d86bbc7e
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 06/15/2019
ms.locfileid: "67148708"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="dbddd-104">Computer Vision aplicaciones para auriculares de realidad mixta</span><span class="sxs-lookup"><span data-stu-id="dbddd-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="dbddd-105">Organizado junto con [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="dbddd-105">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="dbddd-106">Larga playa (CA)</span><span class="sxs-lookup"><span data-stu-id="dbddd-106">Long Beach (CA)</span></span>

<span data-ttu-id="dbddd-107">17 de junio de 2019 (tarde)-Hyatt Regency F</span><span class="sxs-lookup"><span data-stu-id="dbddd-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="dbddd-108">Los organizadores</span><span class="sxs-lookup"><span data-stu-id="dbddd-108">Organizers</span></span>
* <span data-ttu-id="dbddd-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="dbddd-109">Marc Pollefeys</span></span>
* <span data-ttu-id="dbddd-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="dbddd-110">Federica Bogo</span></span>
* <span data-ttu-id="dbddd-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="dbddd-111">Johannes Schönberger</span></span>
* <span data-ttu-id="dbddd-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="dbddd-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="dbddd-113">Información general</span><span class="sxs-lookup"><span data-stu-id="dbddd-113">Overview</span></span>

![Imagen de rompecabezas](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="dbddd-115">Los auriculares de realidad mixta, como Microsoft HoloLens, están convirtiéndose en plataformas eficaces para desarrollar aplicaciones para equipos.</span><span class="sxs-lookup"><span data-stu-id="dbddd-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="dbddd-116">El modo de investigación de HoloLens habilita la investigación de Computer Vision en el dispositivo proporcionando acceso a todas las secuencias de sensor de imagen sin procesar, incluida la profundidad y el IR.</span><span class="sxs-lookup"><span data-stu-id="dbddd-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="dbddd-117">Dado que el modo de investigación ahora está disponible desde el 2018 de mayo, comenzamos a ver varias demostraciones interesantes y aplicaciones que se desarrollan para HoloLens.</span><span class="sxs-lookup"><span data-stu-id="dbddd-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="dbddd-118">El objetivo de este taller es reunir a los estudiantes e investigadores interesados en Computer Vision para aplicaciones de realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="dbddd-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="dbddd-119">El taller proporcionará un lugar para compartir demostraciones y aplicaciones y aprenderá entre sí para compilar o migrar aplicaciones a la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="dbddd-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="dbddd-120">Se recomiendan los envíos de los temas de reconocimiento de objetos (centrados en ego), seguimiento de usuarios y mano, reconocimiento de actividades, ABRIREMOS, reconstrucción 3D, comprensión de escenas, localización basada en sensores, navegación, etc.</span><span class="sxs-lookup"><span data-stu-id="dbddd-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="dbddd-121">Envío de papel</span><span class="sxs-lookup"><span data-stu-id="dbddd-121">Paper Submission</span></span>
* <span data-ttu-id="dbddd-122">Fecha límite de envío de papel: 17 de mayo</span><span class="sxs-lookup"><span data-stu-id="dbddd-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="dbddd-123">Notificación a los autores: 24 de mayo</span><span class="sxs-lookup"><span data-stu-id="dbddd-123">Notification to authors: May 24</span></span>

<span data-ttu-id="dbddd-124">Los envíos de papel deben usar la plantilla CVPR y están limitados a 4 páginas más referencias.</span><span class="sxs-lookup"><span data-stu-id="dbddd-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="dbddd-125">Además, se recomienda a los autores que envíen un vídeo en el que se muestre su aplicación.</span><span class="sxs-lookup"><span data-stu-id="dbddd-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="dbddd-126">Tenga en cuenta que se permiten los envíos de trabajos publicados anteriormente (incluido el trabajo aceptado en la Conferencia principal de CVPR 2019).</span><span class="sxs-lookup"><span data-stu-id="dbddd-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="dbddd-127">Los envíos se pueden cargar en el CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="dbddd-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="dbddd-128">Se seleccionará un subconjunto de papeles para la presentación oral en el taller.</span><span class="sxs-lookup"><span data-stu-id="dbddd-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="dbddd-129">Sin embargo, se recomienda encarecidamente a todos los autores que presenten su trabajo durante la sesión de demostración.</span><span class="sxs-lookup"><span data-stu-id="dbddd-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="dbddd-130">Schedule</span><span class="sxs-lookup"><span data-stu-id="dbddd-130">Schedule</span></span>
* <span data-ttu-id="dbddd-131">13:30-13:45: Bienvenido y abrir Comentarios.</span><span class="sxs-lookup"><span data-stu-id="dbddd-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="dbddd-132">13:45-14:15: **Discurso**de la charla: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="dbddd-132">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="dbddd-133">Título: Computer Vision Egocentric en HoloLens.</span><span class="sxs-lookup"><span data-stu-id="dbddd-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="dbddd-134">14:15-14:45: **Discurso**de la charla: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="dbddd-134">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="dbddd-135">Título: Actividad Egocentric y suponer previsión.</span><span class="sxs-lookup"><span data-stu-id="dbddd-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="dbddd-136">14:45-15:15: **Discurso**de la charla: Ruta. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="dbddd-136">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="dbddd-137">Título: Potenciar un asistente cognitivo para la persiana con realidad aumentada.</span><span class="sxs-lookup"><span data-stu-id="dbddd-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="dbddd-138">15:15-16:15: Pausa de café y demostraciones.</span><span class="sxs-lookup"><span data-stu-id="dbddd-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="dbddd-139">16:15-16:45: **Discurso**de la charla: Prof. Kristen Grauman, Universidad de Texas en investigación de la inteligencia artificial de Austin/Facebook.</span><span class="sxs-lookup"><span data-stu-id="dbddd-139">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="dbddd-140">Título: Interacción del objeto humano en el vídeo de la primera persona.</span><span class="sxs-lookup"><span data-stu-id="dbddd-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="dbddd-141">16:45-17:15: Presentaciones orales:</span><span class="sxs-lookup"><span data-stu-id="dbddd-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="dbddd-142">Registro simplificado: navegación Orthopedic independiente con HoloLens.</span><span class="sxs-lookup"><span data-stu-id="dbddd-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="dbddd-143">FORMATO.</span><span class="sxs-lookup"><span data-stu-id="dbddd-143">F.</span></span> <span data-ttu-id="dbddd-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span><span class="sxs-lookup"><span data-stu-id="dbddd-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="dbddd-145">Aprender estéreo con un HoloLens.</span><span class="sxs-lookup"><span data-stu-id="dbddd-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="dbddd-146">C.</span><span class="sxs-lookup"><span data-stu-id="dbddd-146">H.</span></span> <span data-ttu-id="dbddd-147">Zhan, Y. Pekelny, O. Ulusoy.</span><span class="sxs-lookup"><span data-stu-id="dbddd-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="dbddd-148">17:15-17:30: Notas finales.</span><span class="sxs-lookup"><span data-stu-id="dbddd-148">17:15-17:30: Final Remarks.</span></span>
