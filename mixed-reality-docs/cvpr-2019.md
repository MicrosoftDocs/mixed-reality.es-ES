---
title: Aplicaciones de visión de equipo para taller auriculares de realidad mixta en CVPR 2019
description: Información general y programación de las aplicaciones de visión de equipo para taller auriculares de realidad mixta, entrega en la conferencia CVPR en junio de 2019.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: eventos, el modo de investigación, cvpr, visión de equipo, la investigación, HoloLens
ms.openlocfilehash: ea38256dd5b6b7b36acf9e3d2a209cee8517aed5
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629139"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="824f7-104">Aplicaciones de la visión de equipo para auriculares de realidad mixta</span><span class="sxs-lookup"><span data-stu-id="824f7-104">Computer Vision Applications for Mixed Reality Headsets</span></span>
<span data-ttu-id="824f7-105">Long Beach (CA) - 17 de junio de 2019 (tarde)</span><span class="sxs-lookup"><span data-stu-id="824f7-105">Long Beach (CA) - June 17, 2019 (Afternoon)</span></span>

<span data-ttu-id="824f7-106">Organizan junto con [CVPR 2019](http://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="824f7-106">Organized in conjunction with [CVPR 2019](http://cvpr2019.thecvf.com/)</span></span>

## <a name="organizers"></a><span data-ttu-id="824f7-107">Organizadores</span><span class="sxs-lookup"><span data-stu-id="824f7-107">Organizers</span></span>
* <span data-ttu-id="824f7-108">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="824f7-108">Marc Pollefeys</span></span>
* <span data-ttu-id="824f7-109">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="824f7-109">Federica Bogo</span></span>
* <span data-ttu-id="824f7-110">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="824f7-110">Johannes Schönberger</span></span>
* <span data-ttu-id="824f7-111">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="824f7-111">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="824f7-112">Información general</span><span class="sxs-lookup"><span data-stu-id="824f7-112">Overview</span></span>

![Imagen de un rompecabezas](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="824f7-114">Auriculares de realidad mixta, como el Microsoft HoloLens se están convirtiendo en plataformas eficaz para desarrollar aplicaciones de la visión de equipo.</span><span class="sxs-lookup"><span data-stu-id="824f7-114">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="824f7-115">El modo de investigación de HoloLens permite investigación sobre Visión de equipo en el dispositivo, ya que proporciona acceso a todas las secuencias de sensor de imagen raw--incluidos profundidad e IR.</span><span class="sxs-lookup"><span data-stu-id="824f7-115">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="824f7-116">Como modo de investigación ahora está disponible desde mayo de 2018, estamos comenzando a ver varias demostraciones interesantes y las aplicaciones que se desarrollan para HoloLens.</span><span class="sxs-lookup"><span data-stu-id="824f7-116">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="824f7-117">El objetivo de este taller es reunir los estudiantes e investigadores interesados en la visión de equipo para las aplicaciones de realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="824f7-117">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="824f7-118">El taller proporcionará una ubicación para compartir aplicaciones y demostraciones y aprender entre sí para crear o migrar aplicaciones a la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="824f7-118">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="824f7-119">Le animamos a los envíos en los temas de reconocimiento de objetos (ego-centric), disponible y de seguimiento de usuario, reconocimiento de la actividad, sistema, reconstrucción 3D, descripción de la escena, localización basada en sensores, navegación y mucho más.</span><span class="sxs-lookup"><span data-stu-id="824f7-119">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="824f7-120">Envío de papel</span><span class="sxs-lookup"><span data-stu-id="824f7-120">Paper Submission</span></span>
* <span data-ttu-id="824f7-121">Fecha límite de envío de papel: 17 de mayo</span><span class="sxs-lookup"><span data-stu-id="824f7-121">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="824f7-122">Notificación a los autores: 24 de mayo</span><span class="sxs-lookup"><span data-stu-id="824f7-122">Notification to authors: May 24</span></span>

<span data-ttu-id="824f7-123">Envíos de papel deberían utilizar la plantilla CVPR y están limitados a 4 páginas más referencias.</span><span class="sxs-lookup"><span data-stu-id="824f7-123">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="824f7-124">Además, le animamos a los autores para enviar un vídeo que muestra su aplicación.</span><span class="sxs-lookup"><span data-stu-id="824f7-124">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="824f7-125">Tenga en cuenta que los envíos de trabajo publicado anteriormente están permitidos (incluidas trabajo aceptado para la principal conferencia de 2019 CVPR).</span><span class="sxs-lookup"><span data-stu-id="824f7-125">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="824f7-126">Los envíos se pueden cargar en el CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="824f7-126">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="824f7-127">Se seleccionará un subconjunto de documentos para la presentación oral en el taller.</span><span class="sxs-lookup"><span data-stu-id="824f7-127">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="824f7-128">Sin embargo, se recomienda encarecidamente a todos los autores para presentar su trabajo durante la sesión de demostración.</span><span class="sxs-lookup"><span data-stu-id="824f7-128">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="824f7-129">Programa</span><span class="sxs-lookup"><span data-stu-id="824f7-129">Schedule</span></span>
* <span data-ttu-id="824f7-130">13:30-13:45: Comentarios bienvenidas y la apertura.</span><span class="sxs-lookup"><span data-stu-id="824f7-130">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="824f7-131">13:45-14:15: **El discurso de charla**: Prof. Marc Pollefeys, ETH Zurich y Microsoft.</span><span class="sxs-lookup"><span data-stu-id="824f7-131">13:45-14:15: **Keynote talk**: Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="824f7-132">Título: TBD.</span><span class="sxs-lookup"><span data-stu-id="824f7-132">Title: TBD.</span></span>
* <span data-ttu-id="824f7-133">14:15-14:45: **El discurso de charla**: Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="824f7-133">14:15-14:45: **Keynote talk**: Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="824f7-134">Título: TBD.</span><span class="sxs-lookup"><span data-stu-id="824f7-134">Title: TBD.</span></span>
* <span data-ttu-id="824f7-135">14:45-15:15: **El discurso de charla**: Recuperación ante desastres. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="824f7-135">14:45-15:15: **Keynote talk**: Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="824f7-136">Título: TBD.</span><span class="sxs-lookup"><span data-stu-id="824f7-136">Title: TBD.</span></span>
* <span data-ttu-id="824f7-137">15:15-16:15: Pausa para café y demostraciones.</span><span class="sxs-lookup"><span data-stu-id="824f7-137">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="824f7-138">16:15-16:45: **El discurso de charla**: Prof. Kristen Grauman, University of Texas en investigación de inteligencia artificial de Austin o Facebook.</span><span class="sxs-lookup"><span data-stu-id="824f7-138">16:15-16:45: **Keynote talk**: Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="824f7-139">Título: TBD.</span><span class="sxs-lookup"><span data-stu-id="824f7-139">Title: TBD.</span></span>
* <span data-ttu-id="824f7-140">16:45-17:15: Presentaciones oral.</span><span class="sxs-lookup"><span data-stu-id="824f7-140">16:45-17:15: Oral presentations.</span></span>
* <span data-ttu-id="824f7-141">17:15-17:30: Comentarios finales.</span><span class="sxs-lookup"><span data-stu-id="824f7-141">17:15-17:30: Final Remarks.</span></span>
