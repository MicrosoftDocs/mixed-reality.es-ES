---
title: Manipulación directa con las manos
description: Introducción al modelo de entrada mediante manipulación directa
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, Gaze, gaze targeting, interaction, design, hands near, HoloLens
ms.openlocfilehash: 6e3512eab4070680c48ee8e95240a17e9925822f
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 06/05/2019
ms.locfileid: "66402393"
---
# <a name="direct-manipulation-with-hands"></a><span data-ttu-id="d3fd8-104">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-104">Direct manipulation with hands</span></span>
<span data-ttu-id="d3fd8-105">La manipulación directa es un modelo de entrada de datos que implica tocar hologramas directamente con las manos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="d3fd8-106">El objetivo de la manipulación directa es que los objetos se comporten exactamente igual que lo hacen en el mundo real.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="d3fd8-107">Para activar los botones no hay más que presionarlos, para elegir los objetos no hay más que agarrarlos y el contenido 2D se comporta como una pantalla táctil virtual.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="d3fd8-108">Por eso a los usuarios les resulta muy fácil y divertido aprender la manipulación directa.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="d3fd8-109">Se considera un modelo de entrada "cercano", lo que significa que se usa con preferencia para interactuar con contenido que está al alcance de los brazos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="d3fd8-110">La manipulación directa utiliza prestaciones, lo que significa que es fácil de usar.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-110">Direct manipulation is affordance-based, meaning it's user friendly.</span></span> <span data-ttu-id="d3fd8-111">No hay que enseñar ningún gesto simbólico a los usuarios.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="d3fd8-112">Todas las interacciones se crean en torno a un elemento visual que se puede tocar o agarrar.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-112">All interactions are built around a visual element that you can touch or grab.</span></span>

## <a name="device-support"></a><span data-ttu-id="d3fd8-113">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-113">Device support</span></span>


| <span data-ttu-id="d3fd8-114">Modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="d3fd8-114">Input Model</span></span> | [<span data-ttu-id="d3fd8-115">HoloLens (1ª generación)</span><span class="sxs-lookup"><span data-stu-id="d3fd8-115">HoloLens (1st gen)</span></span>](hololens-hardware-details.md) | <span data-ttu-id="d3fd8-116">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="d3fd8-116">HoloLens 2</span></span> |[<span data-ttu-id="d3fd8-117">Cascos envolventes</span><span class="sxs-lookup"><span data-stu-id="d3fd8-117">Immersive headsets</span></span>](immersive-headset-hardware-details.md)|
|:-------- | :-------| :--------| :------------|
| <span data-ttu-id="d3fd8-118">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-118">Direct manipulation with hands</span></span> | <span data-ttu-id="d3fd8-119">❌ No se admite</span><span class="sxs-lookup"><span data-stu-id="d3fd8-119">❌ Not supported</span></span> | <span data-ttu-id="d3fd8-120">✔️ Se recomienda</span><span class="sxs-lookup"><span data-stu-id="d3fd8-120">✔️ Recommended</span></span> | <span data-ttu-id="d3fd8-121">➕ Una alternativa, se recomienda [apuntar y confirmar con las manos](point-and-commit.md).</span><span class="sxs-lookup"><span data-stu-id="d3fd8-121">➕ An alternative, [point and commit with hands](point-and-commit.md) is recommended.</span></span>

<span data-ttu-id="d3fd8-122">La manipulación directa es un modelo de entrada principal de HoloLens 2 y usa el nuevo sistema articulado de seguimiento de la mano.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-122">Direct manipulation is a primary input model on HoloLens 2, and utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="d3fd8-123">El modelo de entrada también está disponible en los cascos envolventes mediante el uso de controladores de movimiento, pero no se recomienda como medio principal de interacción fuera de la manipulación de objetos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended as a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="d3fd8-124">La manipulación directa no está disponible en HoloLens (1ª generación).</span><span class="sxs-lookup"><span data-stu-id="d3fd8-124">Direct manipluation is not available on HoloLens (1st gen).</span></span>


## <a name="collidable-fingertip"></a><span data-ttu-id="d3fd8-125">Dedo de colisión</span><span class="sxs-lookup"><span data-stu-id="d3fd8-125">Collidable fingertip</span></span>

<span data-ttu-id="d3fd8-126">En HoloLens 2, se reconocen las manos reales del usuario y se interpretan como modelos óseos de las manos derecha e izquierda.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-126">On HoloLens 2, the user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="d3fd8-127">Para aplicar la idea de tocar los hologramas directamente con las manos, lo ideal sería poder acoplar un colisionador a cada dedo del modelo óseo de cada mano.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="d3fd8-128">Sin embargo, en la práctica, dada a la falta de información procedente del tacto, diez dedos de colisión provocaron colisiones inesperadas e impredecibles con los hologramas.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips caused unexpected and unpredictable collisions with holograms.</span></span> 

<span data-ttu-id="d3fd8-129">De ahí que se sugiera colocar solo un colisionador en cada dedo índice.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="d3fd8-130">Los dedos índice de colisión se pueden seguir usando como puntos táctiles activos para diversos gestos táctiles que implican otros dedos, como por ejemplo, presionar con un dedo, pulsar con un dedo, presionar con dos dedos y presionar con cinco dedos, como se muestra en la imagen siguiente.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1-finger press, 1-finger tap, 2-finger press and 5-finger press, as shown in the image below.</span></span>

![Imagen de dedo de colisión](images/Collidable-Fingertip-720px.jpg)

### <a name="sphere-collider"></a><span data-ttu-id="d3fd8-132">Colisionador esférico</span><span class="sxs-lookup"><span data-stu-id="d3fd8-132">Sphere collider</span></span>

<span data-ttu-id="d3fd8-133">En lugar de una forma genérica aleatoria, se recomienda usar un colisionador esférico y representarlo visualmente para proporcionar indicaciones mejores para los objetivos cercanos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-133">Instead of using a random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="d3fd8-134">Para aumentar la precisión del toque, el diámetro de la esfera debe coincidir con el grosor del dedo índice.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="d3fd8-135">Será fácil recuperar la variable de grosor del dedo, solo es preciso llamar a la API de mano.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

### <a name="fingertip-cursor"></a><span data-ttu-id="d3fd8-136">Cursor de dedo</span><span class="sxs-lookup"><span data-stu-id="d3fd8-136">Fingertip cursor</span></span>

<span data-ttu-id="d3fd8-137">Además de representar una esfera de colisión en el dedo índice, hemos creado una solución avanzada, el cursor de dedo, para llegar mejor a objetivos cercanos de forma interactiva.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-137">In addition to rendering a collidable sphere on the index fingertip, we've created an advanced solution, fingertip cursor, to achieve better near-targeting experience interactively.</span></span> <span data-ttu-id="d3fd8-138">Es un cursor en forma de anillo acoplado al dedo índice.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-138">It is a donut-shaped cursor attached on the index fingertip.</span></span> <span data-ttu-id="d3fd8-139">En función de la proximidad, reacciona dinámicamente a un destino en términos de orientación y tamaño como se detalla a continuación:</span><span class="sxs-lookup"><span data-stu-id="d3fd8-139">According to proximity, it dynamically reacts to a target in terms of orientation and size as detailed below:</span></span>

* <span data-ttu-id="d3fd8-140">Cuando un dedo índice se mueve hacia un holograma, el cursor está siempre paralelo a la superficie del holograma y su tamaño se reduce gradualmente en consecuencia.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-140">When an index finger moves toward a hologram, the cursor is always parallel to the hologram's surface  and gradually shrinks its size accordingly.</span></span>
* <span data-ttu-id="d3fd8-141">En cuanto el dedo toca la superficie, el tamaño del cursor se reduce hasta convertirse en un punto y emite un evento de toque.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-141">As soon as the finger touches the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<span data-ttu-id="d3fd8-142">Con la información interactiva, los usuarios pueden realizar tareas en objetivos cercanos de forma muy precisa, como desencadenar un hipervínculo en contenido web o presionar un botón, como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on web content or pressing a button, as shown, below.</span></span> 

![Imagen de cursor de dedo](images/Fingertip-Cursor-720px.jpg)

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="d3fd8-144">Rectángulo de selección con sombreador de proximidad</span><span class="sxs-lookup"><span data-stu-id="d3fd8-144">Bounding box with proximity shader</span></span>

<span data-ttu-id="d3fd8-145">El propio holograma también requiere la capacidad de proporcionar información visual y sonora para compensar la falta de información táctil.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-145">The hologram itself also requires the ability to provide both visual and audio feedback to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="d3fd8-146">Con ese fin generamos el concepto de rectángulo de selección con sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-146">For that, we generate the concept of a bounding box with proximity shader.</span></span> <span data-ttu-id="d3fd8-147">Un rectángulo de selección es un área volumétrica mínima que rodea a un objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-147">A bounding box is a minimum volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="d3fd8-148">El rectángulo de selección tiene un mecanismo de representación interactivo denominado sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="d3fd8-149">Así es como se comporta el sombreador de proximidad:</span><span class="sxs-lookup"><span data-stu-id="d3fd8-149">The proximity shader behaves:</span></span>

* <span data-ttu-id="d3fd8-150">Cuando el dedo índice está dentro del alcance, se proyecta un foco con forma de dedo en la superficie del rectángulo de selección.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span>
* <span data-ttu-id="d3fd8-151">Cuando el dedo se acerca a la superficie, el foco se condensa en consecuencia.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span>
* <span data-ttu-id="d3fd8-152">En cuanto el dedo toca la superficie, todo el rectángulo de selección cambia de color o se genera un efecto visual que refleje dicho estado.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span>
* <span data-ttu-id="d3fd8-153">Además, se puede activar un efecto de sonido que mejore la información visual del toque.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Imagen de rectángulo de selección con sombreador de proximidad](images/Bounding-Box-With-Proximity-Shader-720px.jpg)

## <a name="pressable-button"></a><span data-ttu-id="d3fd8-155">Botón presionable</span><span class="sxs-lookup"><span data-stu-id="d3fd8-155">Pressable button</span></span>

<span data-ttu-id="d3fd8-156">Con el dedo de colisión, los usuarios ya están listos para interactuar con el componente fundamental de la interfaz de usuario holográfica, el botón que se puede pulsar.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="d3fd8-157">Un botón presionable es un botón holográfico adaptado a la presión directa del dedo.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="d3fd8-158">Una vez más, debido a la falta de información táctil, el botón presionable cuenta con un par de mecanismos para abordar los problemas relacionados con la información táctil.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback-related issues.</span></span>

* <span data-ttu-id="d3fd8-159">El primer mecanismo es un rectángulo de selección con sombreador de proximidad, del que se ha proporcionado la información pertinente en la sección anterior.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-159">The first mechanism is a bounding box with proximity shader, detailed in the previous section.</span></span> <span data-ttu-id="d3fd8-160">Sirve para mejorar la sensación de proximidad a los usuarios a la hora de acercarse y entrar en contacto con un botón.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span>
* <span data-ttu-id="d3fd8-161">El segundo es la pulsación.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-161">The second one is depression.</span></span> <span data-ttu-id="d3fd8-162">Crea sensación de pulsación después de un dedo entra en contacto con el botón.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="d3fd8-163">El mecanismo es que el botón se mueve estrechamente junto con el dedo por el eje de profundidad.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="d3fd8-164">El botón se puede desencadenar cuando se alcanza una profundidad designada (al presionar) o se sale de dicha profundidad (al soltar) después de atravesarlo.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-164">The button can be triggered when it reaches a designated depth (on press) or leaves the depth (on release) after passing through it.</span></span>
* <span data-ttu-id="d3fd8-165">El efecto de sonido se debe agregar para mejorar la información, cuando se desencadena el botón.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span>

![Imagen de botón presionable](images/Pressable-Button-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="d3fd8-167">Interacción con una tableta táctil 2D</span><span class="sxs-lookup"><span data-stu-id="d3fd8-167">2D slate interaction</span></span>

<span data-ttu-id="d3fd8-168">Una tableta táctil 2D es un contenedor holográfico que hospeda contenido de aplicaciones 2D, como un explorador web.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="d3fd8-169">El concepto de diseño para interactuar con una tableta táctil 2D mediante la manipulación directa es aprovechar el modelo mental de interactuar con una pantalla táctil física.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span>

<span data-ttu-id="d3fd8-170">Para interactuar con el contacto de la tableta táctil:</span><span class="sxs-lookup"><span data-stu-id="d3fd8-170">To interact with the slate contact:</span></span>

* <span data-ttu-id="d3fd8-171">Utiliza el dedo índice para presionar un botón o un hipervínculo.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-171">Use an index finger to press a hyperlink or a button.</span></span>
* <span data-ttu-id="d3fd8-172">Utiliza el dedo índice para desplazar el contenido de la tableta táctil hacia arriba y abajo.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-172">Use an index finger to scroll a slate content up and down.</span></span>
* <span data-ttu-id="d3fd8-173">Los usuarios utilizan los dos dedos índice para acercar y alejar el contenido de la tableta táctil, en función del movimiento relativo de los dedos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span>

![Imagen de tableta táctil 2D](images/2D-Slate-Interaction-720px.jpg)

<span data-ttu-id="d3fd8-175">Para manipular la propia tableta táctil 2D:</span><span class="sxs-lookup"><span data-stu-id="d3fd8-175">For manipulating the 2D slate itself:</span></span>

* <span data-ttu-id="d3fd8-176">Acerca las manos a las esquinas y bordes para mostrar las prestaciones de manipulación más cercanas.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-176">Approach your hands toward corners and edges to reveal the closest manipulation affordances.</span></span>
* <span data-ttu-id="d3fd8-177">Agarra las prestaciones de manipulación y realiza un escalado uniforme mediante las prestaciones de la esquina y el reflujo mediante las prestaciones del borde.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-177">Grab the manipulation affordances, and perform uniform scaling through the corner affordances and reflow via the edge affordances.</span></span>
* <span data-ttu-id="d3fd8-178">Arrastra la barra holográfica de la parte superior de la tableta táctil 2D para mover toda la tableta táctil.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-178">Grab the holobar at the top of the 2D slate, which lets you move the whole slate.</span></span>

![Imagen de manipulación de la tableta táctil](images/Manipulate-2d-slate-720px.jpg)

## <a name="3d-object-manipulation"></a><span data-ttu-id="d3fd8-180">Manipulación de objetos 3D</span><span class="sxs-lookup"><span data-stu-id="d3fd8-180">3D object manipulation</span></span>

<span data-ttu-id="d3fd8-181">HoloLens 2 permite a los usuarios habilitar sus manos para la manipulación directa de objetos holográficos 3D mediante la aplicación de un rectángulo de selección a cada objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-181">HoloLens 2 lets lets users enable their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="d3fd8-182">El rectángulo de selección proporciona una mejor percepción de la profundidad gracias a su sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="d3fd8-183">Con el rectángulo de selección, hay dos enfoques de diseño para la manipulación de objetos 3D.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-183">With the bounding box, there are two design approaches for 3D object manipulation.</span></span>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="d3fd8-184">Manipulación con prestaciones</span><span class="sxs-lookup"><span data-stu-id="d3fd8-184">Affordance-based manipulation</span></span>

<span data-ttu-id="d3fd8-185">Te permite manipular el objeto 3D a través de un rectángulo de selección y las prestaciones de manipulación que hay a su alrededor.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-185">This lets you manipulate the 3D object through a bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="d3fd8-186">En cuanto la mano de un usuario esté cerca de un objeto 3D, se mostrarán el rectángulo de selección y la prestación más cercana.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="d3fd8-187">Los usuarios pueden agarrar el rectángulo de selección para mover todo el objeto, las prestaciones del borde para girarlo y las prestaciones de la esquina para escalarlo de forma uniforme.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the corner affordances to scale uniformly.</span></span>

![Imagen de manipulación de objetos 3D](images/3D-Object-Manipulation-720px.jpg)

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="d3fd8-189">Manipulación sin prestaciones</span><span class="sxs-lookup"><span data-stu-id="d3fd8-189">Non-affordance based manipulation</span></span>

<span data-ttu-id="d3fd8-190">En este mecanismo, no hay prestaciones conectadas al rectángulo de selección.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-190">In this mechanism, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="d3fd8-191">Los usuarios solo pueden mostrar el rectángulo de selección e interactuar directamente con él.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="d3fd8-192">Si el rectángulo de selección se agarra con una mano, la traslación y rotación del objeto se asocian con el movimiento y la orientación de la mano.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="d3fd8-193">Cuando el objeto se agarra con dos manos, los usuarios pueden trasladarlo, escalarlo y girarlo en función de los movimientos relativos de las dos manos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span>

<span data-ttu-id="d3fd8-194">La manipulación específica requiere precisión, por lo que es aconsejable usar la **manipulación con prestaciones**, ya que proporciona un alto nivel de granularidad.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-194">Specific manipulation requires precision, we recommend you use **affordance-based manipulation**, because it provides a high level of granularity.</span></span> <span data-ttu-id="d3fd8-195">Para la manipulación flexible, se recomienda usar la **manipulación sin prestaciones**, ya que permite experiencias instantáneas y divertidas.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-195">For flexible manipulation, we recommend you uses **non-affordance manipulation** is as it allows for instant and playful experiences.</span></span>

## <a name="instinctual-gestures"></a><span data-ttu-id="d3fd8-196">Gestos instintivos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-196">Instinctual gestures</span></span>

<span data-ttu-id="d3fd8-197">Con HoloLens (1ª generación), enseñamos a los usuarios un par gestos predefinidos, como eclosionar y pulsar en el aire.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-197">With HoloLens (1st gen), we taught users a couple predefined gestures,such as Bloom and Air Tap.</span></span> <span data-ttu-id="d3fd8-198">En el caso de HoloLens 2, no pedimos a los usuarios que memoricen gestos simbólicos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-198">For HoloLens 2, we don't ask users to memorize any symbolic gestures.</span></span> <span data-ttu-id="d3fd8-199">Todos los gestos que los usuarios necesitan para interactuar con los hologramas y el contenido son instintivos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-199">All required user gestures, users need to interact with holograms and contents, are instinctual.</span></span> <span data-ttu-id="d3fd8-200">Para lograr gestos instintivos guía a los usuarios para que realicen los gestos mediante el diseño de prestaciones de la interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-200">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span>

<span data-ttu-id="d3fd8-201">Por ejemplo, si te animamos a arrastrar un objeto o un punto de control acercando dos dedos, tanto el objeto como el punto de control deben ser pequeño.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-201">For example, if we encourage you to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="d3fd8-202">Si queremos que el agarre lo realices con cinco dedos, el objeto o el punto de control debería ser relativamente grande.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-202">If we want you to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="d3fd8-203">Al igual que los botones, un botón pequeño limitaría a los usuarios a presionarlo con un solo dedo, mientras que un botón enorme instaría a los usuarios a presionarlo con las palmas de las manos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-203">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>

![](images/Instinctual-Gestures-720px.jpg)

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="d3fd8-204">Diseño simétrico entre las manos y 6 controladores DoF</span><span class="sxs-lookup"><span data-stu-id="d3fd8-204">Symmetric design between hands and 6 DoF controllers</span></span>

<span data-ttu-id="d3fd8-205">Es posible que hayas observado que ahora hay paralelos de interacción que podemos dibujar en AR y controladores de movimiento en VR.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-205">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="d3fd8-206">Las dos entradas pueden usarse para desencadenar manipulaciones directas en sus respectivos entornos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-206">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="d3fd8-207">En HoloLens 2, la realización de las operaciones de agarrar y arrastrar con las manos a corta distancia funciona de forma muy parecida a como lo hace el botón de agarrar en los controladores de movimiento en WMR.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-207">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="d3fd8-208">Esto proporciona a los usuarios familiaridad en la interacción entre las dos plataformas y resulta muy útil si alguna vez decides portar una aplicación de una plataforma a la otra.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-208">This provides users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimize-with-eye-tracking"></a><span data-ttu-id="d3fd8-209">Optimización con el seguimiento de los ojos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-209">Optimize with eye tracking</span></span>

<span data-ttu-id="d3fd8-210">Si funciona según lo previsto, la manipulación directa puede parecer mágica, pero también puede resultar frustrante si no se puede mover la mano a ningún lugar sin desencadenar involuntariamente un holograma.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-210">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="d3fd8-211">El seguimiento de los ojos puede ayudar a identificar mejor la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-211">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span>

* <span data-ttu-id="d3fd8-212">**Cuándo**: se reduce falsamente, lo que desencadena una respuesta de manipulación.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-212">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="d3fd8-213">El seguimiento de los ojos permite saber mejor lo que hace un usuario en cada momento.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-213">Eye tracking allows for better understanding what a user is currently engaged with.</span></span>
<span data-ttu-id="d3fd8-214">Por ejemplo, imagina que estás leyendo un texto (con instrucciones) de una holografía cuando te dispones a agarrar tu herramienta del mundo real.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-214">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>

<span data-ttu-id="d3fd8-215">Al hacerlo, accidentalmente mueves la mano por unos botones holográficos interactivos que no te habías percatado de que estaban ahí (hasta es posible que estuvieran fuera del campo de visión del usuario).</span><span class="sxs-lookup"><span data-stu-id="d3fd8-215">By doing so, you accidentally move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View (FOV)).</span></span>

  <span data-ttu-id="d3fd8-216">Un resumen: si el usuario lleva un tiempo sin mirar un holograma, pero se ha detectado un evento de tocar o agarrar para él, es probable que el usuario no tuviera realmente intención de interactuar con el holograma.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-216">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span>

* <span data-ttu-id="d3fd8-217">**Cuál**:  además de solucionar activaciones positivas falsas, otro ejemplo incluye una mejor identificación de qué hologramas agarrar o usar, ya que es posible que el punto de intersección preciso no esté claro desde tu perspectiva, sobre todo si hay varios hologramas colocados unos cerca de otros.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-217">**Which one**:  Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span>

  <span data-ttu-id="d3fd8-218">Aunque en HoloLens 2 el seguimiento de los ojos tiene cierta limitación en la precisión con la que puede determinar la mirada con los ojos, puede resultar muy útil para las interacciones próximas debido a la disparidad de profundidad al interactuar con la entrada a mano.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-218">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span>  <span data-ttu-id="d3fd8-219">Esto significa que a veces es difícil determinar si la mano está detrás o delante de un holograma, por ejemplo, para agarrar con precisión un widget de manipulación.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-219">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

* <span data-ttu-id="d3fd8-220">**A dónde**: usa información acerca de lo que mira un usuario con gestos que se realizan rápidamente.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-220">**Where to**: Use information about what a user is looking at with quick- throwing gestures.</span></span> <span data-ttu-id="d3fd8-221">Agarra un holograma y tíralo hacia su destino previsto.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-221">Grab a hologram and roughly toss it toward your intended destination.</span></span>  

    <span data-ttu-id="d3fd8-222">Aunque es posible que a veces esto funcione bien, la realización rápida de gestos con la mano puede dar lugar destinos muy imprecisos.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-222">While this may sometimes works just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span> <span data-ttu-id="d3fd8-223">Aquí es donde el seguimiento de los ojos puede ayudar para inclinar el vector que se lanza con la mano a la posición deseada.</span><span class="sxs-lookup"><span data-stu-id="d3fd8-223">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="d3fd8-224">Consulte también</span><span class="sxs-lookup"><span data-stu-id="d3fd8-224">See also</span></span>

* [<span data-ttu-id="d3fd8-225">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="d3fd8-225">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="d3fd8-226">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="d3fd8-226">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="d3fd8-227">Interacciones instintivas</span><span class="sxs-lookup"><span data-stu-id="d3fd8-227">Instinctual interactions</span></span>](interaction-fundamentals.md)

