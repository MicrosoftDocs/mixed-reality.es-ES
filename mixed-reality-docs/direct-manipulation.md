---
title: Manipulación directa
description: Información general sobre el modelo de entrada de la manipulación directa
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
keywords: Mixto en realidad, mirada, mirada como destino, interacción, diseñar
ms.openlocfilehash: d855955d44c1cf074849992e5dd7b36b54675fdd
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581335"
---
# <a name="direct-manipulation"></a><span data-ttu-id="900cb-104">Manipulación directa</span><span class="sxs-lookup"><span data-stu-id="900cb-104">Direct manipulation</span></span>
<span data-ttu-id="900cb-105">La manipulación directa es un modelo de entrada que implica tocar hologramas directamente con las manos.</span><span class="sxs-lookup"><span data-stu-id="900cb-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="900cb-106">La manipulación directa, el objetivo es que los objetos se comportan igual que en el mundo real.</span><span class="sxs-lookup"><span data-stu-id="900cb-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="900cb-107">Botones que se pueden activar simplemente presionándolos, los objetos se pueden seleccionarlos contratiempos y contenido 2D se comporta como una pantalla táctil virtual.</span><span class="sxs-lookup"><span data-stu-id="900cb-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="900cb-108">Por este motivo, dirigir es fácil para los usuarios obtener información sobre la manipulación, así como de la diversión demasiado.</span><span class="sxs-lookup"><span data-stu-id="900cb-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="900cb-109">Se considera un "cerca de" modelo de entrada, lo que significa que está concebida para interactuar con el contenido que está dentro de brazos llegar.</span><span class="sxs-lookup"><span data-stu-id="900cb-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="900cb-110">Un ingrediente clave que facilita la manipulación directa saber es que está basado en la prestación.</span><span class="sxs-lookup"><span data-stu-id="900cb-110">A key ingredient that makes direct manipulation easy to learn is that it is affordance-based.</span></span> <span data-ttu-id="900cb-111">No hay ningún gestos simbólicos a enseñar a los usuarios.</span><span class="sxs-lookup"><span data-stu-id="900cb-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="900cb-112">Todas las interacciones deben crearse en torno a un elemento visual que puede tocado o capturar.</span><span class="sxs-lookup"><span data-stu-id="900cb-112">All interactions should be built around a visual element that can be touched or grabbed.</span></span>

## <a name="device-support"></a><span data-ttu-id="900cb-113">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="900cb-113">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="900cb-114"><strong>Modelo de entrada</strong></span><span class="sxs-lookup"><span data-stu-id="900cb-114"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="900cb-115"><a href="hololens-hardware-details.md"><strong>HoloLens (gen 1)</strong></a></span><span class="sxs-lookup"><span data-stu-id="900cb-115"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="900cb-116"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="900cb-116"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="900cb-117"><a href="immersive-headset-hardware-details.md"><strong>Inmersivos</strong></a></span><span class="sxs-lookup"><span data-stu-id="900cb-117"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="900cb-118">Manipulación directa (cerca de interacción de mano)</span><span class="sxs-lookup"><span data-stu-id="900cb-118">Direct manipulation (Near hand interaction)</span></span></td>
        <td><span data-ttu-id="900cb-119">❌ No compatible</span><span class="sxs-lookup"><span data-stu-id="900cb-119">❌ Not supported</span></span></td>
        <td><span data-ttu-id="900cb-120">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="900cb-120">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="900cb-121">Opción alternativa ➕ pero <a href="point-and-commit.md">punto y la confirmación (interacción lejano)</a> se recomienda</span><span class="sxs-lookup"><span data-stu-id="900cb-121">➕ An alternate option but <a href="point-and-commit.md">Point and commit (far interaction)</a> is recommended</span></span></td>
    </tr>
</table>

<span data-ttu-id="900cb-122">La manipulación directa es un modelo de entrada principal en HoloLens 2, el uso de la mano articulada nuevo sistema de seguimiento.</span><span class="sxs-lookup"><span data-stu-id="900cb-122">Direct manipulation is a primary input model on HoloLens 2, utilizing the new articulated hand tracking system.</span></span> <span data-ttu-id="900cb-123">El modelo de entrada también está disponible en inmersivos mediante el uso de los controladores de movimiento, pero se recomienda no significa que un elemento principal de interacción fuera de la manipulación del objeto.</span><span class="sxs-lookup"><span data-stu-id="900cb-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="900cb-124">Manipluation directo no está disponible en HoloLens v1.</span><span class="sxs-lookup"><span data-stu-id="900cb-124">Direct manipluation is not available on HoloLens v1.</span></span>

## <a name="collidable-fingertip"></a><span data-ttu-id="900cb-125">Yema collidable</span><span class="sxs-lookup"><span data-stu-id="900cb-125">Collidable fingertip</span></span>
<span data-ttu-id="900cb-126">En HoloLens 2, se reconoce manos real del usuario y se interpretan como modelos de esqueleto mano izquierda y derecha.</span><span class="sxs-lookup"><span data-stu-id="900cb-126">On HoloLens 2, user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="900cb-127">Para implementar la idea de tocar hologramas directamente con las manos, idealmente, 5 colisionadores se podrían conectar a 5 alcance de cada modelo de esqueleto de la mano.</span><span class="sxs-lookup"><span data-stu-id="900cb-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="900cb-128">Sin embargo, en la práctica, debido a la falta de comentarios al tacto, 10 alcance collidable causar una gran cantidad de colisiones inesperadas e impredecibles con hologramas.</span><span class="sxs-lookup"><span data-stu-id="900cb-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips cause lots of unexpected and unpredictable collisions with holograms.</span></span> <span data-ttu-id="900cb-129">Por lo tanto, se recomienda para poner solo un colisionador en cada dedo índice.</span><span class="sxs-lookup"><span data-stu-id="900cb-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="900cb-130">Puntee en el índice collidable alcance todavía puede actuar como puntos de toque activa para los gestos de toque diverso que implican otro dedo, por ejemplo, presione 1 dedo, 1 dedo, 2 presione dedo y 5 dedo.</span><span class="sxs-lookup"><span data-stu-id="900cb-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1 finger press, 1 finger tap, 2 finger press and 5 finger press.</span></span>

![Imagen de la yema del dedo collidable](images/Collidable-Fingertip-720px.jpg)<br>

### <a name="sphere-collider"></a><span data-ttu-id="900cb-132">Colisionador esfera</span><span class="sxs-lookup"><span data-stu-id="900cb-132">Sphere collider</span></span>
<span data-ttu-id="900cb-133">En lugar de forma genérica aleatorio, se recomienda usar un colisionador esfera y para representar visualmente para proporcionar indicaciones mejores para dirigirse a casi.</span><span class="sxs-lookup"><span data-stu-id="900cb-133">Instead of using random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="900cb-134">Diámetro de la esfera debe coincidir con el grosor del dedo índice para aumentar la precisión de toque.</span><span class="sxs-lookup"><span data-stu-id="900cb-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="900cb-135">Será fácil recuperar la variable de grosor dedo mediante una llamada a la API de mano.</span><span class="sxs-lookup"><span data-stu-id="900cb-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

<br>

### <a name="fingertip-cursor"></a><span data-ttu-id="900cb-136">Cursor de la yema del dedo</span><span class="sxs-lookup"><span data-stu-id="900cb-136">Fingertip cursor</span></span>
<span data-ttu-id="900cb-137">Además de representar una esfera de la yema del dedo índice collidable, creamos una solución por adelantado, cursor yema, para lograr el mejor cerca de destinatarios experiencia interactiva.</span><span class="sxs-lookup"><span data-stu-id="900cb-137">In addition to rendering a collidable sphere on the index fingertip, we create an advance solution, fingertip cursor, to achieve better near targeting experience interactively.</span></span> <span data-ttu-id="900cb-138">Es un cursor de la forma de anillo asociado en la yema del dedo índice.</span><span class="sxs-lookup"><span data-stu-id="900cb-138">It is a donut shape cursor attached on the index fingertip.</span></span> <span data-ttu-id="900cb-139">Según la proximidad, dinámicamente reacciona a un destino en términos de orientación y el tamaño como sigue:</span><span class="sxs-lookup"><span data-stu-id="900cb-139">According to proximity, it dynamically reacts to a target in term of orientation and size as below:</span></span>
* <span data-ttu-id="900cb-140">Cuando se mueve un dedo índice hacia un holograma, el cursor siempre es paralelo a la superficie de la holograma y gradualmente reduce su tamaño.</span><span class="sxs-lookup"><span data-stu-id="900cb-140">When an index finger moves toward a hologram, the cursor is always parallel to the surface of the hologram and gradually shrinks its size accordingly.</span></span> 
* <span data-ttu-id="900cb-141">Tan pronto como el dedo toque la superficie, el cursor se reduce en un punto y emite un evento de toque.</span><span class="sxs-lookup"><span data-stu-id="900cb-141">As soon as the finger touch the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<br> <span data-ttu-id="900cb-142">Con la información interactiva, los usuarios puedan lograr alta precisión cerca de tareas, como desencadenar un hipervínculo a un contenido en web o al presionar un botón de destino.</span><span class="sxs-lookup"><span data-stu-id="900cb-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on a web content or pressing a button.</span></span> <br>

![Imagen del cursor yema del dedo](images/Fingertip-Cursor-720px.jpg)<br>

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="900cb-144">Cuadro de límite con el sombreador de proximidad</span><span class="sxs-lookup"><span data-stu-id="900cb-144">Bounding box with proximity shader</span></span>
<span data-ttu-id="900cb-145">También requiere el holograma propia para proporcionar comentarios visuales y de audio para compensar la falta de comentarios al tacto.</span><span class="sxs-lookup"><span data-stu-id="900cb-145">The hologram itself also requires to provide both visual and audio feedbacks to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="900cb-146">Para eso, generamos el concepto de rectángulo de selección con el sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="900cb-146">For that, we generate the concept of bounding box with proximity shader.</span></span> <span data-ttu-id="900cb-147">Un rectángulo de selección es un área volumétricos mínimas que rodea a un objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="900cb-147">A bounding box is a minimun volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="900cb-148">El rectángulo tiene un mecanismo de representación interactiva denominado a sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="900cb-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="900cb-149">El sombreador de proximidad se comporta como sigue:</span><span class="sxs-lookup"><span data-stu-id="900cb-149">The proximity shader behaves as below:</span></span>

* <span data-ttu-id="900cb-150">Cuando el dedo índice está dentro del intervalo, se convierte un foco yema del dedo en la superficie del cuadro de límite.</span><span class="sxs-lookup"><span data-stu-id="900cb-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span> 
* <span data-ttu-id="900cb-151">Cuando se aproxime la yema del dedo a la superficie, destacados condensa según corresponda.</span><span class="sxs-lookup"><span data-stu-id="900cb-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span> 
* <span data-ttu-id="900cb-152">Tan pronto como la yema del dedo toque la superficie, todo el rectángulo de selección cambia el color o generar un efecto visual para reflejar el estado de toque.</span><span class="sxs-lookup"><span data-stu-id="900cb-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span> 
* <span data-ttu-id="900cb-153">Mientras tanto, se puede activar un efecto de sonido para mejorar los comentarios de visual táctil.</span><span class="sxs-lookup"><span data-stu-id="900cb-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Cuadro de límite con la imagen del sombreador de proximidad](images/Bounding-Box-With-Proximity-Shader-720px.jpg)<br>

## <a name="pressable-button"></a><span data-ttu-id="900cb-155">Botón pressable</span><span class="sxs-lookup"><span data-stu-id="900cb-155">Pressable button</span></span>
<span data-ttu-id="900cb-156">Con el dedo collidable, los usuarios ahora están listos para interactuar con el componente holográfico muy fundamental de la interfaz de usuario, botón pressable.</span><span class="sxs-lookup"><span data-stu-id="900cb-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="900cb-157">Un botón pressable es un holográfica adaptada de presionar el dedo directa.</span><span class="sxs-lookup"><span data-stu-id="900cb-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="900cb-158">Nuevamente, debido a la falta de comentarios al tacto, un botón pressable equipa a unos mecanismos para abordar al tacto comentarios relacionados con problemas.</span><span class="sxs-lookup"><span data-stu-id="900cb-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback related issues.</span></span> 
* <span data-ttu-id="900cb-159">El primer mecanismo es rectángulo con el sombreador de proximidad, que ya se ha corregido en el párrafo anterior.</span><span class="sxs-lookup"><span data-stu-id="900cb-159">The first mechanism is bounding box with proximity shader, which has already been addressed in the foregoing paragraph.</span></span> <span data-ttu-id="900cb-160">Sirve para proporcionar un mejor sentido de proximidad a los usuarios enfocar y asegúrese de contacto con un botón.</span><span class="sxs-lookup"><span data-stu-id="900cb-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span> 
* <span data-ttu-id="900cb-161">La segunda es la depresión.</span><span class="sxs-lookup"><span data-stu-id="900cb-161">The second one is depression.</span></span> <span data-ttu-id="900cb-162">Crea sensación de prensa, después de un dedo pone en contacto con el botón.</span><span class="sxs-lookup"><span data-stu-id="900cb-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="900cb-163">El mecanismo es que el botón se mueve estrechamente con el dedo en el eje de profundidad.</span><span class="sxs-lookup"><span data-stu-id="900cb-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="900cb-164">El botón se puede desencadenar tan pronto como llegue a una profundidad designada (al presionar) o dejar la profundidad (en lanzamiento) después de pasar a través de él.</span><span class="sxs-lookup"><span data-stu-id="900cb-164">The button can be triggered as soon as reaching a designated depth (on press) or leaving the depth (on release) after passing through it.</span></span> 
* <span data-ttu-id="900cb-165">El efecto de sonido se debe agregar para mejorar los comentarios, cuando se activa el botón.</span><span class="sxs-lookup"><span data-stu-id="900cb-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span> 

![Imagen del botón pressable](images/Pressable-Button-720px.jpg)<br>

## <a name="2d-slate-interaction"></a><span data-ttu-id="900cb-167">Interacción de pizarra 2D</span><span class="sxs-lookup"><span data-stu-id="900cb-167">2D slate interaction</span></span>
<span data-ttu-id="900cb-168">Una pizarra 2D es un contenedor holográfico hospedar contenido de la aplicación 2D, como explorador web.</span><span class="sxs-lookup"><span data-stu-id="900cb-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="900cb-169">El concepto de diseño para interactuar con una pizarra 2D a través de la manipulación directa es aprovechar el modelo mental de interactuar con una pantalla táctil físico.</span><span class="sxs-lookup"><span data-stu-id="900cb-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span><br> <br>
<span data-ttu-id="900cb-170">Para interactuar con el contacto Pizarra:</span><span class="sxs-lookup"><span data-stu-id="900cb-170">For interacting with the slate contact:</span></span><br> 
* <span data-ttu-id="900cb-171">Los usuarios usar un dedo índice presionar un botón o un hipervínculo.</span><span class="sxs-lookup"><span data-stu-id="900cb-171">Users use an index finger to press a hyperlink or a button.</span></span> 
* <span data-ttu-id="900cb-172">Los usuarios usar un dedo índice desplazar una pizarra contenido hacia arriba y abajo.</span><span class="sxs-lookup"><span data-stu-id="900cb-172">Users use an index finger to scroll a slate content up and down.</span></span> 
* <span data-ttu-id="900cb-173">Los usuarios usar dos dedos de índice para aumentar y reducir el contenido de pizarra según movimiento relativo de los dedos.</span><span class="sxs-lookup"><span data-stu-id="900cb-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span> 
<span data-ttu-id="900cb-174">![Imagen de pizarra 2D](images/2D-Slate-Interaction-720px.jpg)</span><span class="sxs-lookup"><span data-stu-id="900cb-174">![2D slate image](images/2D-Slate-Interaction-720px.jpg)</span></span><br>

<br><span data-ttu-id="900cb-175">Para manipular la 2D Pizarra propio:</span><span class="sxs-lookup"><span data-stu-id="900cb-175">For manipulating the 2D slate itself:</span></span><br>
* <span data-ttu-id="900cb-176">Los usuarios pueden llevar sus manos hacia las esquinas y bordes para revelar la factibilidad de manipulación más cercano.</span><span class="sxs-lookup"><span data-stu-id="900cb-176">Users can approach their hands toward corners and edges to reveal the closest manipulation affordances.</span></span> 
* <span data-ttu-id="900cb-177">Seleccionando la factibilidad de manipulación, los usuarios pueden realizar un escalado uniforme a través de la esquina affordnaces y reflujo a través de las prestaciones de edge.</span><span class="sxs-lookup"><span data-stu-id="900cb-177">By grabbing the manipulation affordances, users can perform uniform scaling through the corner affordnaces and reflow via the edge affordances.</span></span> 
* <span data-ttu-id="900cb-178">Acaparando el holobar en la parte superior de la Pizarra 2D pueden los usuarios mover la Pizarra toda.</span><span class="sxs-lookup"><span data-stu-id="900cb-178">Grabbing the holobar at the top of the 2D slate can users move the whole slate.</span></span><br><br>

![Imagen de pizarra manipulación](images/Manipulate-2d-slate-720px.jpg)


## <a name="3d-object-manipulation"></a><span data-ttu-id="900cb-180">Manipulación del objeto 3D</span><span class="sxs-lookup"><span data-stu-id="900cb-180">3D object manipulation</span></span>
<span data-ttu-id="900cb-181">En el 2 de HoloLens, los usuarios están habilitados para usar las manos para manipular directamente objetos 3D hologramphic aplicando un cuadro de límite para cada objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="900cb-181">In HoloLens 2, users are enabled to use their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="900cb-182">El cuadro de límite proporciona una mejor percepción de profundidad a través de su sombras de proximidad.</span><span class="sxs-lookup"><span data-stu-id="900cb-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="900cb-183">Con el cuadro de límite, hay dos enfoques de diseño para la manipulación del objeto 3D:</span><span class="sxs-lookup"><span data-stu-id="900cb-183">With the bounding box, there are two design approaches for 3D object manipulation:</span></span>      
### <a name="affordance-based-manipulation"></a><span data-ttu-id="900cb-184">Prestación en función de manipulación:</span><span class="sxs-lookup"><span data-stu-id="900cb-184">Affordance based manipulation:</span></span>
<span data-ttu-id="900cb-185">Es una manera para que los usuarios manipular el objeto 3D a través de la factibilidad de manipulación a su alrededor y de cuadro de límite.</span><span class="sxs-lookup"><span data-stu-id="900cb-185">It is a way for users to manipulate the 3D object through bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="900cb-186">Tan pronto como parte de un usuario está a punto de un objeto 3D, se revelan el cuadro de límite y la prestación más cercano.</span><span class="sxs-lookup"><span data-stu-id="900cb-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="900cb-187">Los usuarios pueden tomar para mover todo el objeto, la factibilidad de borde se va a girar el cuadro de límite y el esquina prestaciones para escalar de manera uniforme.</span><span class="sxs-lookup"><span data-stu-id="900cb-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the coner affordances to scale uniformly.</span></span><br>

![Imagen de manipulación del objeto 3D](images/3D-Object-Manipulation-720px.jpg)<br>

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="900cb-189">No prestación en función de manipulación:</span><span class="sxs-lookup"><span data-stu-id="900cb-189">Non-affordance based manipulation:</span></span>
<span data-ttu-id="900cb-190">En este mechanisom, no se asocia ninguna prestación en el cuadro de límite.</span><span class="sxs-lookup"><span data-stu-id="900cb-190">In this mechanisom, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="900cb-191">Los usuarios pueden revelar sólo el rectángulo de selección y luego interactuar directamente con él.</span><span class="sxs-lookup"><span data-stu-id="900cb-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="900cb-192">Si el cuadro de límite se obtiene con una mano, la traslación y rotación del objeto se asocian a movimiento y la orientación de la mano.</span><span class="sxs-lookup"><span data-stu-id="900cb-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="900cb-193">Cuando el objeto se obtiene con dos manos, los usuarios pueden trasladar, escalar y girarlo según los movimientos relativos de dos manos.</span><span class="sxs-lookup"><span data-stu-id="900cb-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span><br><br> 

<br><br>
<span data-ttu-id="900cb-194">Para la manipulación requiere precisión, se recomienda afforance en función de manipulación, proporcionando de alto nivel de granularidad.</span><span class="sxs-lookup"><span data-stu-id="900cb-194">For manipulation requires precision, we recommend afforance based manipulation, providing high level of granularity.</span></span> <span data-ttu-id="900cb-195">Para la manipulación flexible, no prestación manipulación será una buena opción, ofrecer a los usuarios experiencias de instantáneas y divertidas.</span><span class="sxs-lookup"><span data-stu-id="900cb-195">For flexible manipulation, non-affordance manipulation will be a good choice, offering users instant and playful experiences.</span></span>


## <a name="instinctual-gestures"></a><span data-ttu-id="900cb-196">Gestos instinctual</span><span class="sxs-lookup"><span data-stu-id="900cb-196">Instinctual gestures</span></span>
<span data-ttu-id="900cb-197">A diferencia de HoloLens gestos predefinido de un par de usuarios de enseñanza de (gen 1), como Bloom y aire pulse, HoloLens 2, no pedimos a los usuarios que memorizar los gestos simbólico.</span><span class="sxs-lookup"><span data-stu-id="900cb-197">Unlike HoloLens (1st gen), teaching users a couple predefined gestures, such as Bloom and Air Tap, in HoloLens 2, we don't ask users to memorize any symbolic gesture.</span></span> <span data-ttu-id="900cb-198">Todos los gestos que los usuarios necesitan para interactuar con el contenido y hologramas son instinctual.</span><span class="sxs-lookup"><span data-stu-id="900cb-198">All gestures that users need for interacting with holograms and contents are instinctual.</span></span> <span data-ttu-id="900cb-199">Es la forma de lograr gesto instinctual guiar a los usuarios para llevar a cabo movimientos con el diseño de prestaciones de la interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="900cb-199">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span> <span data-ttu-id="900cb-200">Por ejemplo, si le animamos a los usuarios tomar un objeto o un punto de control con pinch dos dedos, el objeto o el punto de control debe ser pequeño.</span><span class="sxs-lookup"><span data-stu-id="900cb-200">For example, if we encourage users to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="900cb-201">Si se desea que los usuarios realicen cinco grab del dedo, el objeto o el punto de control debería ser relativamente grande.</span><span class="sxs-lookup"><span data-stu-id="900cb-201">If we would like users to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="900cb-202">Al igual que los botones, un botón pequeño limitaría usuarios, haga clic con un solo dedo, mientras que un botón enorme insto a los usuarios presionen con sus palmas.</span><span class="sxs-lookup"><span data-stu-id="900cb-202">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>
![](images/Instinctual-Gestures-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="900cb-203">Diseño simétrica entre manos y controladores GDL 6</span><span class="sxs-lookup"><span data-stu-id="900cb-203">Symmetric design between hands and 6 DoF controllers</span></span>
<span data-ttu-id="900cb-204">Es posible que haya observado que ahora hay parallels interacción que podemos dibujar entre manos en los controladores VR AR y movimiento.</span><span class="sxs-lookup"><span data-stu-id="900cb-204">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="900cb-205">Las dos entradas pueden usarse para desencadenar manipulaciones en sus respectivos entornos.</span><span class="sxs-lookup"><span data-stu-id="900cb-205">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="900cb-206">En el 2 de HoloLens, hacerlo y arrastre las manos de un works corta distancia mucho en la misma manera que el botón de agarre hace en los controladores de movimiento en WMR.</span><span class="sxs-lookup"><span data-stu-id="900cb-206">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="900cb-207">Esto proporciona a los usuarios con la familiaridad de la interacción entre las dos plataformas y puede resultar útil si alguna vez decide portar tu aplicación de uno a otro.</span><span class="sxs-lookup"><span data-stu-id="900cb-207">This provides your users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimizing-with-eye-tracking"></a><span data-ttu-id="900cb-208">Optimizar el seguimiento de los ojos</span><span class="sxs-lookup"><span data-stu-id="900cb-208">Optimizing with eye tracking</span></span>
<span data-ttu-id="900cb-209">Si funciona según lo previsto, pero puede volverse rápidamente también frustrante si no se puede mover la mano en cualquier parte ya sin desencadenar involuntariamente un holograma, puede sentirse mágica manipulación directa.</span><span class="sxs-lookup"><span data-stu-id="900cb-209">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="900cb-210">Seguimiento de los ojos potencialmente pueden ayudar a identificar mejor lo que es la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="900cb-210">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span> 

* <span data-ttu-id="900cb-211">**When**: Reducir falsamente desencadenar una respuesta de manipulación.</span><span class="sxs-lookup"><span data-stu-id="900cb-211">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="900cb-212">Permite entender mejor lo que un usuario esté implicado actualmente con seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="900cb-212">Eye tracking allows for better understanding what a user is currently engaged with.</span></span> <span data-ttu-id="900cb-213">Por ejemplo, imagine que está leyendo a través de un texto (informativo) holográfica al alcanzar otra vez para obtener la herramienta de trabajo reales.</span><span class="sxs-lookup"><span data-stu-id="900cb-213">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>
<span data-ttu-id="900cb-214">Al hacerlo, por accidente mover la mano a través de algunos botones holográfica interactivos que incluso no vio antes (por ejemplo, era incluso fuera del campo de visión del usuario).</span><span class="sxs-lookup"><span data-stu-id="900cb-214">By doing so, you accidently move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View).</span></span>
<span data-ttu-id="900cb-215">Para hacer el cuento corto: Si el usuario no ha visto un holograma durante un tiempo, pero se ha detectado un evento táctil o entender para él, es probable que el usuario realmente indebida interactuar con ese holograma.</span><span class="sxs-lookup"><span data-stu-id="900cb-215">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span> 

* <span data-ttu-id="900cb-216">**Cuál**: Aparte de direccionamiento activaciones positivas falsas, otro ejemplo incluye la identificación de mejor qué hologramas para captar o echar un vistazo que no puede ser el punto de intersección precisa claro desde su perspectiva sobre todo si se colocan varias hologramas cerca de cada uno Otro.</span><span class="sxs-lookup"><span data-stu-id="900cb-216">**Which one**: Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span> <span data-ttu-id="900cb-217">Mientras que realizar un seguimiento de ojos en HoloLens 2 tiene una limitación determinada acerca de cómo con precisión puede determinar ocular a mirada, esto todavía puede ser muy útil para casi interacciones debido a la disparidad de profundidad al interactuar con la mano de entrada.</span><span class="sxs-lookup"><span data-stu-id="900cb-217">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span> <span data-ttu-id="900cb-218">Esto significa que a veces es difícil determinar si la mano es detrás o delante un holograma precisamente por ejemplo a tomar un widget de manipulación.</span><span class="sxs-lookup"><span data-stu-id="900cb-218">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

 * <span data-ttu-id="900cb-219">**Dónde**: Utilice la información sobre lo que un usuario está viendo con gestos produce rápidos.</span><span class="sxs-lookup"><span data-stu-id="900cb-219">**Where to**: Use information about what a user is looking at with quick throwing gestures.</span></span> <span data-ttu-id="900cb-220">Tome un holograma y aproximadamente lo meter hacia su destino previsto.</span><span class="sxs-lookup"><span data-stu-id="900cb-220">Grab a hologram and roughly toss it toward your intended destination.</span></span> <span data-ttu-id="900cb-221">Aunque a veces esto puede funcionar perfectamente, rápidamente realizar gestos de mano puede producir destinos muy imprecisos.</span><span class="sxs-lookup"><span data-stu-id="900cb-221">While this may sometimes work just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span>
<span data-ttu-id="900cb-222">Esto es donde rastreo ocular podría ayudar a al inclinar la mano producir vector de vuelta a la posición deseada.</span><span class="sxs-lookup"><span data-stu-id="900cb-222">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="900cb-223">Vea también</span><span class="sxs-lookup"><span data-stu-id="900cb-223">See also</span></span>
* [<span data-ttu-id="900cb-224">Mirada y confirmación</span><span class="sxs-lookup"><span data-stu-id="900cb-224">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="900cb-225">Punto y confirmación</span><span class="sxs-lookup"><span data-stu-id="900cb-225">Point and commit</span></span>](point-and-commit.md)
* [<span data-ttu-id="900cb-226">Conceptos básicos de la interacción</span><span class="sxs-lookup"><span data-stu-id="900cb-226">Interaction fundamentals</span></span>](interaction-fundamentals.md)

