---
title: Manipulación directa con manos
description: Información general sobre el modelo de entrada de la manipulación directa
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixto en realidad, mirada, mirada como destino, interacción, diseñar, manos cerca, HoloLens
ms.openlocfilehash: 412d77a1d7446f82ddf43f051fdb149cb1fd559c
ms.sourcegitcommit: d565a69a9320e736304372b3f010af1a4d286a62
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/20/2019
ms.locfileid: "65940767"
---
# <a name="direct-manipulation-with-hands"></a><span data-ttu-id="a8973-104">Manipulación directa con manos</span><span class="sxs-lookup"><span data-stu-id="a8973-104">Direct manipulation with hands</span></span>
<span data-ttu-id="a8973-105">La manipulación directa es un modelo de entrada que implica tocar hologramas directamente con las manos.</span><span class="sxs-lookup"><span data-stu-id="a8973-105">Direct manipulation is an input model that involves touching holograms directly with your hands.</span></span> <span data-ttu-id="a8973-106">La manipulación directa, el objetivo es que los objetos se comportan igual que en el mundo real.</span><span class="sxs-lookup"><span data-stu-id="a8973-106">The goal with direct manipulation is that objects behave just as they do in the real world.</span></span> <span data-ttu-id="a8973-107">Botones que se pueden activar simplemente presionándolos, los objetos se pueden seleccionarlos contratiempos y contenido 2D se comporta como una pantalla táctil virtual.</span><span class="sxs-lookup"><span data-stu-id="a8973-107">Buttons can be activated simply by pressing them, objects can be picked up by grabbing them, and 2D content behaves like a virtual touchscreen.</span></span>  <span data-ttu-id="a8973-108">Por este motivo, dirigir es fácil para los usuarios obtener información sobre la manipulación, así como de la diversión demasiado.</span><span class="sxs-lookup"><span data-stu-id="a8973-108">Because of this, direct manipulation is easy for users to learn, and it's fun too.</span></span>  <span data-ttu-id="a8973-109">Se considera un "cerca de" modelo de entrada, lo que significa que está concebida para interactuar con el contenido que está dentro de brazos llegar.</span><span class="sxs-lookup"><span data-stu-id="a8973-109">It is considered a "near" input model, meaning it is best used for interacting with content that is within arms reach.</span></span>

<span data-ttu-id="a8973-110">Manipulación directa es la prestación de la base, lo que significa que es fácil de usar.</span><span class="sxs-lookup"><span data-stu-id="a8973-110">Direct manipulation is affordance-based, meaning it's user friendly.</span></span> <span data-ttu-id="a8973-111">No hay ningún gestos simbólicos a enseñar a los usuarios.</span><span class="sxs-lookup"><span data-stu-id="a8973-111">There are no symbolic gestures to teach users.</span></span> <span data-ttu-id="a8973-112">Todas las interacciones se basan en un elemento visual que puede tocar ni tomar.</span><span class="sxs-lookup"><span data-stu-id="a8973-112">All interactions are built around a visual element that you can touch or grab.</span></span>

## <a name="device-support"></a><span data-ttu-id="a8973-113">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="a8973-113">Device support</span></span>


| <span data-ttu-id="a8973-114">Modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="a8973-114">Input Model</span></span> | [<span data-ttu-id="a8973-115">HoloLens (Gen 1)</span><span class="sxs-lookup"><span data-stu-id="a8973-115">HoloLens (1st Gen)</span></span>](https://review.docs.microsoft.com/en-us/windows/mixed-reality/hololens-hardware-details?branch=master) | <span data-ttu-id="a8973-116">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="a8973-116">HoloLens 2</span></span> |[<span data-ttu-id="a8973-117">Inmersivos</span><span class="sxs-lookup"><span data-stu-id="a8973-117">Immersive Headsets</span></span>](https://review.docs.microsoft.com/en-us/windows/mixed-reality/immersive-headset-hardware-details?branch=master)|
|:-------- | :-------| :--------| :------------|
| <span data-ttu-id="a8973-118">Manipulación directa</span><span class="sxs-lookup"><span data-stu-id="a8973-118">Direct manipulation</span></span> | <span data-ttu-id="a8973-119">❌ No compatible</span><span class="sxs-lookup"><span data-stu-id="a8973-119">❌ Not supported</span></span> | <span data-ttu-id="a8973-120">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="a8973-120">✔️ Recommended</span></span> | <span data-ttu-id="a8973-121">Una alternativa ➕ [elija y confirme](https://review.docs.microsoft.com/en-us/windows/mixed-reality/point-and-commit?branch=master) se recomienda.</span><span class="sxs-lookup"><span data-stu-id="a8973-121">➕ An alternative [point and commit](https://review.docs.microsoft.com/en-us/windows/mixed-reality/point-and-commit?branch=master) is recommended.</span></span>

<span data-ttu-id="a8973-122">Manipulación directa es un modelo de entrada principal en HoloLens 2 y usa el nuevo sistema de seguimiento de la mano articulado.</span><span class="sxs-lookup"><span data-stu-id="a8973-122">Direct manipulation is a primary input model on HoloLens 2, and utilizes the new articulated hand-tracking system.</span></span> <span data-ttu-id="a8973-123">El modelo de entrada también está disponible en inmersivos mediante el uso de los controladores de movimiento, pero no se recomienda como medio principal de interacción fuera de la manipulación del objeto.</span><span class="sxs-lookup"><span data-stu-id="a8973-123">The input model is also available on immersive headsets through the use of motion controllers, but is not recommended as a primary means of interaction outside of object manipulation.</span></span>  <span data-ttu-id="a8973-124">Dirigir manipluation no está disponible en HoloLens (gen 1).</span><span class="sxs-lookup"><span data-stu-id="a8973-124">Direct manipluation is not available on HoloLens (1st gen).</span></span>


## <a name="collidable-fingertip"></a><span data-ttu-id="a8973-125">Yema collidable</span><span class="sxs-lookup"><span data-stu-id="a8973-125">Collidable fingertip</span></span>

<span data-ttu-id="a8973-126">En HoloLens 2, se reconoce manos real del usuario y se interpretan como modelos de esqueleto mano izquierda y derecha.</span><span class="sxs-lookup"><span data-stu-id="a8973-126">On HoloLens 2, the user's real hands are recognized and interpreted as left and right hand skeletal models.</span></span> <span data-ttu-id="a8973-127">Para implementar la idea de tocar hologramas directamente con las manos, idealmente, 5 colisionadores se podrían conectar a 5 alcance de cada modelo de esqueleto de la mano.</span><span class="sxs-lookup"><span data-stu-id="a8973-127">To implement the idea of touching holograms directly with hands, ideally, 5 colliders could be attached to 5 fingertips of each hand skeletal model.</span></span> <span data-ttu-id="a8973-128">Sin embargo, en la práctica, debido a la falta de comentarios al tacto, 10 alcance collidable provocó colisiones inesperadas e impredecibles con hologramas.</span><span class="sxs-lookup"><span data-stu-id="a8973-128">However, practically, due to the lack of tactile feedback, 10 collidable fingertips caused unexpected and unpredictable collisions with holograms.</span></span> 

<span data-ttu-id="a8973-129">Por lo tanto, se recomienda para poner solo un colisionador en cada dedo índice.</span><span class="sxs-lookup"><span data-stu-id="a8973-129">Hence, we suggest to only put a collider on each index finger.</span></span> <span data-ttu-id="a8973-130">El alcance del índice collidable todavía puede actuar como puntos de toque activa para los gestos de toque diverso que implican otro dedo, por ejemplo, presione un dedo 1, 1-dedo tap, presione un dedo 2 y 5 dedo press, tal como se muestra en la imagen siguiente.</span><span class="sxs-lookup"><span data-stu-id="a8973-130">The collidable index fingertips can still serve as active touch points for diverse touch gestures involving other fingers, such as 1-finger press, 1-finger tap, 2-finger press and 5-finger press, as shown in the image below.</span></span>

![Imagen de la yema del dedo collidable](images/Collidable-Fingertip-720px.jpg)

### <a name="sphere-collider"></a><span data-ttu-id="a8973-132">Colisionador esfera</span><span class="sxs-lookup"><span data-stu-id="a8973-132">Sphere collider</span></span>

<span data-ttu-id="a8973-133">En lugar de una forma genérica aleatoria, se recomienda usar un colisionador esfera y para representar visualmente para proporcionar indicaciones mejores para dirigirse a casi.</span><span class="sxs-lookup"><span data-stu-id="a8973-133">Instead of using a random generic shape, we suggest to use a sphere collider and to visually render it to provide better cues for near targeting.</span></span> <span data-ttu-id="a8973-134">Diámetro de la esfera debe coincidir con el grosor del dedo índice para aumentar la precisión de toque.</span><span class="sxs-lookup"><span data-stu-id="a8973-134">The sphere's diameter should match the thickness of the index finger to increase touch accuracy.</span></span> <span data-ttu-id="a8973-135">Será fácil recuperar la variable de grosor dedo mediante una llamada a la API de mano.</span><span class="sxs-lookup"><span data-stu-id="a8973-135">It will be easy to retrieve the variable of finger thickness by calling the hand API.</span></span>

### <a name="fingertip-cursor"></a><span data-ttu-id="a8973-136">Cursor de la yema del dedo</span><span class="sxs-lookup"><span data-stu-id="a8973-136">Fingertip cursor</span></span>

<span data-ttu-id="a8973-137">Además de representar una esfera de la yema del dedo índice collidable, hemos creado una solución avanzada, cursor yema, para lograr una mejor experiencia orientado a cerca de interactivamente.</span><span class="sxs-lookup"><span data-stu-id="a8973-137">In addition to rendering a collidable sphere on the index fingertip, we've created an advanced solution, fingertip cursor, to achieve better near-targeting experience interactively.</span></span> <span data-ttu-id="a8973-138">Es un cursor en forma de anillo asociado en la yema del dedo índice.</span><span class="sxs-lookup"><span data-stu-id="a8973-138">It is a donut-shaped cursor attached on the index fingertip.</span></span> <span data-ttu-id="a8973-139">Según la proximidad, dinámicamente reacciona a un destino en términos de orientación y el tamaño como se detalla a continuación:</span><span class="sxs-lookup"><span data-stu-id="a8973-139">According to proximity, it dynamically reacts to a target in terms of orientation and size as detailed below:</span></span>

* <span data-ttu-id="a8973-140">Cuando se mueve un dedo índice hacia un holograma, el cursor siempre es parecido a la superficie del holograma y gradualmente reduce su tamaño.</span><span class="sxs-lookup"><span data-stu-id="a8973-140">When an index finger moves toward a hologram, the cursor is always parallel to the hologram's surface  and gradually shrinks its size accordingly.</span></span>
* <span data-ttu-id="a8973-141">Tan pronto como el dedo toque la superficie, el cursor se reduce en un punto y emite un evento de toque.</span><span class="sxs-lookup"><span data-stu-id="a8973-141">As soon as the finger touches the surface, the cursor shrinks into a dot and emits a touch event.</span></span>

<span data-ttu-id="a8973-142">Con la información interactiva, los usuarios puedan lograr alta precisión cerca de destinatarios de tareas, como desencadenar un hipervínculo en el contenido web o al presionar un botón, como se muestra a continuación.</span><span class="sxs-lookup"><span data-stu-id="a8973-142">With the interactive feedback, users can achieve high precision near targeting tasks, such as triggering a hyperlink on web content or pressing a button, as shown, below.</span></span> 

![Imagen del cursor yema del dedo](images/Fingertip-Cursor-720px.jpg)

## <a name="bounding-box-with-proximity-shader"></a><span data-ttu-id="a8973-144">Cuadro de límite con el sombreador de proximidad</span><span class="sxs-lookup"><span data-stu-id="a8973-144">Bounding box with proximity shader</span></span>

<span data-ttu-id="a8973-145">Holograma de sí mismo también requiere la capacidad de proporcionar comentarios visuales y de audio para compensar la falta de comentarios al tacto.</span><span class="sxs-lookup"><span data-stu-id="a8973-145">The hologram itself also requires the ability to provide both visual and audio feedback to compensate the lack of tactile feedback.</span></span> <span data-ttu-id="a8973-146">Para eso, generamos el concepto de un rectángulo con el sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="a8973-146">For that, we generate the concept of a bounding box with proximity shader.</span></span> <span data-ttu-id="a8973-147">Un cuadro de límite es una superficie mínima volumétrica que rodea a un objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="a8973-147">A bounding box is a minimum volumetric area that encloses a 3D object.</span></span> <span data-ttu-id="a8973-148">El rectángulo tiene un mecanismo de representación interactiva denominado a sombreador de proximidad.</span><span class="sxs-lookup"><span data-stu-id="a8973-148">The bounding box has an interactive rendering mechanism called proximity shader.</span></span> <span data-ttu-id="a8973-149">Se comporta el sombreador de proximidad:</span><span class="sxs-lookup"><span data-stu-id="a8973-149">The proximity shader behaves:</span></span>

* <span data-ttu-id="a8973-150">Cuando el dedo índice está dentro del intervalo, se convierte un foco yema del dedo en la superficie del cuadro de límite.</span><span class="sxs-lookup"><span data-stu-id="a8973-150">When the index finger is within a range, a fingertip spotlight is cast on the surface of bounding box.</span></span>
* <span data-ttu-id="a8973-151">Cuando se aproxime la yema del dedo a la superficie, destacados condensa según corresponda.</span><span class="sxs-lookup"><span data-stu-id="a8973-151">When the fingertip gets closer to the surface, the spotlight condenses accordingly.</span></span>
* <span data-ttu-id="a8973-152">Tan pronto como la yema del dedo toque la superficie, todo el rectángulo de selección cambia el color o generar un efecto visual para reflejar el estado de toque.</span><span class="sxs-lookup"><span data-stu-id="a8973-152">As soon as the fingertip touch the surface, the whole bounding box changes the color or generate visual effect to reflect the touch state.</span></span>
* <span data-ttu-id="a8973-153">Mientras tanto, se puede activar un efecto de sonido para mejorar los comentarios de visual táctil.</span><span class="sxs-lookup"><span data-stu-id="a8973-153">Meanwhile, a sound effect can be activated to enhance the visual touch feedback.</span></span>

![Cuadro de límite con la imagen del sombreador de proximidad](images/Bounding-Box-With-Proximity-Shader-720px.jpg)

## <a name="pressable-button"></a><span data-ttu-id="a8973-155">Botón pressable</span><span class="sxs-lookup"><span data-stu-id="a8973-155">Pressable button</span></span>

<span data-ttu-id="a8973-156">Con el dedo collidable, los usuarios ahora están listos para interactuar con el componente holográfico muy fundamental de la interfaz de usuario, botón pressable.</span><span class="sxs-lookup"><span data-stu-id="a8973-156">With a collidable fingertip, users are now ready to interact with the very fundamental holographic UI component, pressable button.</span></span> <span data-ttu-id="a8973-157">Un botón pressable es un holográfica adaptada de presionar el dedo directa.</span><span class="sxs-lookup"><span data-stu-id="a8973-157">A pressable button is a holographic button tailored for direct finger press.</span></span> <span data-ttu-id="a8973-158">Nuevamente, debido a la falta de comentarios al tacto, un botón pressable proporciona dos mecanismos para abordar problemas relacionados con comentarios al tacto.</span><span class="sxs-lookup"><span data-stu-id="a8973-158">Again, due to the lack of tactile feedback, a pressable button equips a couple mechanisms to tackle tactile feedback-related issues.</span></span>

* <span data-ttu-id="a8973-159">El primer mecanismo es un rectángulo con el sombreador de proximidad, detallado en la sección anterior.</span><span class="sxs-lookup"><span data-stu-id="a8973-159">The first mechanism is a bounding box with proximity shader, detailed in the previous section.</span></span> <span data-ttu-id="a8973-160">Sirve para proporcionar un mejor sentido de proximidad a los usuarios enfocar y asegúrese de contacto con un botón.</span><span class="sxs-lookup"><span data-stu-id="a8973-160">It serves to provide better sense of proximity for users to approach and make contact with a button.</span></span>
* <span data-ttu-id="a8973-161">La segunda es la depresión.</span><span class="sxs-lookup"><span data-stu-id="a8973-161">The second one is depression.</span></span> <span data-ttu-id="a8973-162">Crea sensación de prensa, después de un dedo pone en contacto con el botón.</span><span class="sxs-lookup"><span data-stu-id="a8973-162">It creates sense of press, after a fingertip contacts the button.</span></span> <span data-ttu-id="a8973-163">El mecanismo es que el botón se mueve estrechamente con el dedo en el eje de profundidad.</span><span class="sxs-lookup"><span data-stu-id="a8973-163">The mechanism is that the button tightly moves with the fingertip along the depth axis.</span></span> <span data-ttu-id="a8973-164">El botón puede activarse cuando alcanza una profundidad designada (al presionar) o se sale de la profundidad (en lanzamiento) después de pasar a través de él.</span><span class="sxs-lookup"><span data-stu-id="a8973-164">The button can be triggered when it reaches a designated depth (on press) or leaves the depth (on release) after passing through it.</span></span>
* <span data-ttu-id="a8973-165">El efecto de sonido se debe agregar para mejorar los comentarios, cuando se activa el botón.</span><span class="sxs-lookup"><span data-stu-id="a8973-165">The sound effect should be added to enhance feedback, when the button is triggered.</span></span>

![Imagen del botón pressable](images/Pressable-Button-720px.jpg)

## <a name="2d-slate-interaction"></a><span data-ttu-id="a8973-167">Interacción de pizarra 2D</span><span class="sxs-lookup"><span data-stu-id="a8973-167">2D slate interaction</span></span>

<span data-ttu-id="a8973-168">Una pizarra 2D es un contenedor holográfico hospedar contenido de la aplicación 2D, como explorador web.</span><span class="sxs-lookup"><span data-stu-id="a8973-168">A 2D slate is a holographic container hosting 2D app contents, such as web browser.</span></span> <span data-ttu-id="a8973-169">El concepto de diseño para interactuar con una pizarra 2D a través de la manipulación directa es aprovechar el modelo mental de interactuar con una pantalla táctil físico.</span><span class="sxs-lookup"><span data-stu-id="a8973-169">The design concept for interacting with a 2D slate via direct manipulation is to leverage the mental model of interacting with a physical touch screen.</span></span>

<span data-ttu-id="a8973-170">Para interactuar con el contacto Pizarra:</span><span class="sxs-lookup"><span data-stu-id="a8973-170">To interact with the slate contact:</span></span>

* <span data-ttu-id="a8973-171">Utilice un dedo índice presionar un botón o un hipervínculo.</span><span class="sxs-lookup"><span data-stu-id="a8973-171">Use an index finger to press a hyperlink or a button.</span></span>
* <span data-ttu-id="a8973-172">Utilice un dedo índice desplazar una pizarra contenido hacia arriba y abajo.</span><span class="sxs-lookup"><span data-stu-id="a8973-172">Use an index finger to scroll a slate content up and down.</span></span>
* <span data-ttu-id="a8973-173">Los usuarios usar dos dedos de índice para aumentar y reducir el contenido de pizarra según movimiento relativo de los dedos.</span><span class="sxs-lookup"><span data-stu-id="a8973-173">Users use two index fingers to zoom in and out the slate content according to relative motion of fingers.</span></span>

![Imagen de pizarra 2D](images/2D-Slate-Interaction-720px.jpg)

<span data-ttu-id="a8973-175">Para manipular la 2D Pizarra propio:</span><span class="sxs-lookup"><span data-stu-id="a8973-175">For manipulating the 2D slate itself:</span></span>

* <span data-ttu-id="a8973-176">Aborde las manos hacia las esquinas y bordes para revelar la factibilidad de manipulación más cercano.</span><span class="sxs-lookup"><span data-stu-id="a8973-176">Approach your hands toward corners and edges to reveal the closest manipulation affordances.</span></span>
* <span data-ttu-id="a8973-177">Agarre la factibilidad de manipulación y realizar un escalado uniforme a través de las prestaciones de la esquina y reflujo a través de las prestaciones de edge.</span><span class="sxs-lookup"><span data-stu-id="a8973-177">Grab the manipulation affordances, and perform uniform scaling through the corner affordances and reflow via the edge affordances.</span></span>
* <span data-ttu-id="a8973-178">Arrastre el holobar en la parte superior de la Pizarra 2D, lo que le permite mover la Pizarra toda.</span><span class="sxs-lookup"><span data-stu-id="a8973-178">Grab the holobar at the top of the 2D slate, which lets you move the whole slate.</span></span>

![Imagen de pizarra manipulación](images/Manipulate-2d-slate-720px.jpg)

## <a name="3d-object-manipulation"></a><span data-ttu-id="a8973-180">Manipulación del objeto 3D</span><span class="sxs-lookup"><span data-stu-id="a8973-180">3D object manipulation</span></span>

<span data-ttu-id="a8973-181">HoloLens 2 permite que permite a los usuarios habilitan sus manos dirigir manipular objetos 3D hologramphic aplicando un cuadro de límite para cada objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="a8973-181">HoloLens 2 lets lets users enable their hands to direct manipulate 3D hologramphic objects by applying a bounding box to each 3D object.</span></span> <span data-ttu-id="a8973-182">El cuadro de límite proporciona una mejor percepción de profundidad a través de su sombras de proximidad.</span><span class="sxs-lookup"><span data-stu-id="a8973-182">The bounding box provides better depth perception through its proximity shader.</span></span> <span data-ttu-id="a8973-183">Con el cuadro de límite, hay dos enfoques de diseño para la manipulación del objeto 3D.</span><span class="sxs-lookup"><span data-stu-id="a8973-183">With the bounding box, there are two design approaches for 3D object manipulation.</span></span>

### <a name="affordance-based-manipulation"></a><span data-ttu-id="a8973-184">Manipulación de prestación</span><span class="sxs-lookup"><span data-stu-id="a8973-184">Affordance-based manipulation</span></span>

<span data-ttu-id="a8973-185">Esto le permite manipular el objeto 3D a través de un cuadro de límite y la factibilidad de manipulación alrededor de ella.</span><span class="sxs-lookup"><span data-stu-id="a8973-185">This lets you manipulate the 3D object through a bounding box and the manipulation affordances around it.</span></span> <span data-ttu-id="a8973-186">Tan pronto como parte de un usuario está a punto de un objeto 3D, se revelan el cuadro de límite y la prestación más cercano.</span><span class="sxs-lookup"><span data-stu-id="a8973-186">As soon as a user's hand is close to a 3D object, the bounding box and the nearest affordance are revealed.</span></span> <span data-ttu-id="a8973-187">Los usuarios pueden tomar el cuadro de límite para mover todo el objeto, la factibilidad de borde se va a girar y las prestaciones de la esquina para escalar de manera uniforme.</span><span class="sxs-lookup"><span data-stu-id="a8973-187">Users can grab the bounding box to move the whole object, the edge affordances to rotate and the corner affordances to scale uniformly.</span></span>

![Imagen de manipulación del objeto 3D](images/3D-Object-Manipulation-720px.jpg)

### <a name="non-affordance-based-manipulation"></a><span data-ttu-id="a8973-189">No prestación en función de manipulación</span><span class="sxs-lookup"><span data-stu-id="a8973-189">Non-affordance based manipulation</span></span>

<span data-ttu-id="a8973-190">En este mecanismo, no se asocia ninguna prestación en el cuadro de límite.</span><span class="sxs-lookup"><span data-stu-id="a8973-190">In this mechanism, no affordance is attached to the bounding box.</span></span> <span data-ttu-id="a8973-191">Los usuarios pueden revelar sólo el rectángulo de selección y luego interactuar directamente con él.</span><span class="sxs-lookup"><span data-stu-id="a8973-191">Users can only reveal the bounding box, then directly interact with it.</span></span> <span data-ttu-id="a8973-192">Si el cuadro de límite se obtiene con una mano, la traslación y rotación del objeto se asocian a movimiento y la orientación de la mano.</span><span class="sxs-lookup"><span data-stu-id="a8973-192">If the bounding box is grabbed with one hand, the translation and rotation of the object are associated to motion and orientation of the hand.</span></span> <span data-ttu-id="a8973-193">Cuando el objeto se obtiene con dos manos, los usuarios pueden trasladar, escalar y girarlo según los movimientos relativos de dos manos.</span><span class="sxs-lookup"><span data-stu-id="a8973-193">When the object is grabbed with two hands, users can translate, scale and rotate it according to relative motions of two hands.</span></span>

<span data-ttu-id="a8973-194">Manipulación concreta requiere la precisión, se recomienda que use **manipulación de prestación**, ya que proporciona un alto nivel de granularidad.</span><span class="sxs-lookup"><span data-stu-id="a8973-194">Specific manipulation requires precision, we recommend you use **affordance-based manipulation**, because it provides a high level of granularity.</span></span> <span data-ttu-id="a8973-195">Para la manipulación flexible, le recomendamos que usa **manipulación no prestación** es porque permite que las experiencias de instantáneas y divertidas.</span><span class="sxs-lookup"><span data-stu-id="a8973-195">For flexible manipulation, we recommend you uses **non-affordance manipulation** is as it allows for instant and playful experiences.</span></span>

## <a name="instinctual-gestures"></a><span data-ttu-id="a8973-196">Gestos instinctual</span><span class="sxs-lookup"><span data-stu-id="a8973-196">Instinctual gestures</span></span>

<span data-ttu-id="a8973-197">Con HoloLens (gen 1), se enseñan los usuarios un par gestos predefinidos, como Bloom y puntee en el aire.</span><span class="sxs-lookup"><span data-stu-id="a8973-197">With HoloLens (1st gen), we taught users a couple predefined gestures,such as Bloom and Air Tap.</span></span> <span data-ttu-id="a8973-198">Para HoloLens 2, no pedimos a los usuarios que memorizar los gestos simbólicos.</span><span class="sxs-lookup"><span data-stu-id="a8973-198">For HoloLens 2, we don't ask users to memorize any symbolic gestures.</span></span> <span data-ttu-id="a8973-199">Todos los gestos de usuario necesarios, los usuarios deben interactuar con hologramas y el contenido, son instinctual.</span><span class="sxs-lookup"><span data-stu-id="a8973-199">All required user gestures, users need to interact with holograms and contents, are instinctual.</span></span> <span data-ttu-id="a8973-200">Es la forma de lograr gesto instinctual guiar a los usuarios para llevar a cabo movimientos con el diseño de prestaciones de la interfaz de usuario.</span><span class="sxs-lookup"><span data-stu-id="a8973-200">The way to achieve instinctual gesture is to guide users to perform gestures through the design of UI affordances.</span></span>

<span data-ttu-id="a8973-201">Por ejemplo, si le animamos a que arrastre un objeto o un punto de control con pinch dos dedos, el objeto o el punto de control debe ser pequeño.</span><span class="sxs-lookup"><span data-stu-id="a8973-201">For example, if we encourage you to grab an object or a control point with two finger pinch, the object or the control point should be small.</span></span> <span data-ttu-id="a8973-202">Si queremos realizar cinco grab del dedo, el objeto o el punto de control debería ser relativamente grande.</span><span class="sxs-lookup"><span data-stu-id="a8973-202">If we want you to perform five finger grab, the object or the control point should be relatively big.</span></span> <span data-ttu-id="a8973-203">Al igual que los botones, un botón pequeño limitaría usuarios, haga clic con un solo dedo, mientras que un botón enorme insto a los usuarios presionen con sus palmas.</span><span class="sxs-lookup"><span data-stu-id="a8973-203">Similar to buttons, a tiny button would limit users to press it with a single finger, while a huge button would encourage users to press it with their palms.</span></span>

![](images/Instinctual-Gestures-720px.jpg)

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a><span data-ttu-id="a8973-204">Diseño simétrica entre manos y controladores GDL 6</span><span class="sxs-lookup"><span data-stu-id="a8973-204">Symmetric design between hands and 6 DoF controllers</span></span>

<span data-ttu-id="a8973-205">Es posible que haya observado que ahora hay parallels interacción que podemos dibujar entre manos en los controladores VR AR y movimiento.</span><span class="sxs-lookup"><span data-stu-id="a8973-205">You may have noticed that there are now interaction parallels we can draw between hands in AR and motion controllers in VR.</span></span> <span data-ttu-id="a8973-206">Las dos entradas pueden usarse para desencadenar manipulaciones en sus respectivos entornos.</span><span class="sxs-lookup"><span data-stu-id="a8973-206">Both inputs can be used to trigger direct manipulations in their respective environments.</span></span> <span data-ttu-id="a8973-207">En el 2 de HoloLens, hacerlo y arrastre las manos de un works corta distancia mucho en la misma manera que el botón de agarre hace en los controladores de movimiento en WMR.</span><span class="sxs-lookup"><span data-stu-id="a8973-207">In HoloLens 2, grabbing and dragging with hands at a close distance works much in the same way as the grab button does on the motion controllers in WMR.</span></span> <span data-ttu-id="a8973-208">Esto proporciona a los usuarios con la familiaridad de la interacción entre las dos plataformas y puede resultar útil si alguna vez decide portar tu aplicación de uno a otro.</span><span class="sxs-lookup"><span data-stu-id="a8973-208">This provides users with interaction familiarity between the two platforms and may prove useful should you ever decide to port your app from one to the other.</span></span>

## <a name="optimize-with-eye-tracking"></a><span data-ttu-id="a8973-209">Optimizar el seguimiento de los ojos</span><span class="sxs-lookup"><span data-stu-id="a8973-209">Optimize with eye tracking</span></span>

<span data-ttu-id="a8973-210">Si funciona según lo previsto, pero puede volverse rápidamente también frustrante si no se puede mover la mano en cualquier parte ya sin desencadenar involuntariamente un holograma, puede sentirse mágica manipulación directa.</span><span class="sxs-lookup"><span data-stu-id="a8973-210">Direct manipulation can feel magical if it works as intended, but can also quickly become frustrating if you can’t move your hand anywhere anymore without unintentionally triggering a hologram.</span></span>
<span data-ttu-id="a8973-211">Seguimiento de los ojos potencialmente pueden ayudar a identificar mejor lo que es la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="a8973-211">Eye tracking can potentially help in better identifying what the user’s intent is.</span></span>

* <span data-ttu-id="a8973-212">**When**: Reducir falsamente desencadenar una respuesta de manipulación.</span><span class="sxs-lookup"><span data-stu-id="a8973-212">**When**: Reduce falsely triggering a manipulation response.</span></span> <span data-ttu-id="a8973-213">Permite entender mejor lo que un usuario esté implicado actualmente con seguimiento de los ojos.</span><span class="sxs-lookup"><span data-stu-id="a8973-213">Eye tracking allows for better understanding what a user is currently engaged with.</span></span>
<span data-ttu-id="a8973-214">Por ejemplo, imagine que está leyendo a través de un texto (informativo) holográfica al alcanzar otra vez para obtener la herramienta de trabajo reales.</span><span class="sxs-lookup"><span data-stu-id="a8973-214">For example, imagine you are reading through a holographic (instructional) text when reaching over to grab you real-world work tool.</span></span>

<span data-ttu-id="a8973-215">Al hacerlo, accidentalmente mover la mano a través de algunos botones holográfica interactivos que incluso no vio antes (por ejemplo, era incluso fuera campo de visión del usuario en el (FOV)).</span><span class="sxs-lookup"><span data-stu-id="a8973-215">By doing so, you accidentally move your hand across some interactive holographic buttons that you hadn't even noticed before (maybe it even was outside of the user's Field-of-View (FOV)).</span></span>

  <span data-ttu-id="a8973-216">Para hacer el cuento corto: Si el usuario no ha visto un holograma durante un tiempo, pero se ha detectado un evento táctil o entender para él, es probable que el usuario realmente indebida interactuar con ese holograma.</span><span class="sxs-lookup"><span data-stu-id="a8973-216">Long story short: If the user hasn't looked at a hologram for a while, yet a touch or grasp event has been detected for it, it is likely that the user wasn't actually intending to interact with that hologram.</span></span>

* <span data-ttu-id="a8973-217">**Cuál**:  Aparte de direccionamiento activaciones positivas falsas, otro ejemplo incluye la identificación de mejor qué hologramas para captar o echar un vistazo que no puede ser el punto de intersección precisa claro desde su perspectiva sobre todo si se colocan varias hologramas cerca de cada uno Otro.</span><span class="sxs-lookup"><span data-stu-id="a8973-217">**Which one**:  Aside from addressing false positive activations, another example includes better identifying which holograms to grab or poke as the precise intersection point may not be clear from your perspective especially if several holograms are positioned close to each other.</span></span>

  <span data-ttu-id="a8973-218">Mientras que realizar un seguimiento de ojos en HoloLens 2 tiene una limitación determinada acerca de cómo con precisión puede determinar ocular a mirada, esto todavía puede ser muy útil para casi interacciones debido a la disparidad de profundidad al interactuar con la mano de entrada.</span><span class="sxs-lookup"><span data-stu-id="a8973-218">While eye tracking on HoloLens 2 has a certain limitation on how accurately it can determine you eye gaze, this can still be very helpful for near interactions due to depth disparity when interacting with hand input.</span></span>  <span data-ttu-id="a8973-219">Esto significa que a veces es difícil determinar si la mano es detrás o delante un holograma precisamente por ejemplo a tomar un widget de manipulación.</span><span class="sxs-lookup"><span data-stu-id="a8973-219">This means that it is sometimes difficult to determine whether your hand is behind or in front of a hologram to precisely grab a manipulation widget for example.</span></span>

* <span data-ttu-id="a8973-220">**Dónde**: Información de uso sobre lo que un usuario está viendo con quick - produce los gestos.</span><span class="sxs-lookup"><span data-stu-id="a8973-220">**Where to**: Use information about what a user is looking at with quick- throwing gestures.</span></span> <span data-ttu-id="a8973-221">Tome un holograma y aproximadamente lo meter hacia su destino previsto.</span><span class="sxs-lookup"><span data-stu-id="a8973-221">Grab a hologram and roughly toss it toward your intended destination.</span></span>  

    <span data-ttu-id="a8973-222">Aunque esto es posible que a veces funciona perfectamente, rápidamente realizar gestos de mano puede dar lugar destinos muy imprecisos.</span><span class="sxs-lookup"><span data-stu-id="a8973-222">While this may sometimes works just fine, quickly performing hand gestures may result in highly inaccurate destinations.</span></span> <span data-ttu-id="a8973-223">Esto es donde rastreo ocular podría ayudar a al inclinar la mano producir vector de vuelta a la posición deseada.</span><span class="sxs-lookup"><span data-stu-id="a8973-223">This is where eye tracking could help out to lean the hand throwing vector back to your intended position.</span></span>

## <a name="see-also"></a><span data-ttu-id="a8973-224">Vea también</span><span class="sxs-lookup"><span data-stu-id="a8973-224">See also</span></span>

* [<span data-ttu-id="a8973-225">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="a8973-225">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="a8973-226">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="a8973-226">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="a8973-227">Interacciones instintivas</span><span class="sxs-lookup"><span data-stu-id="a8973-227">Instinctual interactions</span></span>](interaction-fundamentals.md)

