---
title: Información general de la interacción multimodal
description: Información general de la interacción multimodal
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixto en realidad, mirada, mirada como destino, interacción, diseñar, hololens, MMR, multimodal
ms.openlocfilehash: 9d0e639d7474c7e8728282acfa8d288cfeec7043
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974904"
---
# <a name="introducing-instinctual-interactions"></a><span data-ttu-id="dc776-104">Introducción a las interacciones instinctual</span><span class="sxs-lookup"><span data-stu-id="dc776-104">Introducing instinctual interactions</span></span>

<span data-ttu-id="dc776-105">La filosofía de interacciones simple, instinctual es tejida a lo largo de la plataforma Microsoft Mixed Reality (MMR), de hardware al software.</span><span class="sxs-lookup"><span data-stu-id="dc776-105">The philosophy of simple, instinctual interactions is woven throughout the Microsoft Mixed Reality (MMR) platform, from hardware to software.</span></span>

<span data-ttu-id="dc776-106">Estas interacciones instinctual utilizan todas las tecnologías de entrada disponibles, incluido el seguimiento por completo, disponible de seguimiento, seguimiento de los ojos y lenguaje natural, en los modelos de interacción multimodal perfecta.</span><span class="sxs-lookup"><span data-stu-id="dc776-106">These instinctual interactions utilize all available input technologies, including inside-out tracking, hand tracking, eye tracking, and natural language, in seamless multimodal interaction models.</span></span> <span data-ttu-id="dc776-107">Según nuestras investigaciones, diseñar y desarrollar multimodals y no en función de unas entradas únicas, es fundamental al crear experiencias instintiva.</span><span class="sxs-lookup"><span data-stu-id="dc776-107">Based on our research, designing and developing multimodals, and not based on single inputs, is critical when creating instinctive experiences.</span></span>

<span data-ttu-id="dc776-108">Los modelos de interacción Instinctual también naturalmente alinearán por tipo de dispositivo.</span><span class="sxs-lookup"><span data-stu-id="dc776-108">The Instinctual Interaction models also naturally align across device types.</span></span>  <span data-ttu-id="dc776-109">Por ejemplo, interacción lejano en un auricular envolvente con un 6 grados de controlador de libertad (DoF) e interacción lejos de un 2 HoloLens usar los mismos prestaciones, patrones y comportamientos.</span><span class="sxs-lookup"><span data-stu-id="dc776-109">For example, far interaction on an immersive headset with a 6 degrees of freedom (DoF) controller and far interaction on a HoloLens 2 use the same affordances, patterns, and behaviors.</span></span>  <span data-ttu-id="dc776-110">No sólo es este práctico para los desarrolladores y diseñadores, pero se siente más cómodo a los usuarios finales.</span><span class="sxs-lookup"><span data-stu-id="dc776-110">Not only is this convenient for developers and designers, but it feels natural to end users.</span></span>


<span data-ttu-id="dc776-111">Por último, aunque reconocemos que existen miles de efectivo, atractivas y mágicos interacciones posibles en MR, hemos descubierto que intencionadamente que emplean un modelo de interacción único extremo a extremo en una aplicación es la mejor manera de asegurarse de que los usuarios son correctas y tiene una gran experiencia.</span><span class="sxs-lookup"><span data-stu-id="dc776-111">Lastly, while we recognize that there are thousands of effective, engaging, and magical interactions possible in MR, we have found that intentionally employing a single interaction model end to end in an application is the best way to ensure users are successful and have a great experience.</span></span>  <span data-ttu-id="dc776-112">Para ello, hemos incluido tres cosas en esta guía de interacción:</span><span class="sxs-lookup"><span data-stu-id="dc776-112">To that end, we've included three things in this interaction guidance:</span></span>
* <span data-ttu-id="dc776-113">Nos hemos estructurado esta orientación acerca de los tres modelos de interacción principal y los componentes y patrones para cada uno</span><span class="sxs-lookup"><span data-stu-id="dc776-113">We've structured this guidance around the three primary interaction models and the components and patterns required for each</span></span>
* <span data-ttu-id="dc776-114">Hemos incluido orientación complementaria en otras ventajas que ofrece nuestra plataforma.</span><span class="sxs-lookup"><span data-stu-id="dc776-114">We've included supplemental guidance on other benefits that our platform provides</span></span>
* <span data-ttu-id="dc776-115">Hemos incluido orientación para ayudarle a seleccionar el modelo de interacción adecuado para su escenario</span><span class="sxs-lookup"><span data-stu-id="dc776-115">We've included guidance to help select the appropriate interaction model for your scenario</span></span>

## <a name="multimodal-interaction-models"></a><span data-ttu-id="dc776-116">Modelos de interacción multimodal</span><span class="sxs-lookup"><span data-stu-id="dc776-116">Multimodal interaction models</span></span>

<span data-ttu-id="dc776-117">Según nuestras investigaciones y trabajar con clientes hasta la fecha, hemos descubierto tres modelos de interacción principal que se adapten a la mayoría de las experiencias de realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="dc776-117">Based on our research and work with customers to date, we've discovered three primary interaction models that suit the majority of Mixed Reality experiences.</span></span>  

<span data-ttu-id="dc776-118">Piense en estos modelos de interacción como modelo mental del usuario para completar sus flujos.</span><span class="sxs-lookup"><span data-stu-id="dc776-118">Think of these interaction models as the user's mental model for completing their flows.</span></span>

<span data-ttu-id="dc776-119">Cada uno de estos modelos de interacción es utilizable por derecho propio, eficaz y conveniente, y todos están optimizados para un conjunto de necesidades del cliente.</span><span class="sxs-lookup"><span data-stu-id="dc776-119">Each of these interaction models is convenient, powerful, and usable in its own right, and all are optimized for a set of customer needs.</span></span> <span data-ttu-id="dc776-120">Ver el gráfico a continuación, para escenarios, ejemplos y las ventajas de cada modelo de interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-120">View the chart below, for scenarios, examples, and benefits of each interaction model.</span></span>  

<span data-ttu-id="dc776-121">**Modelo**</span><span class="sxs-lookup"><span data-stu-id="dc776-121">**Model**</span></span> | <span data-ttu-id="dc776-122">**[Las manos y herramientas](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span><span class="sxs-lookup"><span data-stu-id="dc776-122">**[Hands and Tools](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)**</span></span> | <span data-ttu-id="dc776-123">**[Manos libres](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span><span class="sxs-lookup"><span data-stu-id="dc776-123">**[Hands free](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)**</span></span> | <span data-ttu-id="dc776-124">**[Mirada y confirmación](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span><span class="sxs-lookup"><span data-stu-id="dc776-124">**[Gaze and Commit](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**</span></span>
|--------- | --------------| ------------| ---------|
<span data-ttu-id="dc776-125">**Escenarios de ejemplo**</span><span class="sxs-lookup"><span data-stu-id="dc776-125">**Example Scenarios**</span></span> | <span data-ttu-id="dc776-126">3D experiencias espaciales, por ejemplo, espacial y un diseño, manipulación o simulación de contenido</span><span class="sxs-lookup"><span data-stu-id="dc776-126">3D spatial experiences, e.g. spatial layout and design, content manipulation, or simulation</span></span> | <span data-ttu-id="dc776-127">Experiencias contextuales donde están ocupadas manos de un usuario, por ejemplo, en el trabajo de aprendizaje, mantenimiento</span><span class="sxs-lookup"><span data-stu-id="dc776-127">Contextual experiences where a user's hands are occupied, e.g. on the-job learning, maintenance</span></span>| <span data-ttu-id="dc776-128">Click-through experiencias, por ejemplo, 3D presentaciones, demostraciones</span><span class="sxs-lookup"><span data-stu-id="dc776-128">Click-through experiences, e.g. 3D presentations, demos</span></span>
<span data-ttu-id="dc776-129">**Fit**</span><span class="sxs-lookup"><span data-stu-id="dc776-129">**Fit**</span></span> | <span data-ttu-id="dc776-130">Muy bien para usuarios nuevos, voz wit acopladas, ocular a mirada principal o de seguimiento.</span><span class="sxs-lookup"><span data-stu-id="dc776-130">Great for new users, coupled wit voice, eye tracking or head gaze.</span></span> <span data-ttu-id="dc776-131">Curva de aprendizaje reducida.</span><span class="sxs-lookup"><span data-stu-id="dc776-131">Low learning curve.</span></span> <span data-ttu-id="dc776-132">Experiencia de usuario coherente a través de la mano de seguimiento y 6 controladores GDL.</span><span class="sxs-lookup"><span data-stu-id="dc776-132">Consistent UX across hand tracking and 6 DoF controllers.</span></span> | <span data-ttu-id="dc776-133">Algunos de aprendizaje necesarios.</span><span class="sxs-lookup"><span data-stu-id="dc776-133">Some learning required.</span></span> <span data-ttu-id="dc776-134">Si las manos son pares disponible también con lenguaje natural y voz</span><span class="sxs-lookup"><span data-stu-id="dc776-134">If hands are unavailable pairs well with voice and natural language</span></span> | <span data-ttu-id="dc776-135">Requiere recursos de aprendizaje en HMDs pero no en dispositivos móviles.</span><span class="sxs-lookup"><span data-stu-id="dc776-135">Requires training on HMDs but not on mobile.</span></span> <span data-ttu-id="dc776-136">Lo mejor para controladores accesible mejor para HoloLens (gen 1)</span><span class="sxs-lookup"><span data-stu-id="dc776-136">Best for accessible controllers Best for HoloLens (1st gen)</span></span> |
<span data-ttu-id="dc776-137">**Hardware**</span><span class="sxs-lookup"><span data-stu-id="dc776-137">**Hardware**</span></span> | <span data-ttu-id="dc776-138">HoloLens 2 inmersivos</span><span class="sxs-lookup"><span data-stu-id="dc776-138">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="dc776-139">HoloLens 2 HoloLens (gen 1) inmersivos</span><span class="sxs-lookup"><span data-stu-id="dc776-139">HoloLens 2 HoloLens (1st gen) Immersive headsets</span></span> | <span data-ttu-id="dc776-140">HoloLens 2 inmersivos</span><span class="sxs-lookup"><span data-stu-id="dc776-140">HoloLens 2 Immersive headsets</span></span> | <span data-ttu-id="dc776-141">HoloLens 2 HoloLens (gen 1) inmersivos Mobile AR</span><span class="sxs-lookup"><span data-stu-id="dc776-141">HoloLens 2 HoloLens (1st gen) Immersive headsets Mobile AR</span></span> |

<span data-ttu-id="dc776-142">Información detallada para usar todas las entradas disponibles juntos sin problemas en cada modelo de interacción es en las páginas siguientes, así como las ilustraciones y vínculos a contenido de ejemplo de nuestra MRTK de Unity.</span><span class="sxs-lookup"><span data-stu-id="dc776-142">Detailed information for using all available inputs seamlessly together in each interaction model is on the pages that follow, as well as illustrations and links to sample content from our Unity MRTK.</span></span>


## <a name="choose-an-interaction-model-for-your-customer"></a><span data-ttu-id="dc776-143">Elija un modelo de interacción de cara al cliente</span><span class="sxs-lookup"><span data-stu-id="dc776-143">Choose an interaction model for your customer</span></span>


<span data-ttu-id="dc776-144">Probablemente, los desarrolladores y creadores de también ya tienen algunas ideas en mente de los tipos de la experiencia de interacción que quieren que sus usuarios a tener.</span><span class="sxs-lookup"><span data-stu-id="dc776-144">Most likely, developers and creators also already have some ideas in mind of the kinds of interaction experience they want their users to have.</span></span>
<span data-ttu-id="dc776-145">Para fomentar un enfoque centrado en el cliente para diseñar, se recomienda seguir las instrucciones siguientes para seleccionar el modelo de interacción que está optimizado para su cliente.</span><span class="sxs-lookup"><span data-stu-id="dc776-145">To encourage a customer-focused approach to design, we recommend following the guidance below to select the interaction model that's optimized for your customer.</span></span>

### <a name="why-follow-this-guidance"></a><span data-ttu-id="dc776-146">¿Por qué seguir esta guía?</span><span class="sxs-lookup"><span data-stu-id="dc776-146">Why follow this guidance?</span></span>

* <span data-ttu-id="dc776-147">Los modelos de interacción se prueban para objetiva y subjetivos criterios como el esfuerzo físico y cognitiva, intuitiveness y learnability.</span><span class="sxs-lookup"><span data-stu-id="dc776-147">Our interaction models are tested for objective and subjective criteria such as physical and cognitive effort, intuitiveness, and learnability.</span></span> 
* <span data-ttu-id="dc776-148">Dado que es diferente de interacción, visual y prestaciones de audio y el comportamiento de los objetos también pueden diferir entre los modelos de interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-148">Because interaction differs, visual and audio affordances and object behavior may also differ between the interaction models.</span></span>  
* <span data-ttu-id="dc776-149">Combinar elementos de varios modelos de interacción, crea el riesgo de factibilidad competencia, como los rayos mano simultáneos y un cursor head mirada, que sobrecargar y confundir a los usuarios.</span><span class="sxs-lookup"><span data-stu-id="dc776-149">Combining parts of multiple interaction models together creates the risk of competing affordances, such as simultaneous hand rays and a head-gaze cursor, which overwhelm and confuse users.</span></span>

<span data-ttu-id="dc776-150">Estos son algunos ejemplos de cómo se optimizan factibilidad y comportamientos para cada modelo de interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-150">Here are some examples of how affordances and behaviors are optimized for each interaction model.</span></span>  <span data-ttu-id="dc776-151">Con frecuencia vemos nuevos usuarios como preguntas similares, como "¿cómo se puede saber el sistema funciona, ¿cómo puedo saber lo que puedo hacer, y cómo saber si entiende lo que hice?"</span><span class="sxs-lookup"><span data-stu-id="dc776-151">We often see new users as similar questions, such as "how do I know the system is working, how do I know what I can do, and how do I know if it understood what I just did?"</span></span>

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="dc776-152"><strong>Modelo</strong></span><span class="sxs-lookup"><span data-stu-id="dc776-152"><strong>Model</strong></span></span></td>
        <td><span data-ttu-id="dc776-153"><strong>¿Cómo puede saber funciona?</strong></span><span class="sxs-lookup"><span data-stu-id="dc776-153"><strong>How do I know it's working?</strong></span></span></td>
        <td><span data-ttu-id="dc776-154"><strong>¿Cómo se puede saber qué puedo hacer?</strong></span><span class="sxs-lookup"><span data-stu-id="dc776-154"><strong>How do I know what I can do?</strong></span></span></td>
        <td><span data-ttu-id="dc776-155"><strong>¿Cómo se puede saber lo que hice?</strong></span><span class="sxs-lookup"><span data-stu-id="dc776-155"><strong>How do I know what I just did?</strong></span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="dc776-156"><a href="hands-and-tools.md">Las manos y herramientas</a></span><span class="sxs-lookup"><span data-stu-id="dc776-156"><a href="hands-and-tools.md">Hands and tools</a></span></span></td>
        <td><span data-ttu-id="dc776-157">Veo una mano de malla, se ve una prestación de la yema del dedo o mano / rayos de controlador.</span><span class="sxs-lookup"><span data-stu-id="dc776-157">I see a hand mesh, I see a fingertip affordance or hand/ controller rays.</span></span></td>
        <td><span data-ttu-id="dc776-158">Veo un rectángulo de selección aparecen cuando mi mano está cerca o identificadores grabbable.</span><span class="sxs-lookup"><span data-stu-id="dc776-158">I see grabbable handles or a bounding box appear when my hand is near.</span></span></td>
        <td><span data-ttu-id="dc776-159">Puedo oír tonos audibles y ver animaciones en la captura y liberación.</span><span class="sxs-lookup"><span data-stu-id="dc776-159">I hear audible tones and see animations on grab and release.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="dc776-160"><a href="gaze-and-commit.md">Mirada-cabeza y confirmación</a></span><span class="sxs-lookup"><span data-stu-id="dc776-160"><a href="gaze-and-commit.md">Head-gaze and commit</a></span></span></td>
        <td><span data-ttu-id="dc776-161">Veo un cursor en el centro de mi campo de visión.</span><span class="sxs-lookup"><span data-stu-id="dc776-161">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="dc776-162">El cursor head mirada cambia el estado cuando se encuentre sobre determinados objetos.</span><span class="sxs-lookup"><span data-stu-id="dc776-162">The head-gaze cursor changes state when over certain objects.</span></span></td>
        <td><span data-ttu-id="dc776-163">Puedo ver o escuchar visuales y audibles confirmaciones al realizar una acción.</span><span class="sxs-lookup"><span data-stu-id="dc776-163">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>   
    <tr>
        <td><span data-ttu-id="dc776-164"><a href="hands-free.md">Manos libres (Head mirada y permanencia)</a></span><span class="sxs-lookup"><span data-stu-id="dc776-164"><a href="hands-free.md">Hands-free (Head-gaze and dwell)</a></span></span></td>
        <td><span data-ttu-id="dc776-165">Veo un cursor en el centro de mi campo de visión.</span><span class="sxs-lookup"><span data-stu-id="dc776-165">I see a cursor in the center of my field of view.</span></span></td>
        <td><span data-ttu-id="dc776-166">Veo un indicador de progreso cuando hincapié en un objeto interactuable.</span><span class="sxs-lookup"><span data-stu-id="dc776-166">I see a progress indicator when I dwell on an interactable object.</span></span></td>
        <td><span data-ttu-id="dc776-167">Puedo ver o escuchar visuales y audibles confirmaciones al realizar una acción.</span><span class="sxs-lookup"><span data-stu-id="dc776-167">I see/ hear visual and audible confirmations when I take action.</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="dc776-168"><a href="hands-free.md">Manos libres (comandos de voz)</a></span><span class="sxs-lookup"><span data-stu-id="dc776-168"><a href="hands-free.md">Hands-free (Voice commanding)</a></span></span></td>
        <td><span data-ttu-id="dc776-169">Veo un indicador de escuchando y las leyendas que muestran lo que escucha el sistema.</span><span class="sxs-lookup"><span data-stu-id="dc776-169">I see a listening indicator and captions that show what the system heard.</span></span></td>
        <td><span data-ttu-id="dc776-170">Recibo mensajes de voz y sugerencias.</span><span class="sxs-lookup"><span data-stu-id="dc776-170">I get voice prompts and hints.</span></span>  <span data-ttu-id="dc776-171">Cuando digo "¿Qué puedo decir?"</span><span class="sxs-lookup"><span data-stu-id="dc776-171">When I say "what can I say?"</span></span> <span data-ttu-id="dc776-172">Puedo ver comentarios.</span><span class="sxs-lookup"><span data-stu-id="dc776-172">I see feedback.</span></span></td>
        <td><span data-ttu-id="dc776-173">Puedo ver o escuchar visuales y audibles confirmaciones cuando asigne a un comando u obtener desambiguación UX cuando sea necesario.</span><span class="sxs-lookup"><span data-stu-id="dc776-173">I see/ hear visual and audible confirmations when I give a command, or get disambiguation UX when needed.</span></span></a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a><span data-ttu-id="dc776-174">A continuación se muestran las preguntas que hemos encontrado ayuda equipos seleccione un modelo de interacción:</span><span class="sxs-lookup"><span data-stu-id="dc776-174">Below are the questions that we've found help teams select an interaction model:</span></span>
 
1.  <span data-ttu-id="dc776-175">Q:  ¿Mis usuarios quieren tocar hologramas y realizar manipulaciones holográfica precisión?</span><span class="sxs-lookup"><span data-stu-id="dc776-175">Q:  Do my users want to touch holograms and perform precision holographic manipulations?</span></span><br><br>
<span data-ttu-id="dc776-176">R:  Si es así, consulte el modelo de interacción de las manos y herramientas para la manipulación con manos o los controladores de movimiento y destinatarios de la precisión.</span><span class="sxs-lookup"><span data-stu-id="dc776-176">A:  If so, check out the Hands and tools interaction model for precision targeting and manipulation with hands or motion controllers.</span></span>
 
2.  <span data-ttu-id="dc776-177">Q:  ¿Es necesario mantener sus manos libres para las tareas reales Mis usuarios?</span><span class="sxs-lookup"><span data-stu-id="dc776-177">Q:  Do my users need to keep their hands free, for real-world tasks?</span></span><br><br>
<span data-ttu-id="dc776-178">R:  Si es así, eche un vistazo en el modelo de interacción de manos libres, que proporciona una gran experiencia a través de las interacciones basadas en voz y mirada manos libres.</span><span class="sxs-lookup"><span data-stu-id="dc776-178">A:  If so, take a look at the Hands-free interaction model, which provides a great hands-free experience through gaze- and voice-based interactions.</span></span>
 
3.  <span data-ttu-id="dc776-179">Q:  ¿Mis usuarios tienen tiempo para obtener información sobre las interacciones para mi aplicación de realidad mixta, o necesitan las interacciones con la curva de aprendizaje más bajo posible?</span><span class="sxs-lookup"><span data-stu-id="dc776-179">Q:  Do my users have time to learn interactions for my mixed reality application, or do they need the interactions with the lowest learning curve possible?</span></span><br><br>
<span data-ttu-id="dc776-180">R:  Se recomienda el modelo de manos y las herramientas de la curva de aprendizaje más bajo e interacciones más intuitivas, siempre y cuando los usuarios pueden usar sus manos para la interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-180">A:  We recommend the Hands and Tools model for the lowest learning curve and most intuitive interactions, as long as users are able to use their hands for interaction.</span></span>
 
4.  <span data-ttu-id="dc776-181">Q:  ¿Mis usuarios utilizan los controladores de movimiento para señalar y manipulación?</span><span class="sxs-lookup"><span data-stu-id="dc776-181">Q:  Do my users use motion controllers for pointing and manipulation?</span></span><br><br>
<span data-ttu-id="dc776-182">R:  El modelo de las manos e incluye todas las instrucciones para una gran experiencia con los controladores de movimiento.</span><span class="sxs-lookup"><span data-stu-id="dc776-182">A:  The Hands and tools model includes all guidance for a great experience with motion controllers.</span></span>
 
5.  <span data-ttu-id="dc776-183">Q:  ¿Mis usuarios usar un controlador de accesibilidad o un controlador de Bluetooth comunes, como un clicker?</span><span class="sxs-lookup"><span data-stu-id="dc776-183">Q:  Do my users use an accessibility controller or a common Bluetooth controller, such as a clicker?</span></span><br><br>
<span data-ttu-id="dc776-184">R:  Se recomienda el modelo mirada de encabezado y confirmación para todos los controladores no realiza un seguimiento.</span><span class="sxs-lookup"><span data-stu-id="dc776-184">A:  We recommend the Head-gaze and Commit model for all non-tracked controllers.</span></span>  <span data-ttu-id="dc776-185">Se ha diseñado para permitir que un usuario recorrer una experiencia completa con un simple mecánico "de destino y de confirmación".</span><span class="sxs-lookup"><span data-stu-id="dc776-185">It's designed to allow a user to traverse an entire experience with a simple "target and commit" mechanic.</span></span> 
 
6.  <span data-ttu-id="dc776-186">Q: ¿Mis usuarios solo de progreso a través de una experiencia haciendo clic en"a través de" (por ejemplo, en un entorno como presentación de diapositivas 3d), en lugar de navegar por los diseños densos de los controles de interfaz de usuario?</span><span class="sxs-lookup"><span data-stu-id="dc776-186">Q: Do my users only progress through an experience by "clicking through" (for example in a 3d slideshow-like environment), as opposed to navigating dense layouts of UI controls?</span></span><br><br>
<span data-ttu-id="dc776-187">R:  Si los usuarios no necesitan controlar una gran cantidad de interfaz de usuario, Head mirada y confirmación ofrece una opción fácil de aprender, donde los usuarios no tienen que preocuparse sobre cómo destinar.</span><span class="sxs-lookup"><span data-stu-id="dc776-187">A:  If users do not need to control a lot of UI, Head-gaze and commit offers a learnable option where users do not have to worry about targeting.</span></span> 
 
7.  <span data-ttu-id="dc776-188">Q:  ¿Mis usuarios usa ambos HoloLens (gen 1) y HoloLens 2 / envolventes de Windows (auriculares de realidad virtual)</span><span class="sxs-lookup"><span data-stu-id="dc776-188">Q:  Do my users use both HoloLens (1st gen) and HoloLens 2/ Windows Immersive (VR headsets)</span></span><br><br>
<span data-ttu-id="dc776-189">R:  Puesto que la mirada de encabezado y confirmación es el modelo de interacción para HoloLens (gen 1), se recomienda que creadores de admiten HoloLens (gen 1) use Head mirada y la confirmación de características o modos que pueden experimentar los usuarios en un HoloLens (gen 1) auriculares.</span><span class="sxs-lookup"><span data-stu-id="dc776-189">A:  Since Head-gaze and commit is the interaction model for HoloLens (1st gen), we recommend that creators who support HoloLens (1st gen) use Head-gaze and commit for any features or modes that users may experience on a HoloLens (1st gen) headset.</span></span>  <span data-ttu-id="dc776-190">Consulte la sección siguiente a continuación en *transición de modelos de interacción* para obtener más información acerca de cómo realizar una gran experiencia para varias generaciones de HoloLens.</span><span class="sxs-lookup"><span data-stu-id="dc776-190">Please see the next section below on *Transitioning interaction models* for details on making a great experience for multiple HoloLens generations.</span></span>
 
8.  <span data-ttu-id="dc776-191">Q: ¿Qué sucede a los usuarios que son generalmente móviles (que abarcan un amplio espacio o mover entre espacios), frente a los usuarios que tienden a funcionar en un único espacio?</span><span class="sxs-lookup"><span data-stu-id="dc776-191">Q: What about for users who are generally mobile (covering a large space or moving between spaces), versus users who tend to work in a single space?</span></span><br><br>
<span data-ttu-id="dc776-192">R:  Cualquiera de los modelos de interacción funcionará para estos usuarios.</span><span class="sxs-lookup"><span data-stu-id="dc776-192">A:  Any of the interaction models will work for these users.</span></span>  

> [!NOTE]
> <span data-ttu-id="dc776-193">Obtener información más específica de diseño de aplicaciones [próximamente](index.md#news-and-notes).</span><span class="sxs-lookup"><span data-stu-id="dc776-193">More guidance specific to app design [coming soon](index.md#news-and-notes).</span></span>


## <a name="transition-interaction-models"></a><span data-ttu-id="dc776-194">Modelos de interacción de transición</span><span class="sxs-lookup"><span data-stu-id="dc776-194">Transition interaction models</span></span>
<span data-ttu-id="dc776-195">También hay casos donde los casos de uso pueden requerir que el uso de más de un modelo de interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-195">There are also cases where your use cases may require that utilizing more than one interaction model.</span></span>  <span data-ttu-id="dc776-196">Por ejemplo, "flujo de creación" de la aplicación utiliza el modelo de interacción de las manos y las herramientas, pero desea emplear un modo manos libres para los técnicos de campo.</span><span class="sxs-lookup"><span data-stu-id="dc776-196">For example, your app's "creation flow" utilizes the Hands and tools interaction model, but you want to employ a Hands-free mode for field technicians.</span></span>  

<span data-ttu-id="dc776-197">Si su experiencia requieren varios modelos de interacción, hemos visto que muchos usuarios finales pueden encontrar dificultades para realizar la transición de un modelo a otro, especialmente los usuarios finales que está familiarizados con el Sr.</span><span class="sxs-lookup"><span data-stu-id="dc776-197">If your experience does require multiple interaction models, we've found that many end users may encounter difficulty transitioning from one model to another -- especially end users who are new to MR.</span></span>

> [!Note]
> <span data-ttu-id="dc776-198">Para ayudar a los diseñadores de guía y los desarrolladores a través de las opciones que pueden ser difíciles en MR, estamos trabajando en obtener más instrucciones para usar varios modelos de interacción.</span><span class="sxs-lookup"><span data-stu-id="dc776-198">To help guide designers and developers through choices that can be difficult in MR, we're working on more guidance for using multiple interaction models.</span></span>
 

## <a name="see-also"></a><span data-ttu-id="dc776-199">Vea también</span><span class="sxs-lookup"><span data-stu-id="dc776-199">See also</span></span>
* [<span data-ttu-id="dc776-200">Mirada-cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="dc776-200">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="dc776-201">Control con la cabeza y permanencia</span><span class="sxs-lookup"><span data-stu-id="dc776-201">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="dc776-202">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="dc776-202">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="dc776-203">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="dc776-203">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="dc776-204">Gestos</span><span class="sxs-lookup"><span data-stu-id="dc776-204">Gestures</span></span>](gestures.md)
* [<span data-ttu-id="dc776-205">Comandos de voz</span><span class="sxs-lookup"><span data-stu-id="dc776-205">Voice commanding</span></span>](voice-design.md)
* [<span data-ttu-id="dc776-206">Controladores de movimiento</span><span class="sxs-lookup"><span data-stu-id="dc776-206">Motion controllers</span></span>](motion-controllers.md)
* [<span data-ttu-id="dc776-207">Diseño de sonido espacial</span><span class="sxs-lookup"><span data-stu-id="dc776-207">Spatial sound design</span></span>](spatial-sound-design.md)
* [<span data-ttu-id="dc776-208">Diseño de asignaciones espaciales</span><span class="sxs-lookup"><span data-stu-id="dc776-208">Spatial mapping design</span></span>](spatial-mapping-design.md)
* [<span data-ttu-id="dc776-209">Comodidad</span><span class="sxs-lookup"><span data-stu-id="dc776-209">Comfort</span></span>](comfort.md)

