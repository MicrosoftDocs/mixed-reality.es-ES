---
title: Cámara localizable
description: Información general acerca de la cámara con orientación frontal de HoloLens.
author: wguyman
ms.author: wguyman
ms.date: 02/24/2019
ms.topic: article
keywords: cámara, hololens, cámara de color, frontal accesibles desde
ms.openlocfilehash: ffcd6faf15dd8556db393237d468a3cdf60e4bdb
ms.sourcegitcommit: 384b0087899cd835a3a965f75c6f6c607c9edd1b
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 04/12/2019
ms.locfileid: "59605458"
---
# <a name="locatable-camera"></a><span data-ttu-id="c4027-104">Cámara localizable</span><span class="sxs-lookup"><span data-stu-id="c4027-104">Locatable camera</span></span>

<span data-ttu-id="c4027-105">HoloLens incluyen una cámara de mundo orientado montada en la parte frontal del dispositivo que permite que las aplicaciones ver lo que ve el usuario.</span><span class="sxs-lookup"><span data-stu-id="c4027-105">HoloLens includes a world-facing camera mounted on the front of the device which enables apps to see what the user sees.</span></span> <span data-ttu-id="c4027-106">Los desarrolladores tienen acceso y control de la cámara, tal como harían para las cámaras de color en los smartphones, equipos portátiles o equipos de escritorio.</span><span class="sxs-lookup"><span data-stu-id="c4027-106">Developers have access to and control of the camera just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="c4027-107">El mismos windows universales [záznam média](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) y foundation de windows media API que funcionan en el escritorio y móviles funcionan en HoloLens.</span><span class="sxs-lookup"><span data-stu-id="c4027-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="c4027-108">Unity [también se ha ajustado estas ventanas API](locatable-camera-in-unity.md) abstraer uso simple de la cámara en HoloLens para tareas como teniendo regulares fotos y vídeos (con o sin hologramas) y buscar la posición de la cámara en y perspectiva en el escena.</span><span class="sxs-lookup"><span data-stu-id="c4027-108">Unity [has also wrapped these windows APIs](locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="c4027-109">Información de la cámara de dispositivo</span><span class="sxs-lookup"><span data-stu-id="c4027-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="c4027-110">HoloLens (primera generación)</span><span class="sxs-lookup"><span data-stu-id="c4027-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="c4027-111">Cámara de fotografías y vídeo (PV) enfoque fijo, con el balance de blanco automático, exposición automática y canalización de procesamiento de imagen completa</span><span class="sxs-lookup"><span data-stu-id="c4027-111">Fixed focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="c4027-112">LED de privacidad en blanco accesible desde el mundo se iluminará cada vez que la cámara está activa</span><span class="sxs-lookup"><span data-stu-id="c4027-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="c4027-113">La cámara admite los siguientes modos (todos los modos son relación de aspecto 16:9) en fps 5, 15, 20, 24 y 30:</span><span class="sxs-lookup"><span data-stu-id="c4027-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="c4027-114">Vídeo</span><span class="sxs-lookup"><span data-stu-id="c4027-114">Video</span></span>  |  <span data-ttu-id="c4027-115">Vista previa</span><span class="sxs-lookup"><span data-stu-id="c4027-115">Preview</span></span>  |  <span data-ttu-id="c4027-116">Todavía</span><span class="sxs-lookup"><span data-stu-id="c4027-116">Still</span></span>  |  <span data-ttu-id="c4027-117">Campo horizontal de visión (FOV-H)</span><span class="sxs-lookup"><span data-stu-id="c4027-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="c4027-118">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="c4027-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="c4027-119">1280x720</span><span class="sxs-lookup"><span data-stu-id="c4027-119">1280x720</span></span> |  <span data-ttu-id="c4027-120">1280x720</span><span class="sxs-lookup"><span data-stu-id="c4027-120">1280x720</span></span> |  <span data-ttu-id="c4027-121">1280x720</span><span class="sxs-lookup"><span data-stu-id="c4027-121">1280x720</span></span> |  <span data-ttu-id="c4027-122">45deg</span><span class="sxs-lookup"><span data-stu-id="c4027-122">45deg</span></span>  |  <span data-ttu-id="c4027-123">(modo predeterminado con estabilización de vídeo)</span><span class="sxs-lookup"><span data-stu-id="c4027-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="c4027-124">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-124">N/A</span></span> |  <span data-ttu-id="c4027-125">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-125">N/A</span></span> |  <span data-ttu-id="c4027-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="c4027-126">2048x1152</span></span> |  <span data-ttu-id="c4027-127">67deg</span><span class="sxs-lookup"><span data-stu-id="c4027-127">67deg</span></span> |  <span data-ttu-id="c4027-128">Imagen fija de mayor resolución</span><span class="sxs-lookup"><span data-stu-id="c4027-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="c4027-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="c4027-129">1408x792</span></span> |  <span data-ttu-id="c4027-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="c4027-130">1408x792</span></span> |  <span data-ttu-id="c4027-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="c4027-131">1408x792</span></span> |  <span data-ttu-id="c4027-132">48deg</span><span class="sxs-lookup"><span data-stu-id="c4027-132">48deg</span></span> |  <span data-ttu-id="c4027-133">Resolución de sobrebarrido (relleno) antes de estabilización de vídeo</span><span class="sxs-lookup"><span data-stu-id="c4027-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="c4027-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="c4027-134">1344x756</span></span> |  <span data-ttu-id="c4027-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="c4027-135">1344x756</span></span> |  <span data-ttu-id="c4027-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="c4027-136">1344x756</span></span> |  <span data-ttu-id="c4027-137">67deg</span><span class="sxs-lookup"><span data-stu-id="c4027-137">67deg</span></span> |  <span data-ttu-id="c4027-138">Modo de vídeo grande FOV con sobrebarrido</span><span class="sxs-lookup"><span data-stu-id="c4027-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="c4027-139">896x504</span><span class="sxs-lookup"><span data-stu-id="c4027-139">896x504</span></span> |  <span data-ttu-id="c4027-140">896x504</span><span class="sxs-lookup"><span data-stu-id="c4027-140">896x504</span></span> |  <span data-ttu-id="c4027-141">896x504</span><span class="sxs-lookup"><span data-stu-id="c4027-141">896x504</span></span> |  <span data-ttu-id="c4027-142">48deg</span><span class="sxs-lookup"><span data-stu-id="c4027-142">48deg</span></span> |  <span data-ttu-id="c4027-143">Baja potencia y tareas de procesamiento de modo de baja resolución de imagen</span><span class="sxs-lookup"><span data-stu-id="c4027-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="c4027-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="c4027-144">HoloLens 2</span></span>

* <span data-ttu-id="c4027-145">Cámara de fotografías y vídeo (PV) enfoque automático, con el balance de blanco automático, exposición automática y canalización de procesamiento de imagen completa</span><span class="sxs-lookup"><span data-stu-id="c4027-145">Auto-focus photo/video (PV) camera, with auto white balance, auto exposure, and full image processing pipe</span></span>
* <span data-ttu-id="c4027-146">LED de privacidad en blanco accesible desde el mundo se iluminará cada vez que la cámara está activa</span><span class="sxs-lookup"><span data-stu-id="c4027-146">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="c4027-147">La cámara admite los siguientes modos (todos los modos de vídeo son relación de aspecto 16:9):</span><span class="sxs-lookup"><span data-stu-id="c4027-147">The camera supports the following modes (all video modes are 16:9 aspect ratio):</span></span>

  >[!NOTE]
  ><span data-ttu-id="c4027-148">Estos modos están sujetos a cambios antes de la disponibilidad general de HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="c4027-148">These modes are subject to change prior to HoloLens 2 general availability.</span></span>

  |  <span data-ttu-id="c4027-149">Vídeo</span><span class="sxs-lookup"><span data-stu-id="c4027-149">Video</span></span>  |  <span data-ttu-id="c4027-150">Vista previa</span><span class="sxs-lookup"><span data-stu-id="c4027-150">Preview</span></span>  |  <span data-ttu-id="c4027-151">Todavía</span><span class="sxs-lookup"><span data-stu-id="c4027-151">Still</span></span>  |  <span data-ttu-id="c4027-152">Velocidades de fotogramas</span><span class="sxs-lookup"><span data-stu-id="c4027-152">Frame rates</span></span>  |  <span data-ttu-id="c4027-153">Campo horizontal de visión (FOV-H)</span><span class="sxs-lookup"><span data-stu-id="c4027-153">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="c4027-154">Uso sugerido</span><span class="sxs-lookup"><span data-stu-id="c4027-154">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|----------|
  |  <span data-ttu-id="c4027-155">1920x1080</span><span class="sxs-lookup"><span data-stu-id="c4027-155">1920x1080</span></span> |  <span data-ttu-id="c4027-156">1920x1080</span><span class="sxs-lookup"><span data-stu-id="c4027-156">1920x1080</span></span> |  <span data-ttu-id="c4027-157">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-157">N/A</span></span> |  <span data-ttu-id="c4027-158">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="c4027-158">30, 15 fps</span></span>  |  <span data-ttu-id="c4027-159">54deg</span><span class="sxs-lookup"><span data-stu-id="c4027-159">54deg</span></span>  |  <span data-ttu-id="c4027-160">(modo predeterminado con estabilización de vídeo)</span><span class="sxs-lookup"><span data-stu-id="c4027-160">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="c4027-161">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-161">N/A</span></span> |  <span data-ttu-id="c4027-162">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-162">N/A</span></span> |  <span data-ttu-id="c4027-163">3904X2196</span><span class="sxs-lookup"><span data-stu-id="c4027-163">3904X2196</span></span> |  <span data-ttu-id="c4027-164">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-164">N/A</span></span>  |  <span data-ttu-id="c4027-165">64deg</span><span class="sxs-lookup"><span data-stu-id="c4027-165">64deg</span></span> |  <span data-ttu-id="c4027-166">Imagen fija de mayor resolución</span><span class="sxs-lookup"><span data-stu-id="c4027-166">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="c4027-167">2272x1278</span><span class="sxs-lookup"><span data-stu-id="c4027-167">2272x1278</span></span> |  <span data-ttu-id="c4027-168">2272x1278</span><span class="sxs-lookup"><span data-stu-id="c4027-168">2272x1278</span></span> |  <span data-ttu-id="c4027-169">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-169">N/A</span></span> |  <span data-ttu-id="c4027-170">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="c4027-170">30, 15 fps</span></span>  |  <span data-ttu-id="c4027-171">64deg</span><span class="sxs-lookup"><span data-stu-id="c4027-171">64deg</span></span> |  <span data-ttu-id="c4027-172">Resolución de sobrebarrido (relleno) antes de estabilización de vídeo</span><span class="sxs-lookup"><span data-stu-id="c4027-172">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="c4027-173">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c4027-173">1952x1100</span></span> |  <span data-ttu-id="c4027-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c4027-174">1952x1100</span></span> |  <span data-ttu-id="c4027-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="c4027-175">1952x1100</span></span>  |  <span data-ttu-id="c4027-176">30, 15 fps</span><span class="sxs-lookup"><span data-stu-id="c4027-176">30, 15 fps</span></span>  |  <span data-ttu-id="c4027-177">64deg</span><span class="sxs-lookup"><span data-stu-id="c4027-177">64deg</span></span> |  <span data-ttu-id="c4027-178">Transmisión de alta calidad</span><span class="sxs-lookup"><span data-stu-id="c4027-178">High-quality streaming</span></span> | 
  |  <span data-ttu-id="c4027-179">1280x720</span><span class="sxs-lookup"><span data-stu-id="c4027-179">1280x720</span></span> |  <span data-ttu-id="c4027-180">1280x720</span><span class="sxs-lookup"><span data-stu-id="c4027-180">1280x720</span></span> |  <span data-ttu-id="c4027-181">N/D</span><span class="sxs-lookup"><span data-stu-id="c4027-181">N/A</span></span> |  <span data-ttu-id="c4027-182">30, 15, fps 5</span><span class="sxs-lookup"><span data-stu-id="c4027-182">30, 15, 5 fps</span></span>  |  <span data-ttu-id="c4027-183">64deg</span><span class="sxs-lookup"><span data-stu-id="c4027-183">64deg</span></span> |  <span data-ttu-id="c4027-184">Modo de baja energía o resolución de transmisión por secuencias y las tareas de procesamiento de imágenes</span><span class="sxs-lookup"><span data-stu-id="c4027-184">Low power/resolution mode for streaming and image processing tasks</span></span> | 

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="c4027-185">Localización de la cámara del dispositivo en el mundo</span><span class="sxs-lookup"><span data-stu-id="c4027-185">Locating the Device Camera in the World</span></span>

<span data-ttu-id="c4027-186">Cuando HoloLens toma fotografías y vídeos, los fotogramas capturados incluyen la ubicación de la cámara en el mundo, así como la proyección en perspectiva de la cámara.</span><span class="sxs-lookup"><span data-stu-id="c4027-186">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the perspective projection of the camera.</span></span> <span data-ttu-id="c4027-187">Esto permite que las aplicaciones para razonar sobre la posición de la cámara en el mundo real para escenarios de creación de imágenes aumentados.</span><span class="sxs-lookup"><span data-stu-id="c4027-187">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="c4027-188">Los desarrolladores de forma creativa pueden implementar sus propios escenarios mediante un procesamiento de imágenes favorito o bibliotecas de visión artificial personalizado.</span><span class="sxs-lookup"><span data-stu-id="c4027-188">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="c4027-189">"Cámara" en otra parte de la documentación de HoloLens puede hacer referencia a la "juego cámara virtual" (frustum de la aplicación se representa en).</span><span class="sxs-lookup"><span data-stu-id="c4027-189">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="c4027-190">A menos que se indica lo contrario, "cámara" en esta página se refiere a la cámara de color RGB reales.</span><span class="sxs-lookup"><span data-stu-id="c4027-190">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

<span data-ttu-id="c4027-191">Los detalles sobre esta cubren la página [Media Foundation atributos](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), sin embargo, hay también las API para extraer la cámara utilizando las funciones intrínsecas [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span><span class="sxs-lookup"><span data-stu-id="c4027-191">The details on this page cover [Media Foundation Attributes](https://msdn.microsoft.com/library/windows/desktop/mt740395(v=vs.85).aspx), however there are also APIs to pull camera intrinsics using [WinRT APIs](https://msdn.microsoft.com/library/windows/apps/windows.media.devices.core.cameraintrinsics).</span></span>  

### <a name="images-with-coordinate-systems"></a><span data-ttu-id="c4027-192">Imágenes con sistemas de coordenadas</span><span class="sxs-lookup"><span data-stu-id="c4027-192">Images with Coordinate Systems</span></span>

<span data-ttu-id="c4027-193">Cada marco de imagen (si foto o vídeo) incluye un sistema de coordenadas, así como dos transformaciones importantes.</span><span class="sxs-lookup"><span data-stu-id="c4027-193">Each image frame (whether photo or video) includes a coordinate system, as well as two important transforms.</span></span> <span data-ttu-id="c4027-194">La "vista" transformar mapas desde el sistema de coordenadas proporcionado a la cámara y el "proyección" se asigna desde la cámara a píxeles de la imagen.</span><span class="sxs-lookup"><span data-stu-id="c4027-194">The "view" transform maps from the provided coordinate system to the camera, and the "projection" maps from the camera to pixels in the image.</span></span> <span data-ttu-id="c4027-195">Juntas, estas transformaciones definen para cada píxel un rayo en el espacio 3D que representa la ruta de acceso realizada por el photons que generó el píxel.</span><span class="sxs-lookup"><span data-stu-id="c4027-195">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="c4027-196">Estos rayos pueden estar relacionados con otro contenido en la aplicación mediante la obtención de la transformación de sistema de coordenadas del marco a otro sistema de coordenadas (por ejemplo, desde un [marco estático de referencia](coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="c4027-196">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="c4027-197">En resumen, cada marco de imagen ofrece lo siguiente:</span><span class="sxs-lookup"><span data-stu-id="c4027-197">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="c4027-198">Datos de píxeles (en formato RGB, NV12, JPEG, etc.)</span><span class="sxs-lookup"><span data-stu-id="c4027-198">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="c4027-199">3 fragmentos de metadatos (almacenados como [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) que hacen cada fotograma "localizable":</span><span class="sxs-lookup"><span data-stu-id="c4027-199">3 pieces of metadata (stored as [IMFAttributes](https://msdn.microsoft.com/library/windows/desktop/ms704598(v=vs.85).aspx)) that make each frame "locatable":</span></span>

|  <span data-ttu-id="c4027-200">Nombre del atributo</span><span class="sxs-lookup"><span data-stu-id="c4027-200">Attribute name</span></span>  |  <span data-ttu-id="c4027-201">Tipo</span><span class="sxs-lookup"><span data-stu-id="c4027-201">Type</span></span>  |  <span data-ttu-id="c4027-202">GUID</span><span class="sxs-lookup"><span data-stu-id="c4027-202">GUID</span></span>  |  <span data-ttu-id="c4027-203">Descripción</span><span class="sxs-lookup"><span data-stu-id="c4027-203">Description</span></span> | 
|----------|----------|----------|----------|
|  <span data-ttu-id="c4027-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span><span class="sxs-lookup"><span data-stu-id="c4027-204">MFSampleExtension_Spatial_CameraCoordinateSystem</span></span>  |  <span data-ttu-id="c4027-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span><span class="sxs-lookup"><span data-stu-id="c4027-205">IUnknown ([SpatialCoordinateSystem](https://msdn.microsoft.com/library/windows/apps/windows.perception.spatial.spatialcoordinatesystem.aspx))</span></span>  |  <span data-ttu-id="c4027-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span><span class="sxs-lookup"><span data-stu-id="c4027-206">{9D13C82F-2199-4E67-91CD-D1A4181F2534}</span></span>  |  <span data-ttu-id="c4027-207">Almacena el [del sistema de coordenadas](coordinate-systems-in-directx.md) del fotograma capturado</span><span class="sxs-lookup"><span data-stu-id="c4027-207">Stores the [coordinate system](coordinate-systems-in-directx.md) of the captured frame</span></span> | 
|  <span data-ttu-id="c4027-208">MFSampleExtension_Spatial_CameraViewTransform</span><span class="sxs-lookup"><span data-stu-id="c4027-208">MFSampleExtension_Spatial_CameraViewTransform</span></span>  |  <span data-ttu-id="c4027-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="c4027-209">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="c4027-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span><span class="sxs-lookup"><span data-stu-id="c4027-210">{4E251FA4-830F-4770-859A-4B8D99AA809B}</span></span>  |  <span data-ttu-id="c4027-211">Almacena extrínsecos transformación de la cámara en el sistema de coordenadas</span><span class="sxs-lookup"><span data-stu-id="c4027-211">Stores the camera's extrinsic transform in the coordinate system</span></span> | 
|  <span data-ttu-id="c4027-212">MFSampleExtension_Spatial_CameraProjectionTransform</span><span class="sxs-lookup"><span data-stu-id="c4027-212">MFSampleExtension_Spatial_CameraProjectionTransform</span></span>  |  <span data-ttu-id="c4027-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span><span class="sxs-lookup"><span data-stu-id="c4027-213">Blob ([Matrix4x4](https://msdn.microsoft.com/library/windows/apps/windows.foundation.numerics.matrix4x4.aspx))</span></span>  |  <span data-ttu-id="c4027-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span><span class="sxs-lookup"><span data-stu-id="c4027-214">{47F9FCB5-2A02-4F26-A477-792FDF95886A}</span></span>  |  <span data-ttu-id="c4027-215">Almacena la transformación de proyección de la cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-215">Stores the camera's projection transform</span></span> | 

<span data-ttu-id="c4027-216">La transformación de proyección representa las propiedades intrínsecas (longitud focal, centro de proyección, sesgar) de la lente asignado en un plano de la imagen que se extiende desde -1 a + 1 en el eje X e Y.</span><span class="sxs-lookup"><span data-stu-id="c4027-216">The projection transform represents the intrinsic properties (focal length, center of projection, skew) of the lens mapped onto an image plane that extends from -1 to +1 in both the X and Y axis.</span></span>

```
Matrix4x4 format          Terms
   m11 m12 m13 m14      fx    0   0   0
   m21 m22 m23 m24     skew  fy   0   0
   m31 m32 m33 m34      cx   cy   A  -1
   m41 m42 m43 m44       0    0   B   0
```

<span data-ttu-id="c4027-217">Las distintas aplicaciones tendrán distintos sistemas de coordenadas.</span><span class="sxs-lookup"><span data-stu-id="c4027-217">Different applications will have different coordinate systems.</span></span> <span data-ttu-id="c4027-218">Presentamos una visión general del flujo para localizar un píxel de la cámara para una sola aplicación:</span><span class="sxs-lookup"><span data-stu-id="c4027-218">Here's an overview of the flow to locate a camera pixel for a single application:</span></span>

![Transformaciones aplicadas a los sistemas de coordenadas de la cámara](images/pvcameratransform5-500px.png)

### <a name="camera-to-application-specified-coordinate-system"></a><span data-ttu-id="c4027-220">Cámara al sistema de coordenadas especificado por la aplicación</span><span class="sxs-lookup"><span data-stu-id="c4027-220">Camera to Application-specified Coordinate System</span></span>

<span data-ttu-id="c4027-221">Para ir desde el 'CameraView' y 'CameraCoordinateSystem' al aplicación o sistema de coordenadas, necesitará lo siguiente:</span><span class="sxs-lookup"><span data-stu-id="c4027-221">To go from the 'CameraView' and 'CameraCoordinateSystem' to your application/world coordinate system, you'll need the following:</span></span>

<span data-ttu-id="c4027-222">[Cámara localizable en Unity](locatable-camera-in-unity.md): Clase PhotoCaptureFrame proporciona automáticamente CameraToWorldMatrix (por lo que no es necesario preocuparse por las transformaciones CameraCoordinateSystem).</span><span class="sxs-lookup"><span data-stu-id="c4027-222">[Locatable camera in Unity](locatable-camera-in-unity.md): CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class(so you don't need to worry about the CameraCoordinateSystem transforms).</span></span>

<span data-ttu-id="c4027-223">[Cámara localizable en DirectX](locatable-camera-in-directx.md): Muestra la manera bastante sencilla para consultar la transformación entre el sistema de coordenadas de la cámara y coordinate system(s) de su propia aplicación.</span><span class="sxs-lookup"><span data-stu-id="c4027-223">[Locatable camera in DirectX](locatable-camera-in-directx.md): Shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate system(s).</span></span>

### <a name="application-specified-coordinate-system-to-pixel-coordinates"></a><span data-ttu-id="c4027-224">Sistema de coordenadas especificado por la aplicación en coordenadas de píxel</span><span class="sxs-lookup"><span data-stu-id="c4027-224">Application-specified Coordinate System to Pixel Coordinates</span></span>

<span data-ttu-id="c4027-225">Supongamos que desea buscar o dibujar en una ubicación específica de 3d en una imagen de la cámara:</span><span class="sxs-lookup"><span data-stu-id="c4027-225">Let's say you wanted to find or draw at a specific 3d location on a camera image:</span></span>

<span data-ttu-id="c4027-226">Las transformaciones de vista y proyección, mientras ambas matrices de 4 x 4, deben utilizarse de forma ligeramente diferente.</span><span class="sxs-lookup"><span data-stu-id="c4027-226">The view and projection transforms, while both 4x4 matrices, need to be utilized slightly differently.</span></span> <span data-ttu-id="c4027-227">Es decir, después de realizar la proyección, uno 'normalizarán por w', este paso adicional en la proyección simula cómo varias ubicaciones diferentes de 3d pueden acabar como la misma ubicación 2d en una pantalla (es decir, algo a lo largo de un radio determinado se mostrará en el mismo píxel).</span><span class="sxs-lookup"><span data-stu-id="c4027-227">Namely after performing the Projection, one would 'normalize by w', this extra step in the projection simulates how multiple different 3d locations can end up as the same 2d location on a screen (i.e. anything along a certain ray will show up on the same pixel).</span></span> <span data-ttu-id="c4027-228">Por lo que la clave de puntos (en el código del sombreador):</span><span class="sxs-lookup"><span data-stu-id="c4027-228">So key points (in shader code):</span></span>

```
// Usual 3d math:
 float4x4 WorldToCamera = inverse( CameraToWorld );
 float4 CameraSpacePos = mul( WorldToCamera, float4( WorldSpacePos.xyz, 1 ) ); // use 1 as the W component
 // Projection math:
 float4 ImagePosUnnormalized = mul( CameraProjection, float4( CameraSpacePos.xyz, 1 ) ); // use 1 as the W component
 float2 ImagePosProjected = ImagePosUnnormalized.xy / ImagePosUnnormalized.w; // normalize by W, gives -1 to 1 space
 float2 ImagePosZeroToOne = ( ImagePosProjected * 0.5 ) + float2( 0.5, 0.5 ); // good for GPU textures
 int2 PixelPos = int2( ImagePosZeroToOne.x * ImageWidth, ( 1 - ImagePosZeroToOne.y ) * ImageHeight ); // good for CPU textures
```

### <a name="pixel-to-application-specified-coordinate-system"></a><span data-ttu-id="c4027-229">Píxeles al sistema de coordenadas especificado por la aplicación</span><span class="sxs-lookup"><span data-stu-id="c4027-229">Pixel to Application-specified Coordinate System</span></span>

<span data-ttu-id="c4027-230">Ir de píxeles a coordenadas universales es un poco más complicado:</span><span class="sxs-lookup"><span data-stu-id="c4027-230">Going from pixel to world coordinates is a little trickier:</span></span>

```
float2 ImagePosZeroToOne = float2( PixelPos.x / ImageWidth, 1.0 - (PixelPos.y / ImageHeight ) );
 float2 ImagePosProjected = ( ( ImagePosZeroToOne * 2.0 ) - float2(1,1) ); // -1 to 1 space
 float3 CameraSpacePos = UnProjectVector( Projection, float3( ImagePosProjected, 1) );
 float3 WorldSpaceRayPoint1 = mul( CameraToWorld, float4(0,0,0,1) ); // camera location in world space
 float3 WorldSpaceRayPoint2 = mul( CameraToWorld, CameraSpacePos ); // ray point in world space
```

<span data-ttu-id="c4027-231">Donde definimos UnProject como:</span><span class="sxs-lookup"><span data-stu-id="c4027-231">Where we define UnProject as:</span></span>

```
public static Vector3 UnProjectVector(Matrix4x4 proj, Vector3 to)
 {
   Vector3 from = new Vector3(0, 0, 0);
   var axsX = proj.GetRow(0);
   var axsY = proj.GetRow(1);
   var axsZ = proj.GetRow(2);
   from.z = to.z / axsZ.z;
   from.y = (to.y - (from.z * axsY.z)) / axsY.y;
   from.x = (to.x - (from.z * axsX.z)) / axsX.x;
   return from;
 }
```

<span data-ttu-id="c4027-232">Para buscar la ubicación del mundo real de un punto, será necesario: mundo dos rayos y encontrar su intersección o un tamaño conocido de los puntos.</span><span class="sxs-lookup"><span data-stu-id="c4027-232">To find the actual world location of a point, you'll need either: two world rays and find their intersection, or a known size of the points.</span></span>

### <a name="distortion-error"></a><span data-ttu-id="c4027-233">Error de distorsión</span><span class="sxs-lookup"><span data-stu-id="c4027-233">Distortion Error</span></span>

<span data-ttu-id="c4027-234">En HoloLens, el vídeo y sigue los flujos de imagen son distorsiones en la canalización de procesamiento de la imagen del sistema antes de que los marcos están disponibles para la aplicación (la secuencia de vista previa contiene los fotogramas distorsionados originales).</span><span class="sxs-lookup"><span data-stu-id="c4027-234">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="c4027-235">Ya está disponible solo en la matriz de proyección, aplicaciones deben asumir la imagen marcos representan una cámara pinhole perfecto, sin embargo el undistortion funcione en el procesador de imágenes puede dejar un error de hasta 10 píxeles cuando se usa en la matriz de proyección los metadatos del marco.</span><span class="sxs-lookup"><span data-stu-id="c4027-235">Because only the projection matrix is made available, applications must assume image frames represent a perfect pinhole camera, however the undistortion function in the image processor may still leave an error of up to 10 pixels when using the projection matrix in the frame metadata.</span></span> <span data-ttu-id="c4027-236">En muchos casos de uso, este error no se importa, pero si se están alineando hologramas a marcadores/pósteres de mundo real, por ejemplo, y tenga en cuenta un < 10 px de desplazamiento (aproximadamente 11mm para hologramas colocado 2 metros de distancia) distorsión de este error podría ser la causa.</span><span class="sxs-lookup"><span data-stu-id="c4027-236">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away) this distortion error could be the cause.</span></span>

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="c4027-237">Escenarios de uso de la cámara localizable</span><span class="sxs-lookup"><span data-stu-id="c4027-237">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="c4027-238">Mostrar una foto o vídeo en el mundo donde capturó</span><span class="sxs-lookup"><span data-stu-id="c4027-238">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="c4027-239">Los marcos de la cámara del dispositivo incluyen una transformación "Cámara a World", que puede usarse para mostrar exactamente donde el dispositivo estaba cuando se tomó la imagen.</span><span class="sxs-lookup"><span data-stu-id="c4027-239">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="c4027-240">Por ejemplo podría colocar un pequeño icono holográfico en esta ubicación (CameraToWorld.MultiplyPoint(Vector3.zero)) y draw incluso una pequeña flecha en la dirección que la cámara enfrentaba (CameraToWorld.MultiplyVector(Vector3.forward)).</span><span class="sxs-lookup"><span data-stu-id="c4027-240">For example you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="painting-the-world-using-a-camera-shader"></a><span data-ttu-id="c4027-241">El dibujo del mundo mediante un sombreador de cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-241">Painting the world using a camera shader</span></span>

<span data-ttu-id="c4027-242">En esta sección vamos a crear un material 'sombreador' ese colores en el mundo en función de donde se mostraba en la vista de la cámara de un dispositivo.</span><span class="sxs-lookup"><span data-stu-id="c4027-242">In this section we'll create a material 'shader' that colors the world based on where it showed up in a device camera's view.</span></span> <span data-ttu-id="c4027-243">Eficazmente lo que haremos es que cada vértice descifrará su ubicación en relación con la cámara y, a continuación, cada píxel utilizará la matriz de proyección' ' figura fuera que está asociada con la textura de imagen.</span><span class="sxs-lookup"><span data-stu-id="c4027-243">Effectively what we'll do is that every vertex will figure out its location relative to the camera, and then every pixel will utilize the 'projection matrix' to figure out which image texel it is associated with.</span></span> <span data-ttu-id="c4027-244">Por último y, opcionalmente, se deberá atenuar las esquinas de la imagen para que parezca más como un sueño similar de memoria:</span><span class="sxs-lookup"><span data-stu-id="c4027-244">Lastly, and optionally, we'll fade out the corners of the image to make it appear more as a dream-like memory:</span></span>

```
// In the vertex shader:
 float4 worldSpace = mul( ObjectToWorld, float4( vertexPos.xyz, 1));
 float4 cameraSpace = mul( CameraWorldToLocal, float4(worldSpace.xyz, 1));

 // In the pixel shader:
 float4 unprojectedTex = mul( CameraProjection, float4( cameraSpace .xyz, 1));
 float2 projectedTex = (unprojectedTex.xy / unprojectedTex.w);
 float2 unitTexcoord = ((projectedTex * 0.5) + float4(0.5, 0.5, 0, 0));
 float4 cameraTextureColor = tex2D(_CameraTex, unitTexcoord);
 // Fade out edges for better look:
 float pctInView = saturate((1.0 - length(projectedTex.xy)) * 3.0);
 float4 finalColor = float4( cameraTextureColor.rgb, pctInView );
```

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="c4027-245">Etiqueta / modelo / póster / seguimiento de objetos</span><span class="sxs-lookup"><span data-stu-id="c4027-245">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="c4027-246">Muchas aplicaciones de realidad mixta usan una imagen reconocible o patrón visual para crear un punto trackable en el espacio.</span><span class="sxs-lookup"><span data-stu-id="c4027-246">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="c4027-247">A continuación, se utiliza para representar objetos con relación a la que elija o creación una ubicación conocida.</span><span class="sxs-lookup"><span data-stu-id="c4027-247">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="c4027-248">Algunos usos de HoloLens incluyen buscar un objeto del mundo real se etiqueta con fiducials (por ejemplo, un monitor de TV con un código QR), colocar hologramas sobre fiducials y visualmente con no HoloLens dispositivos como tabletas que se configuraron para comunicarse con HoloLens a través de emparejamiento Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="c4027-248">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="c4027-249">Para reconocer una pauta visual y, a continuación, colocar ese objeto en el espacio global de aplicaciones, necesitará algunas cosas:</span><span class="sxs-lookup"><span data-stu-id="c4027-249">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="c4027-250">Una imagen patrón reconocimiento Kit de herramientas, como el código QR, AR etiquetas, buscador de cara, rastreadores de círculo, etcetera OCR.</span><span class="sxs-lookup"><span data-stu-id="c4027-250">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="c4027-251">Recopile los marcos de imagen en tiempo de ejecución y pasarlos a la capa de reconocimiento</span><span class="sxs-lookup"><span data-stu-id="c4027-251">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="c4027-252">Unproject sus ubicaciones de las imágenes en las posiciones del mundo, o los rayos mundo probablemente.</span><span class="sxs-lookup"><span data-stu-id="c4027-252">Unproject their image locations back into world positions, or likely world rays.</span></span> <span data-ttu-id="c4027-253">Consulte</span><span class="sxs-lookup"><span data-stu-id="c4027-253">See</span></span>
4. <span data-ttu-id="c4027-254">Coloque los modelos de virtuales a través de estas ubicaciones del mundo</span><span class="sxs-lookup"><span data-stu-id="c4027-254">Position your virtual models over these world locations</span></span>

<span data-ttu-id="c4027-255">Algunos vínculos de procesamiento de imagen importantes:</span><span class="sxs-lookup"><span data-stu-id="c4027-255">Some important image processing links:</span></span>
* [<span data-ttu-id="c4027-256">OpenCV</span><span class="sxs-lookup"><span data-stu-id="c4027-256">OpenCV</span></span>](http://opencv.org/)
* [<span data-ttu-id="c4027-257">QR etiquetas</span><span class="sxs-lookup"><span data-stu-id="c4027-257">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="c4027-258">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="c4027-258">FaceSDK</span></span>](http://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="c4027-259">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="c4027-259">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="c4027-260">Mantener una velocidad de fotogramas de aplicación interactiva es crítico, especialmente al tratar con algoritmos de reconocimiento de imagen de ejecución prolongada.</span><span class="sxs-lookup"><span data-stu-id="c4027-260">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="c4027-261">Por este motivo, usamos frecuentemente el siguiente patrón:</span><span class="sxs-lookup"><span data-stu-id="c4027-261">For this reason we commonly use the following pattern:</span></span>
1. <span data-ttu-id="c4027-262">Subproceso principal: administra el objeto de cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-262">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="c4027-263">Subproceso principal: solicitudes nuevos marcos (asincrónico)</span><span class="sxs-lookup"><span data-stu-id="c4027-263">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="c4027-264">Subproceso principal: pasar nuevos marcos a seguimiento de subproceso</span><span class="sxs-lookup"><span data-stu-id="c4027-264">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="c4027-265">Seguimiento de subproceso: imagen de los procesos para recopilar los puntos clave</span><span class="sxs-lookup"><span data-stu-id="c4027-265">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="c4027-266">Subproceso principal: encuentra el modelo virtual se desplaza para que coincida con los puntos clave</span><span class="sxs-lookup"><span data-stu-id="c4027-266">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="c4027-267">Subproceso principal: repita el paso 2</span><span class="sxs-lookup"><span data-stu-id="c4027-267">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="c4027-268">Algunos sistemas de marcador de imagen solo proporcionan una ubicación de píxel único (otros proporcionan la transformación completa en cuyo caso no se necesitará en esta sección), que equivale a un rayo de ubicaciones posibles.</span><span class="sxs-lookup"><span data-stu-id="c4027-268">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="c4027-269">Para llegar a una sola ubicación 3d, a continuación, podemos aprovechar varios rayos y buscar el resultado final mediante su intersección aproximado.</span><span class="sxs-lookup"><span data-stu-id="c4027-269">To get to a single 3d location we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="c4027-270">Para ello deberá:</span><span class="sxs-lookup"><span data-stu-id="c4027-270">To do this you'll need to:</span></span>
1. <span data-ttu-id="c4027-271">Obtener un bucle que se va a recopilar varias imágenes de la cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-271">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="c4027-272">Buscar el [puntos de característica asociados](#pixel-to-application-specified-coordinate-system)y sus rayos world</span><span class="sxs-lookup"><span data-stu-id="c4027-272">Find the [associated feature points](#pixel-to-application-specified-coordinate-system), and their world rays</span></span>
3. <span data-ttu-id="c4027-273">Cuando haya un diccionario de funciones, cada uno con varios rayos del mundo, puede usar el código siguiente a la solución en la intersección de los rayos:</span><span class="sxs-lookup"><span data-stu-id="c4027-273">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="c4027-274">Dadas dos o más ubicaciones de etiqueta sometidas a seguimiento, puede colocar una escena modelled para ajustar el escenario actual de los usuarios.</span><span class="sxs-lookup"><span data-stu-id="c4027-274">Given two or more tracked tag locations, you can position a modelled scene to fit the users current scenario.</span></span> <span data-ttu-id="c4027-275">Si no se puede suponer la gravedad, necesitará tres ubicaciones de etiqueta.</span><span class="sxs-lookup"><span data-stu-id="c4027-275">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="c4027-276">En muchos casos, que se usa una combinación de colores simple donde esferas blancos representan en tiempo real realiza un seguimiento de las ubicaciones de la etiqueta y esferas azules representan ubicaciones de etiqueta pueden modelar, esto permite al usuario medir la calidad de la alineación de visualmente.</span><span class="sxs-lookup"><span data-stu-id="c4027-276">In many cases we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations, this allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="c4027-277">Se supone la siguiente configuración en todas nuestras aplicaciones:</span><span class="sxs-lookup"><span data-stu-id="c4027-277">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="c4027-278">Dos o más ubicaciones pueden modelar etiqueta</span><span class="sxs-lookup"><span data-stu-id="c4027-278">Two or more modelled tag locations</span></span>
* <span data-ttu-id="c4027-279">Una 'espacio de calibración' que en la escena es el elemento primario de las etiquetas</span><span class="sxs-lookup"><span data-stu-id="c4027-279">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="c4027-280">Identificador de la característica de cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-280">Camera feature identifier</span></span>
* <span data-ttu-id="c4027-281">Comportamiento que se mueve el espacio de calibración para alinear las etiquetas modelled con las etiquetas en tiempo real (estamos cuidados al mover el espacio primario, no los marcadores modelled por sí mismos, porque otros connect es posiciones en relación con ellos).</span><span class="sxs-lookup"><span data-stu-id="c4027-281">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="render-holograms-from-the-cameras-position"></a><span data-ttu-id="c4027-282">Representar hologramas desde la posición de la cámara</span><span class="sxs-lookup"><span data-stu-id="c4027-282">Render holograms from the Camera's position</span></span>

<span data-ttu-id="c4027-283">Nota: Si intenta crear las suyas propias [mixto captura realidad (MRC)](mixed-reality-capture.md), que combina hologramas con el flujo de la cámara, puede usar el [efectos MRC](mixed-reality-capture-for-developers.md) o habilitar la propiedad showHolograms en [ Cámara localizable en Unity](locatable-camera-in-unity.md).</span><span class="sxs-lookup"><span data-stu-id="c4027-283">Note: If you are trying to create your own [Mixed reality capture (MRC)](mixed-reality-capture.md), which blends holograms with the Camera stream, you can use the [MRC effects](mixed-reality-capture-for-developers.md) or enable the showHolograms property in [Locatable camera in Unity](locatable-camera-in-unity.md).</span></span>

<span data-ttu-id="c4027-284">Si desea realizar un procesamiento especial directamente en la secuencia de cámara RGB, es posible representar hologramas en el espacio de la posición de la cámara en sincronización con una fuente de vídeo con el fin de proporcionar una vista previa grabación/live holograma personalizado.</span><span class="sxs-lookup"><span data-stu-id="c4027-284">If you'd like to do a special render directly on the RGB Camera stream, it's possible to render holograms in space from the Camera's position in sync with a video feed in order to provide a custom hologram recording/live preview.</span></span>

<span data-ttu-id="c4027-285">En Skype, hacemos esto para mostrar que el cliente remoto lo está viendo el usuario de HoloLens y que puedan interactuar con el mismos hologramas.</span><span class="sxs-lookup"><span data-stu-id="c4027-285">In Skype, we do this to show the remote client what the HoloLens user is seeing and allow them to interact with the same holograms.</span></span> <span data-ttu-id="c4027-286">Antes de enviar a través de cada fotograma de vídeo a través del servicio Skype, obtenemos datos cámara correspondientes de cada fotograma.</span><span class="sxs-lookup"><span data-stu-id="c4027-286">Before sending over each video frame through the Skype service, we grab each frame's corresponding camera data.</span></span> <span data-ttu-id="c4027-287">Hemos, a continuación, los metadatos intrínsecos y extrínsecos de la cámara con el fotograma de vídeo del paquete y, a continuación, enviarla a través del servicio Skype.</span><span class="sxs-lookup"><span data-stu-id="c4027-287">We then package the camera's extrinsic and intrinsic metadata with the video frame and then send it over the Skype service.</span></span>

<span data-ttu-id="c4027-288">En el lado receptor, con Unity, nos hemos ya sincronizados todos los hologramas en el espacio del usuario HoloLens con el mismo sistema de coordenadas.</span><span class="sxs-lookup"><span data-stu-id="c4027-288">On the receiving side, using Unity, we've already synced all of the holograms in the HoloLens user's space using the same coordinate system.</span></span> <span data-ttu-id="c4027-289">Esto nos permite usar extrínsecos metadatos de la cámara para colocar la cámara de Unity en el lugar exacto en el mundo (en relación con el resto de los hologramas) que el usuario HoloLens estaba de pie cuando se capturó ese fotograma de vídeo y use la información intrínsecos de cámara para Asegúrese de que la vista es el mismo.</span><span class="sxs-lookup"><span data-stu-id="c4027-289">This allows us to use the camera's extrinsic metadata to place the Unity camera in the exact place in the world (relative to the rest of the holograms) that the HoloLens user was standing when that video frame was captured, and use the camera intrinsic information to ensure the view is the same.</span></span>

<span data-ttu-id="c4027-290">Una vez que tenemos la cámara configurado correctamente, combinamos qué hologramas ve la cámara en el marco que hemos recibido de Skype, crear una vista de realidad mixta de cuál es el usuario de HoloLens ve mediante Graphics.Blit.</span><span class="sxs-lookup"><span data-stu-id="c4027-290">Once we have the camera set up properly, we combine what holograms the camera sees onto the frame we received from Skype, creating a mixed reality view of what the HoloLens user sees using Graphics.Blit.</span></span>

```cs
private void OnFrameReceived(Texture frameTexture, Vector3 cameraPosition, Quaternion cameraRotation, Matrix4x4 cameraProjectionMatrix)
{
    //set material that will be blitted onto the RenderTexture
    this.compositeMaterial.SetTexture(CompositeRenderer.CameraTextureMaterialProperty, frameTexture);
    //set the camera to be that of the HoloLens's device camera
    this.Camera.transform.position = cameraPosition;
    this.Camera.transform.rotation = cameraRotation;
    this.Camera.projectionMatrix = cameraProjectionMatrix;
    //trigger the Graphics's Blit now that the frame and camera are set up
    this.TextureReady = false;
}
private void OnRenderImage(RenderTexture source, RenderTexture destination)
{
    if (!this.TextureReady)
    {
        Graphics.Blit(source, destination, this.compositeMaterial);
        this.TextureReady = true;
    }
}
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="c4027-291">Seguimiento o identificar estacionarios etiquetados o en movimiento reales objetos/caras mediante LED u otras bibliotecas de módulo de reconocimiento</span><span class="sxs-lookup"><span data-stu-id="c4027-291">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="c4027-292">Ejemplos:</span><span class="sxs-lookup"><span data-stu-id="c4027-292">Examples:</span></span>
* <span data-ttu-id="c4027-293">Robots industriales con LED (u objetos de los códigos QR para mover más lento)</span><span class="sxs-lookup"><span data-stu-id="c4027-293">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="c4027-294">Identificar y reconocer objetos en la sala de reuniones</span><span class="sxs-lookup"><span data-stu-id="c4027-294">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="c4027-295">Identificar y reconocer las personas del salón (por ejemplo, lugar holográfica tarjetas de contacto a través de caras)</span><span class="sxs-lookup"><span data-stu-id="c4027-295">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="c4027-296">Vea también</span><span class="sxs-lookup"><span data-stu-id="c4027-296">See also</span></span>
* [<span data-ttu-id="c4027-297">Cámara localizable en DirectX</span><span class="sxs-lookup"><span data-stu-id="c4027-297">Locatable camera in DirectX</span></span>](locatable-camera-in-directx.md)
* [<span data-ttu-id="c4027-298">Cámara localizable en Unity</span><span class="sxs-lookup"><span data-stu-id="c4027-298">Locatable camera in Unity</span></span>](locatable-camera-in-unity.md)
* [<span data-ttu-id="c4027-299">Captura de realidad mixta</span><span class="sxs-lookup"><span data-stu-id="c4027-299">Mixed reality capture</span></span>](mixed-reality-capture.md)
* [<span data-ttu-id="c4027-300">Mixto captura realidad para desarrolladores</span><span class="sxs-lookup"><span data-stu-id="c4027-300">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="c4027-301">Introducción de captura de medios</span><span class="sxs-lookup"><span data-stu-id="c4027-301">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
