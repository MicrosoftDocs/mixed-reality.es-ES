---
title: Mirada con la cabeza y confirmación
description: Introducción al modelo de entrada de mirada con la cabeza y confirmación
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, gaze, gaze targeting, interaction, design
ms.openlocfilehash: d9eae3c0cfceba7c2c31425941dfce865f3aa609
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 06/05/2019
ms.locfileid: "66692305"
---
# <a name="head-gaze-and-commit"></a><span data-ttu-id="014b4-104">Mirada con la cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="014b4-104">Head-gaze and commit</span></span>
<span data-ttu-id="014b4-105">El modelo de mirada con la cabeza y confirmación es un modelo de entrada que implica establecer un objeto como destino con la cabeza apuntando hacia adelante (dirección de la cabeza) y actuar sobre él con una entrada secundaria, como un gesto de pulsación en el aire con la mano o el comando de voz "Seleccionar".</span><span class="sxs-lookup"><span data-stu-id="014b4-105">Head-gaze and commit is an input model that involves targeting an object with the direction of your head pointing forward (head-direction), and then acting on it with a secondary input such as the hand gesture Air Tap or the voice command “Select”.</span></span> <span data-ttu-id="014b4-106">Se considera un modelo de entrada "lejano" con manipulación indirecta, lo que significa que se usa preferiblemente para interactuar con el contenido que está fuera del alcance de los brazos.</span><span class="sxs-lookup"><span data-stu-id="014b4-106">It is considered a "far" input model with indirect manipulation, meaning it is best used for interacting with content that is beyond arms reach.</span></span>

## <a name="device-support"></a><span data-ttu-id="014b4-107">Compatibilidad con dispositivos</span><span class="sxs-lookup"><span data-stu-id="014b4-107">Device support</span></span>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><span data-ttu-id="014b4-108"><strong>Modelo de entrada</strong></span><span class="sxs-lookup"><span data-stu-id="014b4-108"><strong>Input model</strong></span></span></td>
        <td><span data-ttu-id="014b4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1.ª generación)</strong></a></span><span class="sxs-lookup"><span data-stu-id="014b4-109"><a href="hololens-hardware-details.md"><strong>HoloLens (1st gen)</strong></a></span></span></td>
        <td><span data-ttu-id="014b4-110"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="014b4-110"><strong>HoloLens 2</strong></span></span></td>
        <td><span data-ttu-id="014b4-111"><a href="immersive-headset-hardware-details.md"><strong>Cascos envolventes</strong></a></span><span class="sxs-lookup"><span data-stu-id="014b4-111"><a href="immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
    </tr>
     <tr>
        <td><span data-ttu-id="014b4-112">Mirada con la cabeza y confirmación</span><span class="sxs-lookup"><span data-stu-id="014b4-112">Head-gaze and commit</span></span></td>
        <td><span data-ttu-id="014b4-113">✔️ Recomendado</span><span class="sxs-lookup"><span data-stu-id="014b4-113">✔️ Recommended</span></span></td>
        <td><span data-ttu-id="014b4-114">✔️ Recomendado (tercera opción: <a href="interaction-fundamentals.md">Ver las demás opciones</a>)</span><span class="sxs-lookup"><span data-stu-id="014b4-114">✔️ Recommended (third choice - <a href="interaction-fundamentals.md">See the other options</a>)</span></span></td>
        <td><span data-ttu-id="014b4-115">➕ Opción alternativa</span><span class="sxs-lookup"><span data-stu-id="014b4-115">➕ Alternate option</span></span></td>
    </tr>
</table>

## <a name="head-gaze"></a><span data-ttu-id="014b4-116">Mirada con la cabeza</span><span class="sxs-lookup"><span data-stu-id="014b4-116">Head-gaze</span></span>
<span data-ttu-id="014b4-117">Los cascos de realidad mixta utilizan la posición y orientación de la cabeza del usuario para determinar el vector de dirección de la cabeza.</span><span class="sxs-lookup"><span data-stu-id="014b4-117">Mixed reality headsets use the position and orientation of the user's head to determine their head direction vector.</span></span> <span data-ttu-id="014b4-118">Se puede considerar como un láser que apunta en línea recta directamente desde el punto situado entre los ojos del usuario.</span><span class="sxs-lookup"><span data-stu-id="014b4-118">You can think of this as a laser that points straight ahead from directly between the user's eyes.</span></span> <span data-ttu-id="014b4-119">Esto es una aproximación bastante general de dónde mira el usuario.</span><span class="sxs-lookup"><span data-stu-id="014b4-119">This is a fairly coarse approximation of where the user is looking.</span></span> <span data-ttu-id="014b4-120">La aplicación puede intersecar este rayo con objetos reales o virtuales y dibujar un cursor en esa ubicación para que el usuario sepa adónde está apuntando en ese momento.</span><span class="sxs-lookup"><span data-stu-id="014b4-120">Your application can intersect this ray with virtual or real-world objects and draw a cursor at that location to let the user know what they are currently targeting.</span></span>

<span data-ttu-id="014b4-121">Además de la mirada con la cabeza, algunos cascos de realidad mixta, como HoloLens 2, incluyen sistemas de seguimiento de los ojos que generan un vector de la mirada con los ojos.</span><span class="sxs-lookup"><span data-stu-id="014b4-121">In addition to head gaze, some mixed reality headsets like the HoloLens 2 include eye tracking systems that produce an eye-gaze vector.</span></span> <span data-ttu-id="014b4-122">Esto proporciona una medida específica de adónde mira el usuario.</span><span class="sxs-lookup"><span data-stu-id="014b4-122">This provides a fine-grained measurement of where the user is looking.</span></span> <span data-ttu-id="014b4-123">Es posible crear interacciones de mirada y confirmación utilizando la mirada con los ojos, pero tiene un conjunto muy diferente de restricciones de diseño, que se explicará por separado en el [artículo de seguimiento de los ojos](eye-tracking.md).</span><span class="sxs-lookup"><span data-stu-id="014b4-123">It is possible to build gaze and commit interactions using eye gaze, but this comes with a very different set of design constraints, which will be covered separately in the [eye tracking article](eye-tracking.md).</span></span>

## <a name="commit"></a><span data-ttu-id="014b4-124">Confirmación</span><span class="sxs-lookup"><span data-stu-id="014b4-124">Commit</span></span>
<span data-ttu-id="014b4-125">Después de establecer como destino un objeto o un elemento de la interfaz de usuario, el usuario puede interactuar o hacer "clic" en el mismo con una entrada secundaria.</span><span class="sxs-lookup"><span data-stu-id="014b4-125">After targeting an object or UI element, the user can interact or "click" on it using a secondary input.</span></span> <span data-ttu-id="014b4-126">Esto se conoce como el paso de confirmación del modelo.</span><span class="sxs-lookup"><span data-stu-id="014b4-126">This is known as the commit step of the model.</span></span> <span data-ttu-id="014b4-127">Se admiten los siguientes métodos de confirmación:</span><span class="sxs-lookup"><span data-stu-id="014b4-127">The following commit methods are supported:</span></span>

- <span data-ttu-id="014b4-128">Gesto de pulsación en el aire</span><span class="sxs-lookup"><span data-stu-id="014b4-128">Air Tap gesture</span></span>
- <span data-ttu-id="014b4-129">Pronunciar el comando de voz "Seleccionar" o uno de los comandos de voz de destino</span><span class="sxs-lookup"><span data-stu-id="014b4-129">Speak the voice command "Select" or one of the targeted voice commands</span></span>
- <span data-ttu-id="014b4-130">Presionar el único botón de [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span><span class="sxs-lookup"><span data-stu-id="014b4-130">Press the single button on a [HoloLens Clicker](hardware-accessories.md#hololens-clicker)</span></span>
- <span data-ttu-id="014b4-131">Presionar el botón "A" del mando de Xbox</span><span class="sxs-lookup"><span data-stu-id="014b4-131">Press the 'A' button on an Xbox Gamepad</span></span>
- <span data-ttu-id="014b4-132">Presionar el botón "A" del Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="014b4-132">Press the 'A' button on an Xbox Adaptive Controller</span></span>

### <a name="head-gaze-and-air-tap-gesture"></a><span data-ttu-id="014b4-133">Mirada con la cabeza y gesto de pulsación en el aire</span><span class="sxs-lookup"><span data-stu-id="014b4-133">Head-gaze and air tap gesture</span></span>
<span data-ttu-id="014b4-134">Pulsar en el aire es hacer el gesto de pulsar con la mano vertical.</span><span class="sxs-lookup"><span data-stu-id="014b4-134">Air tap is a tapping gesture with the hand held upright.</span></span> <span data-ttu-id="014b4-135">Para pulsar en el aire, coloca el dedo índice en posición vertical, acerca el dedo al pulgar y levántalo de nuevo para liberar el clic.</span><span class="sxs-lookup"><span data-stu-id="014b4-135">To perform an Air tap, raise your index finger to the ready position, then pinch with your thumb and raise your index finger back up to release.</span></span> <span data-ttu-id="014b4-136">En HoloLens 1, pulsar en el aire es la entrada secundaria más común.</span><span class="sxs-lookup"><span data-stu-id="014b4-136">On HoloLens 1, Air tap is the most common secondary input.</span></span>

![Dedo en posición vertical y movimiento de pulsar o hacer clic](images/readyandpress.jpg)<br>

<span data-ttu-id="014b4-138">El gesto de pulsación en el aire también está disponible en HoloLens 2 y se ha relajado con respecto a la versión original.</span><span class="sxs-lookup"><span data-stu-id="014b4-138">Air tap is also available on HoloLens 2, and it has been relaxed from the original version.</span></span> <span data-ttu-id="014b4-139">Ahora se admiten casi todos los tipos de movimientos de acercar los dedos, siempre que la mano esté vertical y permanezca quieta.</span><span class="sxs-lookup"><span data-stu-id="014b4-139">Nearly all types of pinches are now supported, as long as the hand is upright and holding still.</span></span> <span data-ttu-id="014b4-140">Esto facilita a los usuarios aprender y realizar el gesto.</span><span class="sxs-lookup"><span data-stu-id="014b4-140">This makes it much easier for users to learn and perform the gesture.</span></span>  <span data-ttu-id="014b4-141">Este nuevo gesto de pulsación en el aire reemplaza al antiguo en la misma API, por lo que las aplicaciones existentes obtendrán automáticamente el nuevo comportamiento después de recompilar para HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="014b4-141">This new Air tap replaces the old one through the same API, so existing applications will get the new behavior automatically after recompiling for HoloLens 2.</span></span>

### <a name="head-gaze-and-select-voice-command"></a><span data-ttu-id="014b4-142">Mirada con la cabeza y comando de voz "Seleccionar"</span><span class="sxs-lookup"><span data-stu-id="014b4-142">Head-gaze and "Select" voice command</span></span>
<span data-ttu-id="014b4-143">Los comandos de voz son uno de los principales métodos de interacción en la realidad mixta.</span><span class="sxs-lookup"><span data-stu-id="014b4-143">Voice commanding is one of the primary interaction methods on Mixed Reality.</span></span> <span data-ttu-id="014b4-144">Proporcionan un mecanismo de "manos libres" muy eficaz para controlar el sistema.</span><span class="sxs-lookup"><span data-stu-id="014b4-144">It provides a very powerful "Hands Free" mechanism to control the system.</span></span> <span data-ttu-id="014b4-145">Hay diferentes tipos de modelos de interacción de voz:</span><span class="sxs-lookup"><span data-stu-id="014b4-145">There are diferent types of voice interaction models:</span></span>

- <span data-ttu-id="014b4-146">El comando genérico "Seleccionar", que equivale a confirmar o accionar un "clic" como una entrada secundaria.</span><span class="sxs-lookup"><span data-stu-id="014b4-146">The generic command "Select" that allows to perform a "click" actuation or commit as a secondary input.</span></span>
- <span data-ttu-id="014b4-147">Los comandos de objetos, como "Cerrar" o "Ampliar", que permiten realizar y confirmar una acción como una entrada secundaria.</span><span class="sxs-lookup"><span data-stu-id="014b4-147">Object commands like "Close" or "Make it bigger" that allow to perform and commit to an action as a secondary input.</span></span>
- <span data-ttu-id="014b4-148">Los comandos globales, como "Ir al principio", que no requieren un destino.</span><span class="sxs-lookup"><span data-stu-id="014b4-148">Global commnads like "Go to start" that don't require a target.</span></span>
- <span data-ttu-id="014b4-149">Las interfaces de usuario o entidades de conversación, como Cortana, que tienen una funcionalidad de lenguaje natural basada en inteligencia artificial.</span><span class="sxs-lookup"><span data-stu-id="014b4-149">Conversation user interfaces or entities like Cortana that have an AI Natural Language capability.</span></span>
- <span data-ttu-id="014b4-150">Los comandos personalizados.</span><span class="sxs-lookup"><span data-stu-id="014b4-150">Custom commnads</span></span>

<span data-ttu-id="014b4-151">Para obtener más información y una lista completa de los comandos disponibles y cómo usarlos, consulta nuestra guía de [comandos de voz](voice-design.md).</span><span class="sxs-lookup"><span data-stu-id="014b4-151">To find more details and a comprenhesive list of available commands and how to use, check out our [voice commanding](voice-design.md) guidance.</span></span>


### <a name="head-gaze-and-hololens-clicker"></a><span data-ttu-id="014b4-152">Mirada con la cabeza y HoloLens Clicker</span><span class="sxs-lookup"><span data-stu-id="014b4-152">Head-gaze and HoloLens Clicker</span></span>
<span data-ttu-id="014b4-153">HoloLens Clicker es el primer dispositivo periférico creado específicamente para HoloLens y se incluye en HoloLens 1 Development Edition.</span><span class="sxs-lookup"><span data-stu-id="014b4-153">The HoloLens Clicker is the first peripheral device built specifically for HoloLens and is included with the HoloLens 1 Development Edition.</span></span> <span data-ttu-id="014b4-154">HoloLens Clicker permite a un usuario hacer clic con un movimiento de la mano mínimo y confirmar como una entrada secundaria.</span><span class="sxs-lookup"><span data-stu-id="014b4-154">The HoloLens Clicker allows a user to click with minimal hand motion and commit as a secondary input.</span></span> <span data-ttu-id="014b4-155">HoloLens Clicker se conecta a HoloLens 1 o 2 mediante Bluetooth de bajo consumo (BTLE).</span><span class="sxs-lookup"><span data-stu-id="014b4-155">The HoloLens clicker connects to the HoloLens 1 or 2 using Bluetooth Low Energy (BTLE).</span></span>

<span data-ttu-id="014b4-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-156">![HoloLens Clicker](images/hololens-clicker-500px.jpg)</span></span><br>
<span data-ttu-id="014b4-157">*HoloLens Clicker*</span><span class="sxs-lookup"><span data-stu-id="014b4-157">*HoloLens Clicker*</span></span>

<span data-ttu-id="014b4-158">[Aquí](hardware-accessories.md#pairing-bluetooth-accessories) encontrarás más información e instrucciones para emparejar el dispositivo.</span><span class="sxs-lookup"><span data-stu-id="014b4-158">More information and instructions to pair the device can be found [here](hardware-accessories.md#pairing-bluetooth-accessories)</span></span>




### <a name="head-gaze-and-xbox-wireless-controller"></a><span data-ttu-id="014b4-159">Mirada con la cabeza y controlador inalámbrico de Xbox</span><span class="sxs-lookup"><span data-stu-id="014b4-159">Head-gaze and Xbox Wireless Controller</span></span>
<span data-ttu-id="014b4-160">El controlador inalámbrico de Xbox permite realizar una acción de "clic" como entrada secundaria con el botón A.</span><span class="sxs-lookup"><span data-stu-id="014b4-160">The Xbox Wireless Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="014b4-161">El dispositivo se asigna a un conjunto predeterminado de acciones que ayudan a desplazarse por el sistema y controlarlo.</span><span class="sxs-lookup"><span data-stu-id="014b4-161">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="014b4-162">Si deseas personalizar el controlador, utiliza la aplicación de accesorios de Xbox para configurar el controlador inalámbrico de Xbox.</span><span class="sxs-lookup"><span data-stu-id="014b4-162">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Wireless Controller.</span></span>

<span data-ttu-id="014b4-163">![Controlador inalámbrico de Xbox](images/xboxcontroller.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-163">![Xbox Wireless Controller](images/xboxcontroller.jpg)</span></span><br>
<span data-ttu-id="014b4-164">*Controlador inalámbrico de Xbox*</span><span class="sxs-lookup"><span data-stu-id="014b4-164">*Xbox Wireless Controller*</span></span>

[<span data-ttu-id="014b4-165">Emparejamiento de un controlador de Xbox con el PC</span><span class="sxs-lookup"><span data-stu-id="014b4-165">Pairing an Xbox controller with your PC</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a><span data-ttu-id="014b4-166">Mirada con la cabeza y Xbox Adaptive Controller</span><span class="sxs-lookup"><span data-stu-id="014b4-166">Head-gaze and Xbox Adaptive Controller</span></span>
<span data-ttu-id="014b4-167">Diseñado principalmente para satisfacer las necesidades de los jugadores con movilidad limitada, el Xbox Adaptive Controller es un centro unificado para dispositivos que hace la realidad mixta más accesible.</span><span class="sxs-lookup"><span data-stu-id="014b4-167">Designed primarily to meet the needs of gamers with limited mobility, the Xbox Adaptive Controller is a unified hub for devices that helps make Mixed Reality more accessible.</span></span>

<span data-ttu-id="014b4-168">Xbox Adaptive Controller permite realizar una acción de "clic" como entrada secundaria con el botón A.</span><span class="sxs-lookup"><span data-stu-id="014b4-168">The Xbox Adaptive Controller allows to perform a "click" actuation as a secondary input by using the A button.</span></span> <span data-ttu-id="014b4-169">El dispositivo se asigna a un conjunto predeterminado de acciones que ayudan a desplazarse por el sistema y controlarlo.</span><span class="sxs-lookup"><span data-stu-id="014b4-169">The device is mapped to a default set of actions that help navigate and controll the system.</span></span> <span data-ttu-id="014b4-170">Si deseas personalizar el controlador, utiliza la aplicación de accesorios de Xbox para configurar el Xbox Adaptive Controller.</span><span class="sxs-lookup"><span data-stu-id="014b4-170">If you want to customize the controller, use the Xbox Accesories App to configure your Xbox Adaptive Controller.</span></span>

<span data-ttu-id="014b4-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-171">![Xbox Adaptive Controller](images/xbox-adaptive-controller-devices.jpg)</span></span><br>
<span data-ttu-id="014b4-172">*Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="014b4-172">*Xbox Adaptive Controller*</span></span>

<span data-ttu-id="014b4-173">Conecta dispositivos externos como conmutadores, botones, soportes y joysticks para crear una experiencia de controladores personalizada exclusivamente para ti.</span><span class="sxs-lookup"><span data-stu-id="014b4-173">Connect external devices such as switches, buttons, mounts, and joysticks to create a custom controllers experience that is uniquely yours.</span></span> <span data-ttu-id="014b4-174">Las entradas de botones, palancas de control y activadores se controlan mediante dispositivos de asistencia que se conectan a las tomas de 3,5 mm y los puertos USB.</span><span class="sxs-lookup"><span data-stu-id="014b4-174">Button, thumbstick and trigger inputs are controlled with assistive devices connected through 3.5mm jacks and USB ports.</span></span>

<span data-ttu-id="014b4-175">![Puertos del Xbox Adaptive Controller](images/xbox-adaptive-controller-ports.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-175">![Xbox Adaptive Controller ports](images/xbox-adaptive-controller-ports.jpg)</span></span><br>
<span data-ttu-id="014b4-176">*Puertos del Xbox Adaptive Controller*</span><span class="sxs-lookup"><span data-stu-id="014b4-176">*Xbox Adaptive Controller ports*</span></span>

[<span data-ttu-id="014b4-177">Instrucciones para emparejar el dispositivo</span><span class="sxs-lookup"><span data-stu-id="014b4-177">Instructions to pair the device</span></span>](hardware-accessories.md#pairing-bluetooth-accessories)

<span data-ttu-id="014b4-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>Más información disponible en el sitio de Xbox</a></span><span class="sxs-lookup"><span data-stu-id="014b4-178"><a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>More info available on the Xbox site</a></span></span>


## <a name="design-guidelines"></a><span data-ttu-id="014b4-179">Directrices de diseño</span><span class="sxs-lookup"><span data-stu-id="014b4-179">Design guidelines</span></span>
> [!NOTE]
> <span data-ttu-id="014b4-180">[Próximamente](index.md) habrá disponible más información específica para el diseño de la mirada.</span><span class="sxs-lookup"><span data-stu-id="014b4-180">More guidance specific to gaze design [coming soon](index.md).</span></span>

## <a name="head-gaze-targeting"></a><span data-ttu-id="014b4-181">Establecer el destino de la mirada con la cabeza</span><span class="sxs-lookup"><span data-stu-id="014b4-181">Head-gaze targeting</span></span>
<span data-ttu-id="014b4-182">Todas las interacciones se basan en la capacidad de un usuario de establecer como destino el elemento con el que desea interactuar, independientemente de la modalidad de entrada.</span><span class="sxs-lookup"><span data-stu-id="014b4-182">All interactions are built upon the ability of a user to target the element they want to interact with, regardless of the input modality.</span></span> <span data-ttu-id="014b4-183">En Windows Mixed Reality, esto se hace mediante la mirada del usuario por lo general.</span><span class="sxs-lookup"><span data-stu-id="014b4-183">In Windows Mixed Reality, this is generally done using the user's gaze.</span></span>
<span data-ttu-id="014b4-184">Para que los usuarios puedan trabajar con una experiencia correctamente, la comprensión de la intención del usuario calculada por el sistema y la intención real del usuario deben estar lo más alineadas como sea posible.</span><span class="sxs-lookup"><span data-stu-id="014b4-184">To enable a user to work with an experience successfully, the system's calculated understanding of a user's intent, and the user's actual intent, must align as closely as possible.</span></span> <span data-ttu-id="014b4-185">En la medida que el sistema interpreta las intenciones del usuario correctamente, la satisfacción aumenta y el rendimiento mejora.</span><span class="sxs-lookup"><span data-stu-id="014b4-185">To the degree that the system interprets the user's intended actions correctly, satisfaction increases and performance improves.</span></span>


## <a name="target-sizing-and-feedback"></a><span data-ttu-id="014b4-186">Ajuste de tamaño del destino y comentarios</span><span class="sxs-lookup"><span data-stu-id="014b4-186">Target sizing and feedback</span></span>
<span data-ttu-id="014b4-187">Se ha demostrado repetidamente que el vector de mirada se puede usar para establecer el destino de forma precisa, pero suele funcionar mejor para destinos de mayor tamaño (adquisición de destinos algo mayores).</span><span class="sxs-lookup"><span data-stu-id="014b4-187">The gaze vector has been shown repeatedly to be usable for fine targeting, but often works best for gross targeting (acquiring somewhat larger targets).</span></span> <span data-ttu-id="014b4-188">Los destinos con un tamaño mínimo de entre 1 y 1,5 grados deberían permitir acciones de usuario correctas en la mayoría de los escenarios, aunque los destinos de 3 grados suelen permitir mayor velocidad.</span><span class="sxs-lookup"><span data-stu-id="014b4-188">Minimum target sizes of 1 to 1.5 degrees should allow successful user actions in most scenarios, though targets of 3 degrees often allow for greater speed.</span></span> <span data-ttu-id="014b4-189">Tenga en cuenta que el tamaño que el usuario establece como destino es realmente un área 2D incluso para los elementos 3D (cualquier proyección de ellos debe ser un área potencial de destino).</span><span class="sxs-lookup"><span data-stu-id="014b4-189">Note that the size that the user targets is effectively a 2D area even for 3D elements--whichever projection is facing them should be the targetable area.</span></span> <span data-ttu-id="014b4-190">Resulta muy útil proporcionar alguna indicación destacada de que un elemento está "activo" (que el usuario lo está estableciendo como destino). Esto puede incluir tratamientos como los efectos visibles de "mantener el puntero", señales auditivas o clics, o la alineación clara de un cursor con un elemento.</span><span class="sxs-lookup"><span data-stu-id="014b4-190">Providing some salient cue that an element is "active" (that the user is targeting it) is extremely helpful - this can include treatments like visible "hover" effects, audio highlights or clicks, or clear alignment of a cursor with an element.</span></span>

<span data-ttu-id="014b4-191">![Tamaño de destino óptimo a una distancia de 2 metros](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-191">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="014b4-192">*Tamaño de objetivo óptimo a una distancia de 2 metros*</span><span class="sxs-lookup"><span data-stu-id="014b4-192">*Optimal target size at 2 meter distance*</span></span>

<span data-ttu-id="014b4-193">![Ejemplo de resaltado de un objeto establecido como destino de la mirada](images/gazetargeting-highlighting-640px.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-193">![An example of highlighting a gaze targeted object](images/gazetargeting-highlighting-640px.jpg)</span></span><br>
<span data-ttu-id="014b4-194">*Ejemplo de resaltado de un objeto establecido como destino de la mirada*</span><span class="sxs-lookup"><span data-stu-id="014b4-194">*An example of highlighting a gaze targeted object*</span></span>

## <a name="target-placement"></a><span data-ttu-id="014b4-195">Situación del destino</span><span class="sxs-lookup"><span data-stu-id="014b4-195">Target placement</span></span>
<span data-ttu-id="014b4-196">Con frecuencia, los usuarios no podrán encontrar elementos de la interfaz de usuario que estén situados muy arriba o muy abajo en su campo de visión, y centrarán la mayoría de su atención en las áreas en torno al foco principal (normalmente al nivel de los ojos aproximadamente).</span><span class="sxs-lookup"><span data-stu-id="014b4-196">Users will often fail to find UI elements that are positioned very high or very low in their field of view, focusing most of their attention on areas around their main focus (usually roughly eye level).</span></span> <span data-ttu-id="014b4-197">Quizás resulte útil colocar la mayoría de los destinos en una banda razonable a la altura de los ojos.</span><span class="sxs-lookup"><span data-stu-id="014b4-197">Placing most targets in some reasonable band around eye level can help.</span></span> <span data-ttu-id="014b4-198">Dada la tendencia de los usuarios de centrarse en un área visual relativamente pequeña en todo momento (el cono de atención de la visión es de 10 grados aproximadamente), agrupar los elementos de la interfaz de usuario según su relación conceptual puede producir comportamientos de llamada de atención de un elemento a otro, ya que un usuario mueve su mirada dentro de un área.</span><span class="sxs-lookup"><span data-stu-id="014b4-198">Given the tendency for users to focus on a relatively small visual area at any time (the attentional cone of vision is roughly 10 degrees), grouping UI elements together to the degree that they're related conceptually can leverage attention-chaining behaviors from item to item as a user moves their gaze through an area.</span></span> <span data-ttu-id="014b4-199">Al diseñar la interfaz de usuario, se deben tener en cuenta las posibles grandes variaciones en el campo de visión entre HoloLens y los cascos envolventes.</span><span class="sxs-lookup"><span data-stu-id="014b4-199">When designing UI, keep in mind the potential large variation in field of view between HoloLens and immersive headsets.</span></span>

<span data-ttu-id="014b4-200">![Ejemplo de elementos de la interfaz de usuario agrupados para facilitar el establecimiento del destino con la mirada en Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="014b4-200">![An example of grouped UI elements for easier gaze targeting in Galaxy Explorer](images/gazetargeting-grouping-1000px.jpg)</span></span><br>
<span data-ttu-id="014b4-201">*Ejemplo de elementos de la interfaz de usuario agrupados para facilitar el establecimiento del destino con la mirada en Galaxy Explorer*</span><span class="sxs-lookup"><span data-stu-id="014b4-201">*An example of grouped UI elements for easier gaze targeting in Galaxy Explorer*</span></span>

## <a name="improving-targeting-behaviors"></a><span data-ttu-id="014b4-202">Mejora de los comportamientos de establecimiento de destino</span><span class="sxs-lookup"><span data-stu-id="014b4-202">Improving targeting behaviors</span></span>
<span data-ttu-id="014b4-203">Si se puede determinar (o aproximar) la intención del usuario de establecer algo como destino, puede ser muy útil aceptar intentos "casi incorrectos" en la interacción como si se hubiesen establecido correctamente.</span><span class="sxs-lookup"><span data-stu-id="014b4-203">If user intent to target something can be determined (or approximated closely), it can be very helpful to accept "near miss" attempts at interaction as though they were targeted correctly.</span></span> <span data-ttu-id="014b4-204">Hay una serie de métodos correctos que se pueden incorporar en las experiencias de realidad mixta:</span><span class="sxs-lookup"><span data-stu-id="014b4-204">There are a handful of successful methods that can be incorporated in mixed reality experiences:</span></span>

### <a name="head-gaze-stabilization-gravity-wells"></a><span data-ttu-id="014b4-205">Estabilización de la mirada con la cabeza ("pozos de gravedad")</span><span class="sxs-lookup"><span data-stu-id="014b4-205">Head-gaze stabilization ("gravity wells")</span></span>
<span data-ttu-id="014b4-206">Debería estar activada la mayor parte o todo el tiempo.</span><span class="sxs-lookup"><span data-stu-id="014b4-206">This should be turned on most/all of the time.</span></span> <span data-ttu-id="014b4-207">Esta técnica elimina las vibraciones naturales del cuello o la cabeza que los usuarios puedan tener.</span><span class="sxs-lookup"><span data-stu-id="014b4-207">This technique removes the natural head/neck jitters that users may have.</span></span> <span data-ttu-id="014b4-208">También existe un movimiento debido a los comportamientos de la mirada o el habla.</span><span class="sxs-lookup"><span data-stu-id="014b4-208">Also movement due to looking/speaking behaviors.</span></span>

### <a name="closest-link-algorithms"></a><span data-ttu-id="014b4-209">Algoritmos de vínculo más cercano</span><span class="sxs-lookup"><span data-stu-id="014b4-209">Closest link algorithms</span></span>
<span data-ttu-id="014b4-210">Funcionan mejor en áreas con un contenido interactivo disperso.</span><span class="sxs-lookup"><span data-stu-id="014b4-210">These work best in areas with sparse interactive content.</span></span> <span data-ttu-id="014b4-211">Si hay una alta probabilidad de poder determinar con qué intentaba interactuar un usuario, sus habilidades de establecimiento de destino se pueden complementar simplemente suponiendo cierto nivel de intención.</span><span class="sxs-lookup"><span data-stu-id="014b4-211">If there is a high probability that you can determine what a user was attempting to interact with, you can supplement their targeting abilities by simply assuming some level of intent.</span></span>

### <a name="backdatingpostdating-actions"></a><span data-ttu-id="014b4-212">Anticipar y posponer acciones</span><span class="sxs-lookup"><span data-stu-id="014b4-212">Backdating/postdating actions</span></span>
<span data-ttu-id="014b4-213">Este mecanismo es útil en las tareas que requieren velocidad.</span><span class="sxs-lookup"><span data-stu-id="014b4-213">This mechanism is useful in tasks requiring speed.</span></span> <span data-ttu-id="014b4-214">Cuando un usuario se mueve en una serie de maniobras de establecimiento de destino o activación con velocidad, puede resultar útil suponer alguna intención y permitir que los pasos no correctos puedan actuar sobre los destinos que el usuario ha tenido en su foco ligeramente antes o después de la acción de pulsar (50 ms antes o después ha resultado eficaz en las primeras pruebas).</span><span class="sxs-lookup"><span data-stu-id="014b4-214">When a user is moving through a series of targeting/activation maneuvers at speed, it can be useful to assume some intent and allow missed steps to act upon targets which the user had in focus slightly before or slightly after the tap (50ms before/after was effective in early testing).</span></span>

### <a name="smoothing"></a><span data-ttu-id="014b4-215">Suavizado</span><span class="sxs-lookup"><span data-stu-id="014b4-215">Smoothing</span></span>
<span data-ttu-id="014b4-216">Este mecanismo es útil para el trazado de movimientos y reduce la vibración u oscilación debidas a las características de los movimientos naturales de la cabeza.</span><span class="sxs-lookup"><span data-stu-id="014b4-216">This mechanism is useful for pathing movements, reducing the slight jitter/wobble due to natural head movement characteristics.</span></span> <span data-ttu-id="014b4-217">En el suavizado del trazado de movimientos, se debe realizar un suavizado en función del tamaño o la distancia de los movimientos y no en función del tiempo.</span><span class="sxs-lookup"><span data-stu-id="014b4-217">When smoothing over pathing motions, smooth by size/distance of movements rather than over time</span></span>

### <a name="magnetism"></a><span data-ttu-id="014b4-218">Magnetismo</span><span class="sxs-lookup"><span data-stu-id="014b4-218">Magnetism</span></span>
<span data-ttu-id="014b4-219">Este mecanismo puede considerarse como una versión más general de los algoritmos de "vínculo más cercano": dibujar un cursor hacia un destino o simplemente aumentar los indicadores de acierto (visibles o no) a medida que los usuarios se aproximan a los destinos usando conocimientos sobre el diseño interactivo para aproximar mejor la intención del usuario.</span><span class="sxs-lookup"><span data-stu-id="014b4-219">This mechanism can be thought of as a more general version of "Closest link" algorithms - drawing a cursor toward a target, or simply increasing hitboxes (whether visibly or not) as users approach likely targets, using some knowledge of the interactive layout to better approach user intent.</span></span> <span data-ttu-id="014b4-220">Esto puede resultar especialmente eficaz para destinos pequeños.</span><span class="sxs-lookup"><span data-stu-id="014b4-220">This can be particularly powerful for small targets.</span></span>

### <a name="focus-stickiness"></a><span data-ttu-id="014b4-221">Permanencia del foco</span><span class="sxs-lookup"><span data-stu-id="014b4-221">Focus stickiness</span></span>
<span data-ttu-id="014b4-222">Al determinar a qué elementos interactivos cercanos se dará el foco, se produce un sesgo hacia el elemento que está actualmente en el foco.</span><span class="sxs-lookup"><span data-stu-id="014b4-222">When determining which nearby interactive elements to give focus to, provide a bias to the element that is currently focused.</span></span> <span data-ttu-id="014b4-223">Esto ayudará a reducir comportamientos de cambio errático del foco cuando se flota en un punto intermedio entre dos elementos con ruido natural.</span><span class="sxs-lookup"><span data-stu-id="014b4-223">This will help reduce erratic focus switching behaviours when floating at a midpoint between two elements with natural noise.</span></span>


## <a name="composite-gestures"></a><span data-ttu-id="014b4-224">Gestos compuestos</span><span class="sxs-lookup"><span data-stu-id="014b4-224">Composite gestures</span></span>
<span data-ttu-id="014b4-225">Las aplicaciones pueden reconocer algo más que simples pulsaciones individuales.</span><span class="sxs-lookup"><span data-stu-id="014b4-225">Apps can recognize more than just individual taps.</span></span> <span data-ttu-id="014b4-226">Combinando los gestos de pulsar, mantener pulsado y soltar con el movimiento de la mano, se pueden realizar gestos compuestos más complejos.</span><span class="sxs-lookup"><span data-stu-id="014b4-226">By combining tap, hold and release with the movement of the hand, more complex composite gestures can be performed.</span></span> <span data-ttu-id="014b4-227">Estos gestos compuestos o de alto nivel se basan en los datos de entrada espaciales de bajo nivel (de Air tap y Bloom) a los que los desarrolladores tienen acceso.</span><span class="sxs-lookup"><span data-stu-id="014b4-227">These composite or high-level gestures build on the low-level spatial input data (from Air tap and Bloom) that developers have access to.</span></span>

### <a name="air-tap"></a><span data-ttu-id="014b4-228">Pulsar en el aire</span><span class="sxs-lookup"><span data-stu-id="014b4-228">Air tap</span></span>
<span data-ttu-id="014b4-229">El gesto de pulsación en el aire (así como los siguientes gestos) responden solo a una pulsación específica.</span><span class="sxs-lookup"><span data-stu-id="014b4-229">The Air tap gesture (as well as the other gestures below) reacts only to a specific tap.</span></span> <span data-ttu-id="014b4-230">Para detectar otras pulsaciones, como Menú o Agarrar, la aplicación debe usar directamente las interacciones de nivel inferior que se describen en la sección de dos gestos de componentes clave anterior.</span><span class="sxs-lookup"><span data-stu-id="014b4-230">To detect other taps, such as Menu or Grasp, your app must directly use the lower-level interactions described in two key component gestures section above.</span></span>

### <a name="tap-and-hold"></a><span data-ttu-id="014b4-231">Mantener pulsado</span><span class="sxs-lookup"><span data-stu-id="014b4-231">Tap and hold</span></span>
<span data-ttu-id="014b4-232">Mantener pulsado simplemente consiste en mantener la posición del dedo hacia abajo al pulsar en el aire.</span><span class="sxs-lookup"><span data-stu-id="014b4-232">Hold is simply maintaining the downward finger position of the air tap.</span></span> <span data-ttu-id="014b4-233">La combinación de pulsar en el aire y mantener pulsado permite una variedad de interacciones de "hacer clic y arrastrar" más complejas cuando se combina con el movimiento del brazo, como recoger un objeto en lugar de activarlo o interacciones secundarias del tipo "pulsación del mouse" tales como mostrar un menú contextual.</span><span class="sxs-lookup"><span data-stu-id="014b4-233">The combination of air tap and hold allows for a variety of more complex "click and drag" interactions when combined with arm movement such as picking up an object instead of activating it or "mousedown" secondary interactions such as showing a context menu.</span></span>
<span data-ttu-id="014b4-234">No obstante, se debe tener precaución al diseñar para este gesto, porque los usuarios pueden ser propensos a relajar las posturas de la mano en el caso de gestos prolongados.</span><span class="sxs-lookup"><span data-stu-id="014b4-234">Caution should be used when designing for this gesture however, as users can be prone to relaxing their hand postures during the course of any extended gesture.</span></span>

### <a name="manipulation"></a><span data-ttu-id="014b4-235">Manipulación</span><span class="sxs-lookup"><span data-stu-id="014b4-235">Manipulation</span></span>
<span data-ttu-id="014b4-236">Los gestos de manipulación se pueden utilizar para mover, cambiar el tamaño o girar un holograma cuando se desea que el holograma reaccione 1:1 con el movimiento de las manos del usuario.</span><span class="sxs-lookup"><span data-stu-id="014b4-236">Manipulation gestures can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements.</span></span> <span data-ttu-id="014b4-237">Uno de los usos de estos movimientos 1:1 es permitir al usuario dibujar o pintar en el mundo.</span><span class="sxs-lookup"><span data-stu-id="014b4-237">One use for such 1:1 movements is to let the user draw or paint in the world.</span></span>
<span data-ttu-id="014b4-238">El destino inicial de un gesto de manipulación debe establecerse con la mirada o apuntando.</span><span class="sxs-lookup"><span data-stu-id="014b4-238">The initial targeting for a manipulation gesture should be done by gaze or pointing.</span></span> <span data-ttu-id="014b4-239">Una vez que se inicia la acción de mantener pulsado, cualquier manipulación del objeto se controla con los movimientos de la mano, lo que permite al usuario mirar a su alrededor mientras manipula.</span><span class="sxs-lookup"><span data-stu-id="014b4-239">Once the tap and hold starts, any manipulation of the object is then handled by hand movements, freeing the user to look around while they manipulate.</span></span>

### <a name="navigation"></a><span data-ttu-id="014b4-240">Navegación</span><span class="sxs-lookup"><span data-stu-id="014b4-240">Navigation</span></span>
<span data-ttu-id="014b4-241">Los gestos de navegación funcionan como un joystick virtual y se pueden usar para navegar por los widgets de la interfaz de usuario, como los menús circulares.</span><span class="sxs-lookup"><span data-stu-id="014b4-241">Navigation gestures operate like a virtual joystick, and can be used to navigate UI widgets, such as radial menus.</span></span> <span data-ttu-id="014b4-242">Se mantiene pulsado para iniciar el gesto y, después, se mueve la mano dentro de un cubo 3D normalizado centrado alrededor de la pulsación inicial.</span><span class="sxs-lookup"><span data-stu-id="014b4-242">You tap and hold to start the gesture and then move your hand within a normalized 3D cube, centered around the initial press.</span></span> <span data-ttu-id="014b4-243">Se puede mover la mano a lo largo del eje X, Y o Z desde un valor de -1 hasta 1, siendo 0 el punto de partida.</span><span class="sxs-lookup"><span data-stu-id="014b4-243">You can move your hand along the X, Y or Z axis from a value of -1 to 1, with 0 being the starting point.</span></span>
<span data-ttu-id="014b4-244">La navegación se puede utilizar para crear gestos de zoom o desplazamiento continuo basado en la velocidad, similares al desplazamiento en una interfaz de usuario 2D cuando se hace clic con el botón central del ratón para después mover el ratón hacia arriba y abajo.</span><span class="sxs-lookup"><span data-stu-id="014b4-244">Navigation can be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</span></span>

<span data-ttu-id="014b4-245">La navegación con carriles hace referencia a la capacidad de reconocer los movimientos en un determinado eje hasta que se alcanza cierto umbral en ese eje.</span><span class="sxs-lookup"><span data-stu-id="014b4-245">Navigation with rails refers to the ability of recognizing movements in certain axis until certain threshold is reached on that axis.</span></span> <span data-ttu-id="014b4-246">Esto solo es útil cuando el desarrollador ha habilitado el movimiento en más de un eje en una aplicación; por ejemplo, si una aplicación está configurada para reconocer gestos de navegación en el eje X y el eje Y pero también se especifica el eje X con carriles.</span><span class="sxs-lookup"><span data-stu-id="014b4-246">This is only useful, when movement in more than one axis is enabled in an application by the developer, e.g. if an application is configured to recognize navigation gestures across X, Y axis but also specified X axis with rails.</span></span> <span data-ttu-id="014b4-247">En este caso, el sistema reconocerá los movimientos de la mano en el eje X siempre que permanezcan dentro de un carril imaginario (guía) en el eje X si también se produce movimiento en el eje Y.</span><span class="sxs-lookup"><span data-stu-id="014b4-247">In this case system will recognize hand movements across X axis as long as they remain within an imaginary rails (guide) on X axis, if hand movement also occurs Y axis.</span></span>

<span data-ttu-id="014b4-248">En las aplicaciones 2D, los usuarios pueden usar gestos de navegación vertical para desplazarse, hacer zoom o arrastrar dentro de la aplicación.</span><span class="sxs-lookup"><span data-stu-id="014b4-248">Within 2D apps, users can use vertical navigation gestures to scroll, zoom, or drag inside the app.</span></span> <span data-ttu-id="014b4-249">Esto inserta entradas táctiles virtuales en la aplicación para simular gestos táctiles del mismo tipo.</span><span class="sxs-lookup"><span data-stu-id="014b4-249">This injects virtual finger touches to the app to simulate touch gestures of the same type.</span></span> <span data-ttu-id="014b4-250">Los usuarios pueden seleccionar cuál de estas acciones tendrá lugar alternando entre las herramientas de la barra situada encima de la aplicación, ya sea seleccionando el botón o diciendo "Herramienta <desplazar/arrastrar/zoom>".</span><span class="sxs-lookup"><span data-stu-id="014b4-250">Users can select which of these actions take place by toggling between the tools on the bar above the app, either by selecting the button or saying '<Scroll/Drag/Zoom> Tool'.</span></span>

[<span data-ttu-id="014b4-251">Más información sobre los gestos compuestos</span><span class="sxs-lookup"><span data-stu-id="014b4-251">More info on composite gestures</span></span>](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a><span data-ttu-id="014b4-252">Reconocedores de gestos</span><span class="sxs-lookup"><span data-stu-id="014b4-252">Gesture recognizers</span></span>

<span data-ttu-id="014b4-253">Una ventaja de usar el reconocimiento de gestos es que se puede configurar un reconocedor de gestos solo para los gestos que puede aceptar el holograma de destino actual.</span><span class="sxs-lookup"><span data-stu-id="014b4-253">One benefit of using gesture recognition is that you can configure a gesture recognizer just for the gestures the currently targeted hologram can accept.</span></span> <span data-ttu-id="014b4-254">La plataforma hará la desambiguación necesaria para distinguir esos gestos admitidos en particular.</span><span class="sxs-lookup"><span data-stu-id="014b4-254">The platform will do only the disambiguation necessary to distinguish those particular supported gestures.</span></span> <span data-ttu-id="014b4-255">De este modo, un holograma que solo admite pulsar en el aire puede aceptar cualquier intervalo de tiempo entre pulsar y soltar, mientras que un holograma que también admite mantener pulsado puede promover la transición de pulsar a mantener pulsado una vez transcurrido el tiempo de espera.</span><span class="sxs-lookup"><span data-stu-id="014b4-255">That way, a hologram that just supports air tap can accept any length of time between press and release, while a hologram that supports both tap and hold can promote the tap to a hold after the hold time threshold.</span></span>

## <a name="hand-recognition"></a><span data-ttu-id="014b4-256">Reconocimiento de la mano</span><span class="sxs-lookup"><span data-stu-id="014b4-256">Hand recognition</span></span>
<span data-ttu-id="014b4-257">HoloLens reconoce los gestos de la mano mediante el seguimiento de la posición de una o ambas manos si son visibles para el dispositivo.</span><span class="sxs-lookup"><span data-stu-id="014b4-257">HoloLens recognizes hand gestures by tracking the position of either or both hands that are visible to the device.</span></span> <span data-ttu-id="014b4-258">HoloLens ve las manos cuando están en el estado preparado (parte posterior de la mano hacia ti con el dedo índice arriba) o el estado presionado (parte posterior de la mano hacia ti con el dedo índice hacia abajo).</span><span class="sxs-lookup"><span data-stu-id="014b4-258">HoloLens sees hands when they are in either the ready state (back of the hand facing you with index finger up) or the pressed state (back of the hand facing you with the index finger down).</span></span> <span data-ttu-id="014b4-259">Cuando las manos están en otra postura, HoloLens las ignorará.</span><span class="sxs-lookup"><span data-stu-id="014b4-259">When hands are in other poses, the HoloLens will ignore them.</span></span>
<span data-ttu-id="014b4-260">Para cada mano que HoloLens detecta, puedes acceder a su posición (sin orientación) y a su estado presionado.</span><span class="sxs-lookup"><span data-stu-id="014b4-260">For each hand that HoloLens detects, you can access its position (without orientation) and its pressed state.</span></span> <span data-ttu-id="014b4-261">A medida que la mano se acerca al borde del marco gestual, obtendrás un vector de dirección que puedes mostrar al usuario para que sepa cómo mover la mano para volver a ponerla donde HoloLens pueda verla.</span><span class="sxs-lookup"><span data-stu-id="014b4-261">As the hand nears the edge of the gesture frame, you're also provided with a direction vector, which you can show to the user so they know how to move their hand to get it back where HoloLens can see it.</span></span>

## <a name="gesture-frame"></a><span data-ttu-id="014b4-262">Marco gestual</span><span class="sxs-lookup"><span data-stu-id="014b4-262">Gesture frame</span></span>
<span data-ttu-id="014b4-263">Para los gestos en HoloLens, la mano debe estar dentro de un "marco gestual", en un intervalo donde las cámaras de detección de gestos la puedan ver correctamente (de forma muy aproximada, desde la nariz a la cintura y entre los hombros).</span><span class="sxs-lookup"><span data-stu-id="014b4-263">For gestures on HoloLens, the hand must be within a “gesture frame”, in a range that the gesture-sensing cameras can see appropriately (very roughly from nose to waist, and between the shoulders).</span></span> <span data-ttu-id="014b4-264">Los usuarios deben entrenarse en este área de reconocimiento para realizar una acción correcta y por su propia comodidad (muchos usuarios asumirán inicialmente que el marco gestual está dentro de su visión con HoloLens y subirán sus brazos de un modo incómodo para interactuar).</span><span class="sxs-lookup"><span data-stu-id="014b4-264">Users need to be trained on this area of recognition both for success of action and for their own comfort (many users will initially assume that the gesture frame must be within their view through HoloLens, and hold their arms up uncomfortably in order to interact).</span></span> <span data-ttu-id="014b4-265">Cuando se usa HoloLens Clicker, las manos no necesitan estar dentro del marco gestual.</span><span class="sxs-lookup"><span data-stu-id="014b4-265">When using the HoloLens Clicker, your hands do not need to be within the gesture frame.</span></span>

<span data-ttu-id="014b4-266">En el caso de gestos continuos, existe el riesgo de que los usuarios muevan las manos fuera del marco gestual mientras se encuentran en medio del gesto (mientras mueven algún objeto holográfico, por ejemplo) y pierdan el resultado previsto.</span><span class="sxs-lookup"><span data-stu-id="014b4-266">In the case of continuous gestures in particular, there is some risk of users moving their hands outside of the gesture frame while in mid-gesture (while moving some holographic object, for example), and losing their intended outcome.</span></span>

<span data-ttu-id="014b4-267">Hay tres cosas que hay que tener en cuenta:</span><span class="sxs-lookup"><span data-stu-id="014b4-267">There are three things that you should consider:</span></span>

- <span data-ttu-id="014b4-268">La educación del usuario en la existencia del marco gestual y sus límites aproximados (esto se enseña durante la instalación de HoloLens).</span><span class="sxs-lookup"><span data-stu-id="014b4-268">User education on the gesture frame's existence and approximate boundaries (this is taught during HoloLens setup).</span></span>

- <span data-ttu-id="014b4-269">Notificar a los usuarios cuando sus movimientos se aproximan a los límites del marco gestual o se salen de él en una aplicación, en la medida que un gesto perdido dará lugar a resultados no deseados.</span><span class="sxs-lookup"><span data-stu-id="014b4-269">Notifying users when their gestures are nearing/breaking the gesture frame boundaries within an application, to the degree that a lost gesture will lead to undesired outcomes.</span></span> <span data-ttu-id="014b4-270">Las investigaciones han demostrado las ventajas de este sistema de notificación y el shell de HoloLens es un buen ejemplo de este tipo de notificación (visual, en el cursor central, indicando la dirección en la que se están traspasando los límites).</span><span class="sxs-lookup"><span data-stu-id="014b4-270">Research has shown the key qualities of such a notification system, and the HoloLens shell provides a good example of this type of notification (visual, on the central cursor, indicating the direction in which boundary crossing is taking place).</span></span>

- <span data-ttu-id="014b4-271">Se deben minimizar las consecuencias de traspasar los límites del marco gestual.</span><span class="sxs-lookup"><span data-stu-id="014b4-271">Consequences of breaking the gesture frame boundaries should be minimized.</span></span> <span data-ttu-id="014b4-272">En general, esto significa que el resultado de un gesto se debe en el límite, pero no se debe revertir.</span><span class="sxs-lookup"><span data-stu-id="014b4-272">In general, this means that the outcome of a gesture should be stopped at the boundary, but not reversed.</span></span> <span data-ttu-id="014b4-273">Por ejemplo, si un usuario está moviendo algún objeto holográfico por una sala, el movimiento debe detenerse cuando se traspasa el marco gestual, pero no debe devolverse al punto de partida.</span><span class="sxs-lookup"><span data-stu-id="014b4-273">For example, if a user is moving some holographic object across a room, movement should stop when the gesture frame is breached, but not be returned to the starting point.</span></span> <span data-ttu-id="014b4-274">El usuario podría experimentar alguna frustración, pero comprenderá más rápidamente los límites y no tendrá que reiniciar las acciones previstas completas cada vez.</span><span class="sxs-lookup"><span data-stu-id="014b4-274">The user may experience some frustration then, but may more quickly understand the boundaries, and not have to restart their full intended actions each time.</span></span>


## <a name="see-also"></a><span data-ttu-id="014b4-275">Consulte también</span><span class="sxs-lookup"><span data-stu-id="014b4-275">See also</span></span>
* [<span data-ttu-id="014b4-276">Manipulación directa con las manos</span><span class="sxs-lookup"><span data-stu-id="014b4-276">Direct manipulation with hands</span></span>](direct-manipulation.md)
* [<span data-ttu-id="014b4-277">Apuntar y confirmar con las manos</span><span class="sxs-lookup"><span data-stu-id="014b4-277">Point and commit with hands</span></span>](point-and-commit.md)
* [<span data-ttu-id="014b4-278">Interacciones instintivas</span><span class="sxs-lookup"><span data-stu-id="014b4-278">Instinctual interactions</span></span>](interaction-fundamentals.md)
* [<span data-ttu-id="014b4-279">Control con la cabeza y permanencia</span><span class="sxs-lookup"><span data-stu-id="014b4-279">Head-gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="014b4-280">Comandos de voz</span><span class="sxs-lookup"><span data-stu-id="014b4-280">Voice commanding</span></span>](voice-design.md)





